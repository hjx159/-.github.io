<!-- build time:Sat Mar 02 2024 22:12:19 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="水文 & 摄影" href="http://example.com/rss.xml"><link rel="alternate" type="application/atom+xml" title="水文 & 摄影" href="http://example.com/atom.xml"><link rel="alternate" type="application/json" title="水文 & 摄影" href="http://example.com/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="http://example.com/database/redis/Redis-JavaGuide/"><title>Redis-JavaGuide - Redis - 数据库 | fantedong = 水文 & 摄影 = 为了能更好地查看图片，你需要一点魔法</title><meta name="generator" content="Hexo 6.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Redis-JavaGuide</h1><div class="meta"><span class="item" title="创建时间：2023-11-17 20:03:29"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2023-11-17T20:03:29+08:00">2023-11-17</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>103k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>1:34</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">fantedong</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><img src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/sql-nosql-tushi.png"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/database/" itemprop="item" rel="index" title="分类于 数据库"><span itemprop="name">数据库</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/database/redis/" itemprop="item" rel="index" title="分类于 Redis"><span itemprop="name">Redis</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://example.com/database/redis/Redis-JavaGuide/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="范特东东东"><meta itemprop="description" content="为了能更好地查看图片，你需要一点魔法, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="水文 & 摄影"></span><div class="body md" itemprop="articleBody"><h1 id="缓存基础常见面试题"><a class="anchor" href="#缓存基础常见面试题">#</a> 缓存基础常见面试题</h1><h2 id="为什么要用分布式缓存"><a class="anchor" href="#为什么要用分布式缓存">#</a> 为什么要用分布式缓存？</h2><blockquote><p>相关面试题：</p><ul><li>为什么要用缓存？</li><li>本地缓存应该怎么做？</li><li>为什么要有分布式缓存？/ 为什么不直接用本地缓存？</li><li>多级缓存了解么？</li></ul></blockquote><h3 id="缓存的基本思想"><a class="anchor" href="#缓存的基本思想">#</a> 缓存的基本思想</h3><p>很多同学只知道<font color="red">缓存可以提高系统性能，减少请求相应时间</font>。但是，不太清楚缓存的本质思想是什么。</p><p>缓存的基本思想其实很简单，就是我们非常熟悉的 **<font color="red">空间换时间</font>**。不要把缓存想的太高大上，虽然，它的确对系统的性能提升的性价比非常高。</p><p>其实，我们在学习使用缓存的时候，你会发现缓存的思想实际在操作系统或者其他地方都被大量用到。比如<font color="red"> CPU Cache 缓存的是内存数据，用于解决 CPU 处理速度和内存不匹配的问题</font>；<font color="red">内存缓存的是硬盘数据，用于解决硬盘访问速度过慢的问题</font>；<font color="red">操作系统在页表方案基础之上引入了快表，来加速虚拟地址到物理地址的转换</font>。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache）。</p><p>我们知道，缓存中的数据通常存储于内存中，因此访问速度非常快。为了避免内存中的数据在重启或者宕机之后丢失，很多缓存中间件会利用磁盘做持久化。</p><p>也就是说，缓存相比于我们常用的关系型数据库（比如 MySQL）来说访问速度要快非常多。<strong><font color="red">为了避免用户请求数据库中的数据速度过慢，可以在数据库之上增加一层缓存</font></strong>。</p><p>除了能够提高访问速度之外，<font color="red">缓存支持的并发量也要更大</font>，有了缓存之后，数据库的压力也会随之变小。</p><h3 id="缓存的分类"><a class="anchor" href="#缓存的分类">#</a> 缓存的分类</h3><h4 id="本地缓存"><a class="anchor" href="#本地缓存">#</a> 本地缓存</h4><h5 id="是什么"><a class="anchor" href="#是什么">#</a> 是什么</h5><p>这个实际在很多项目中用的蛮多，特别是<font color="red">单体架构</font>的时候。<font color="red">数据量不大，并且没有分布式要求</font>的话，使用本地缓存还是可以的。</p><p><strong><font color="red">本地缓存位于应用内部，其最大的优点是应用存在于同一个进程内部，请求本地缓存的速度非常快，不存在额外的网络开销</font></strong>。</p><p>常见的单体架构图如下，我们使用 <strong>Nginx</strong> 来做<strong>负载均衡</strong>，部署两个相同的应用到服务器，两个服务使用同一个数据库，并且使用的是本地缓存。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/local-cache.png" alt="local-cache.png"></p><h5 id="实现方案"><a class="anchor" href="#实现方案">#</a> 实现方案</h5><p><strong>1、JDK 自带的 HashMap 和 ConcurrentHashMap</strong></p><blockquote><p>一般不用</p></blockquote><p>ConcurrentHashMap 可以看作是线程安全版本的 HashMap ，两者都是存放 key/value 形式的键值对。但是，大部分场景来说不会使用这两者当做缓存，因为<font color="red">只提供了缓存的功能，并没有提供其他诸如过期时间之类的功能</font>。一个稍微完善一点的缓存框架 **<font color="red">至少要提供：过期时间、淘汰机制、命中率统计</font>** 这三点。</p><p><strong>2、 Ehcache 、 Guava Cache 、 Spring Cache 本地缓存框架</strong></p><blockquote><p>使用的比较多</p></blockquote><ul><li><code>Ehcache</code> ：相比于其他两者<font color="red">更加重量</font>，不过 <code>Ehcache</code> 支持可以嵌入到 hibernate 和 mybatis 作为<font color="red">多级缓存</font>，并且可以将缓存的数据<font color="red">持久化</font>到本地磁盘中、同时也提供了<font color="red">集群方案</font>（比较鸡肋，可忽略）。</li><li><code>Guava Cache</code> 和 <code>Spring Cache</code> 比较像。 <code>Guava</code> 相比于 <code>Spring Cache</code> 的话使用的更多一点，它提供了 API 非常方便我们使用，同时也提供了<font color="red">设置缓存有效时间</font>等功能。它的内部实现也比较干净，很多地方都和 <code>ConcurrentHashMap</code> 的思想有异曲同工之妙。</li><li>使用 <code>Spring Cache</code> 的注解实现缓存的话，<font color="red">代码会看着很干净和优雅</font>，但是很容易出现问题比如<font color="red">缓存穿透、内存溢出</font>。</li></ul><p><strong><font color="red">3、后起之秀 Caffeine</font></strong></p><blockquote><p>使用最多</p></blockquote><p>相比于 <code>Guava</code> 来说 <code>Caffeine</code> 在各个方面比如性能要更加优秀，一般建议使用其来替代 <code>Guava</code> 。并且 <code>Guava</code> 和 <code>Caffeine</code> 的使用方式很像！</p><h5 id="缺点"><a class="anchor" href="#缺点">#</a> 缺点</h5><p>本地的缓存的优势非常明显：低依赖、轻量、简单、成本低。</p><p>但是，本地缓存存在下面这些缺陷：</p><ul><li><strong><font color="red">本地缓存应用耦合，对分布式架构支持不友好</font></strong>：比如同一个相同的服务部署在多台机器上的时候，各个服务之间的缓存是无法共享的，因为本地缓存只在当前机器上有。</li><li><strong><font color="red">本地缓存的容量受服务部署所在机器的限制明显</font></strong>：如果当前系统服务所耗费的内存多，那么本地缓存可用的容量就很少。</li></ul><h4 id="分布式缓存"><a class="anchor" href="#分布式缓存">#</a> 分布式缓存</h4><h5 id="是什么-2"><a class="anchor" href="#是什么-2">#</a> 是什么</h5><p>我们可以把分布式缓存（Distributed Cache）看作是一种内存数据库的服务，它的最终作用就是提供缓存数据的服务。</p><p><strong><font color="red">分布式缓存脱离于应用独立存在，多个应用可直接的共同使用同一个分布式缓存服务</font></strong>。</p><p>如下图所示，就是一个简单的使用分布式缓存的架构图。我们使用 Nginx 来做负载均衡，部署两个相同的应用到服务器，两个服务使用同一个数据库和缓存。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/distributed-cache.png" alt="distributed-cache.png"></p><p>使用分布式缓存之后，<font color="red">缓存服务可以部署在一台单独的服务器上</font>，即使同一个相同的服务部署在多台机器上，也是使用的同一份缓存。 并且，单独的分布式缓存服务的<font color="red">性能、容量和提供的功能都要更加强大</font>。</p><p>** 但是，软件系统设计中没有银弹，往往任何技术的引入都像是把双刃剑。** 你使用的方式得当，就能为系统带来很大的收益。否则，只是费了精力不讨好。</p><p>简单来说，为系统引入分布式缓存之后往往会带来下面这些问题：</p><ul><li><strong><font color="red">系统复杂性增加</font></strong>：引入缓存之后，<font color="red">要维护缓存和数据库的数据一致性、维护热点缓存、保证缓存服务的高可用</font>等等。</li><li><strong><font color="red">系统开发成本增加</font></strong>：引入缓存意味着系统需要一个单独的缓存服务，这是需要花费相应的成本的，并且这个成本还是很贵的，毕竟耗费的是宝贵的内存。</li></ul><h5 id="实现方案redis"><a class="anchor" href="#实现方案redis">#</a> 实现方案：Redis</h5><p>唯一真神：<strong><font color="red">Redis</font></strong>！</p><h4 id="多级缓存"><a class="anchor" href="#多级缓存">#</a> 多级缓存</h4><p>这里只来简单聊聊 <strong><font color="red">本地缓存 + 分布式缓存</font></strong> 的多级缓存方案。</p><p>这个时候估计有很多小伙伴就会问了：既然用了分布式缓存，为什么还要用本地缓存呢？</p><p>的确，<font color="red">一般情况下是不建议使用多级缓存的，这会增加维护负担</font>（比如你需要保证一级缓存和二级缓存的数据一致性），并且，实际带来的提升效果对于绝大部分项目来说其实并不是很大。</p><p>多级缓存方案中，<strong><font color="red">第一级缓存（L1）使用本地内存（比如 Caffeine），第二级缓存（L2）使用分布式缓存（比如 Redis）</font></strong>。读取缓存数据的时候，我们<font color="red">先从 L1 中读取，读取不到的时候再去 L2 读取</font>。这样可以降低 L2 的压力，减少 L2 的读次数。并且，<font color="red">本地内存的访问速度是最快的，不存在什么网络开销</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/multilevel-cache.png" alt="multilevel-cache.png"></p><h2 id="常见的缓存更新策略有哪几种"><a class="anchor" href="#常见的缓存更新策略有哪几种">#</a> 常见的缓存更新策略有哪几种？</h2><p>下面介绍到的三种模式各有优劣，不存在最佳模式，根据具体的业务场景选择适合自己的缓存读写模式即可！</p><h3 id="cache-aside-pattern旁路缓存模式"><a class="anchor" href="#cache-aside-pattern旁路缓存模式">#</a> Cache Aside Pattern（旁路缓存模式）</h3><blockquote><p>平时使用比较多</p></blockquote><h4 id="是什么-3"><a class="anchor" href="#是什么-3">#</a> 是什么</h4><p>Cache Aside Pattern 是我们<font color="red">平时使用比较多</font>的一个缓存读写模式，<font color="red">适合读请求比较多的场景</font>。</p><p>Cache Aside Pattern 中 **<font color="red">服务端需要同时维系数据库（后文简称 db）和缓存（后文简称 cache）</font>**，并且是<font color="red">以 db 的结果为准</font>。</p><h4 id="缓存读写步骤"><a class="anchor" href="#缓存读写步骤">#</a> 缓存读写步骤</h4><p><strong>写</strong>：</p><ol><li>先更新 db</li><li><font color="red">直接删除 cache</font></li></ol><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/fd814571-c1ae-4f7e-aad8-5dac5b741de8.png" alt="img"></p><p><strong>读</strong>：</p><ol><li>先从 cache 中读取数据，读取到就直接返回</li><li>cache 中读取不到的话，再从 db 中读取数据返回</li><li><font color="red">再把从 db 中读取到的数据写入 cache 中</font></li></ol><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/cfa0a217-53d2-45d8-b9e9-13970de9982c.png" alt="img"></p><h4 id="原理"><a class="anchor" href="#原理">#</a> 原理</h4><p>问题：<strong>写数据时为什么删除 cache，而不是更新 cache？</strong></p><p>仅仅了解了上面这些内容的话是远远不够的，我们还要搞懂其中的原理。</p><p>主要原因有两点：</p><ol><li><strong><font color="red">对服务端资源造成浪费</font></strong>：<font color="red">删除 cache 更加直接</font>，这是因为 cache 中存放的一些数据需要服务端经过大量的计算才能得出，会消耗服务端的资源，是一笔不小的开销。<font color="red">如果频繁修改 db，就能会导致需要频繁更新 cache，而 cache 中的数据可能都没有被访问到</font>。</li><li><strong><font color="red">产生数据不一致问题</font></strong>：并发场景下，更新 cache 产生数据不一致性问题的概率会更大（后文会解释原因）。</li></ol><hr><p>追问：<strong>写数据时，为什么不先删除 cache ，再更新 db ？</strong></p><p>答案：那肯定是不行的！因为这样可能 **<font color="red">会造成数据库（db）和缓存（Cache）数据不一致</font>** 的问题。</p><p>举例：请求 1 先写数据 A，请求 2 随后读数据 A 的话，就很有可能产生数据不一致性的问题。这个过程可以简单描述为：</p><ol><li><p>请求 1 先把 cache 中的 A 数据删除；</p></li><li><p>请求 2 从 db 中读取数据；</p></li><li><p>请求 1 再把 db 中的 A 数据更新。</p></li></ol><p>这就会导致请求 2 读取到的是旧值。</p><hr><p>追问：<strong>写数据时，先更新 db，后删除 cache 就没有问题了么？</strong></p><p>答案：理论上来说<font color="red">出现数据不一致性的概率非常小，因为缓存的写入速度是比数据库的写入速度快很多</font>。</p><p>举例：请求 1 先读数据 A，请求 2 随后写数据 A，并且数据 A 在请求 1 请求之前不在缓存中的话，也有可能产生数据不一致性的问题。这个过程可以简单描述为：</p><ol><li><p>请求 1 从 db 读数据 A；</p></li><li><p>请求 2 更新 db 中的数据 A（此时缓存中无数据 A ，故不用执行删除缓存操作 ）；</p></li><li><p>请求 1 将数据 A 写入 cache。</p></li></ol><p>这就会导致 cache 中存放的其实是旧值。</p><h4 id="缺点-2"><a class="anchor" href="#缺点-2">#</a> 缺点</h4><ul><li><p>缺陷 1：<strong>首次请求数据一定不在 cache 中</strong></p><blockquote><p>解决办法：<font color="red">将热点数据提前放入 cache 中</font></p></blockquote></li><li><p>缺陷 2：<strong>写操作比较频繁的话，会导致 cache 中的数据频繁被删除，影响缓存命中率</strong></p><blockquote><p>解决办法：</p><ul><li><p>数据库和缓存数据强一致场景：更新 db 的时候同样更新 cache，不过我们需要加一个锁 / 分布式锁来保证更新 cache 的时候不存在线程安全问题。</p></li><li><p>可以短暂地允许数据库和缓存数据不一致的场景：更新 db 的时候同样更新 cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。</p></li></ul></blockquote></li></ul><h3 id="readwrite-through-pattern读写穿透模式"><a class="anchor" href="#readwrite-through-pattern读写穿透模式">#</a> Read/Write Through Pattern（读 / 写穿透模式）</h3><blockquote><p>在平时开发过程中非常少见</p></blockquote><h4 id="是什么-4"><a class="anchor" href="#是什么-4">#</a> 是什么</h4><p>Read/Write Through Pattern 中服务端 **<font color="red">把 cache 视为主要数据存储，从中读 / 写数据；而 cache 服务负责将此数据读取和写入 db，从而减轻了应用程序的职责</font>**。</p><p>这种缓存读写策略小伙伴们应该也发现了<font color="red">在平时开发过程中非常少见</font>。抛去性能方面的影响，大概率是因为我们经常使用的分布式缓存<font color="red"> Redis 并没有提供将 cache 数据写入 db 的功能</font>。</p><h4 id="缓存读写步骤-2"><a class="anchor" href="#缓存读写步骤-2">#</a> 缓存读写步骤</h4><p><strong>写（Write Through）</strong>：</p><blockquote><p>与旁路缓存模式的写步骤不同</p></blockquote><ol><li><p><font color="red">先检查 cache 中是否存在要写入的数据</font>：</p><ol><li><p><font color="red">若 cache 中不存在</font>，则直接更新 db</p></li><li><p><font color="red">若 cache 中存在</font>，则先更新 cache；然后 cache 服务再更新 db</p></li></ol></li></ol><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/0126e23d-f0d1-4c30-a568-b60405b3dda8.png" alt="img"></p><p><strong>读（Read Through）</strong>：</p><blockquote><p>与旁路缓存模式的读步骤一样</p></blockquote><ol><li><p>先从 cache 中读取数据，读取到就直接返回</p></li><li><p>从 cache 中读取不到的话，再从 db 加载，最后写入 cache ，返回响应</p></li></ol><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/e685e967-1655-4424-a75d-490101b52087.png" alt="img"></p><h4 id="原理-2"><a class="anchor" href="#原理-2">#</a> 原理</h4><p><strong>Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装</strong>。在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由客户端自己负责把数据写入 cache，而 Read Through Pattern 则是 cache 服务自己来写入缓存的，这对客户端是透明的。</p><h4 id="缺点-3"><a class="anchor" href="#缺点-3">#</a> 缺点</h4><p>和 Cache Aside Pattern 一样， Read-Through Pattern <strong><font color="red">也存在首次请求数据一定不在 cache 的问题，可以将热点数据提前放入 cache 中</font></strong>。</p><h3 id="write-behind-pattern异步缓存写入模式"><a class="anchor" href="#write-behind-pattern异步缓存写入模式">#</a> Write Behind Pattern（异步缓存写入模式）</h3><blockquote><p>在平时开发过程中也非常非常少见</p></blockquote><p>Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 db 的读写。</p><p>但是，两个又有很大的不同：<strong>Read/Write Through 是同步更新 cache 和 db，<font color="red">而 Write Behind 则是只更新 cache，不直接更新 db，而是改为异步批量的方式来更新 db</font>。</strong></p><p>很明显，这种方式对数据一致性带来了更大的挑战，比如 cache 数据可能还没异步更新 db 的话，cache 服务可能就就挂掉了。</p><p>这种策略<font color="red">在平时开发过程中也非常非常少见</font>，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 Innodb Buffer Pool 机制都用到了这种策略。</p><p>Write Behind Pattern 下 db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。</p><h1 id="redis-基础"><a class="anchor" href="#redis-基础">#</a> Redis 基础</h1><h2 id="redis-是什么"><a class="anchor" href="#redis-是什么">#</a> Redis 是什么</h2><p><span class="exturl" data-url="aHR0cHM6Ly9yZWRpcy5pby8=">Redis</span>（<strong>RE</strong>mote <strong>DI</strong>ctionary <strong>S</strong>erver，远程词典服务器）是一个基于<font color="red"> C 语言</font>开发的开源 <font color="red">NoSQL</font> 数据库（BSD 许可）。与传统数据库不同的是，Redis 的数据是保存在内存中的（<strong><font color="red">内存数据库，支持持久化</font></strong>），因此<font color="red">读写速度非常快</font>，被广泛应用于<font color="red">分布式缓存</font>方向。并且，Redis 存储的是<font color="red"> Key-Value 键值对数据</font>。</p><p>为了满足不同的业务场景，Redis <font color="red">内置多种数据类型实现</font>（比如 String、Hash、Sorted Set、Bitmap、HyperLogLog、GEO）。并且，Redis 还<font color="red">支持事务、持久化、Lua 脚本、发布 / 订阅、缓存淘汰、流技术</font>等功能特性，提供了<font color="red">多种集群方案（主从模式、 <code>Redis Sentinel</code> 、 <code>Redis Cluster</code> ）</font>。</p><h2 id="redis-怎么用"><a class="anchor" href="#redis-怎么用">#</a> Redis 怎么用</h2><p>生产环境下，官方推荐使用 Linux 部署 Redis。</p><p>个人学习的话，可以自己本机安装 Redis 或者通过 Redis 官网提供的<span class="exturl" data-url="aHR0cHM6Ly90cnkucmVkaXMuaW8v">在线 Redis 环境</span>（少部分命令无法使用）来实际体验 Redis。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/try.redis.io.png" alt="try-redis"></p><p><span class="exturl" data-url="aHR0cHM6Ly90ZWNoc3RhY2tzLmlvLw==">techstacks.io</span> 专门维护了一个<span class="exturl" data-url="aHR0cHM6Ly90ZWNoc3RhY2tzLmlvL3RlY2gvcmVkaXM=">使用 Redis 的热门站点列表</span> ，感兴趣的话可以看看。</p><h2 id="redis-功能"><a class="anchor" href="#redis-功能">#</a> <mark>Redis 功能</mark></h2><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/Redis-v2-01-1.jpg" alt="img"></p><center>Redis 总体功能概览图</center><ul><li><p><strong><font color="orange">分布式缓存</font></strong>，帮 MySQL 减负</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231202180734903.png" alt="image-20231202180734903"></p><blockquote><p>MySQL 与 Redis 的对比：</p><ul><li>MySQL 是关系型数据库，Redis 是<font color="red">key-value</font>数据库（NoSQL 的一种）</li><li>MySQL 主要存储在磁盘，Redis 数据操作主要在<font color="red">内存</font></li><li>Redis 在一些场景中明显优于 MySQL，例如<font color="red">计数器、排行榜</font>等</li><li>Redis 通常用于一些特定场景，需要与 MySQL 一起配合使用，两者并不是相互替换和竞争关系，而是共用和<strong>配合使用</strong></li></ul></blockquote></li><li><p><strong>内存存储</strong>和<strong>持久化</strong>（ <code>RDB</code> + <code>AOF</code> ）：Redis 支持异步将内存中的数据写到硬盘上，同时不影响继续服务</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231202180535935.png" alt="image-20231202180535935"></p></li><li><p><strong>高可用架构搭配</strong>：避免某台 Redis 挂了后，影响系统运行</p><ul><li>单机</li><li>主从（replica）</li><li>哨兵（sentinel）</li><li>集群（cluster)</li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231202180648762.png" alt="image-20231202180648762"></p></li><li><p>缓存穿透、击穿、雪崩</p></li><li><p><strong>分布式锁</strong>：跨服务器加锁</p></li><li><p><strong>消息队列平台</strong>：Reids<font color="red">提供 list 和 set 操作</font>，这使得 Redis 能作为一个很好的消息队列平台来使用。</p><blockquote><p>通过 Reids 的队列功能做<strong>购买限制</strong>。比如到节假日或者推广期间，进行一些活动，对用户购买行为进行限制，限制今天只能购买几次商品或者一段时间内只能购买一次。</p></blockquote></li><li><p><strong>排行榜</strong> +<strong> 点赞</strong>：Redis 提供的<font color="red">zset 数据类型</font>能够快速实现这些复杂的排行榜。</p></li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230802155434366.png" alt="image-20230802155434366"></p><h2 id="redis-优势"><a class="anchor" href="#redis-优势">#</a> Redis 优势</h2><ul><li><strong>读写性能极高</strong></li><li><strong>数据类型丰富</strong>：不仅支持<font color="red">key-value</font>类型的数据，同时还提供<font color="red">list，set，zset，hash</font>等数据结构的存储</li><li><strong>支持数据持久化</strong>：可将内存中的数据存入磁盘中，重启时再加载到内存使用</li><li><strong>支持数据备份</strong>，即 master-slave 模式的数据备份</li></ul><h2 id="redis-迭代历史"><a class="anchor" href="#redis-迭代历史">#</a> Redis 迭代历史</h2><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230802161140294.png" alt="image-20230802161140294"></p><p><font color="red">5.0 版本</font>是直接升级到<font color="red">6.0 版本</font>，对于这个激进的升级，Redis 之父 antirez 表现得很有信心和兴奋，所以第一时间发文来阐述 6.0 的一些重大功能 &quot;Redis 6.0.0 GA is out!&quot;</p><p>随后 Redis 再接再厉，直接王炸<font color="red">Redis7.0</font>---2023 年爆款。2022 年 4 月 27 日 Redis 正式发布了 7.0 更新（其实早在 2022 年 1 月 31 日，Redis 已经预发布了 7.0rc-1，经过社区的考验后，确认没重大 Bug 才会正式发布）</p><p>Redis<strong> 版本的命名规则</strong>：</p><ul><li>版本号第二位如果是奇数，则为非稳定版本。如 2.7、2.9、3.1</li><li><font color="red">版本号第二位如果是偶数，则为稳定版本</font>。如 2.6、2.8、3.0、3.2</li><li>当前奇数版本就是下一个稳定版本的开发版本。如 2.9 版本是 3.0 版本的开发版本</li></ul><h2 id="redis7-新特性"><a class="anchor" href="#redis7-新特性">#</a> Redis7 新特性</h2><p>可以从 redis 的 GitHub 的 releases 中查看当前版本的新特性，Redis7 的部分新特性总览：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230802162007264.png" alt="image-20230802162007264"></p><ul><li><p>Redis Functions：Redis 函数，一种新的通过服务端脚本扩展 Redis 的方式，函数与数据本身一起存储。简言之，redis 自己要去<font color="red">抢夺 Lua 脚本的饭碗</font>，但是 Lua 已经稳定且普及，所以 Redis Functions<font color="red">没必要学</font></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230802162230304.png" alt="image-20230802162230304"></p></li><li><p><strong>Client-eviction</strong>：客户端相关优化，能让更多 client 连接上</p><p><font color="red">限制客户端内存使用</font>，一旦 Redis 连接较多，再加上每个连接的内存占用都比较大的时候，Redis 总连接内存占用可能会达到 maxmemory 的上限，可以增加允许限制所有客户端的总内存使用量配置项，redis.config 中对应的配置项，有两种配置形式：</p><ul><li><font color="red">指定内存大小</font>。例如 maxmemory-clients 1g</li><li><font color="red">基于 maxmemory 的百分比</font>。例如 maxmemory-clients 10%</li></ul><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230802162439869.png" alt="image-20230802162439869" style="zoom:80%"></li><li><p><strong>Multi-part AOF</strong>：多 AOF 文件支持，AOF 文件由一个变成了多个，主要分为两种类型：<font color="red">基本文件 (base files)</font>、<font color="red">增量文件 (incr files)</font>，请注意这些文件名称是复数形式说明每一类文件不仅仅只有一个。在此之外还引入了一个<font color="red">清单文件 (manifest) </font>用于跟踪文件以及文件的创建和应用顺序（恢复）。性能急剧上升，再也不用担心 AOFRW 异步读写时的运维痛点</p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230802163004405.png" alt="image-20230802163004405" style="zoom:80%"></li><li><p><strong>config 命令增强</strong>：对于<font color="red">Config Set 和 Get 命令</font>，支持在一次调用过程中<font color="red">传递多个配置参数</font>。例如，现在我们可以在执行一次 Config Set 命令中更改多个参数： config set maxmemory 10000001 maxmemory-clients 50% port 6399</p></li><li><p><strong>访问安全性增强 ACL V2</strong>：访问控制，在 redis.conf 配置文件中，<font color="red">protected-mode 默认为 yes</font>，只有当你希望你的客户端在没有授权的情况下可以连接到 Redis server 的时候可以将 protected-mode 设置为 no</p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230802163118585.png" alt="image-20230802163118585" style="zoom:80%"></li><li><p><strong>listpack 紧凑列表调整</strong>：listpack 是用来<font color="red">替代 ziplist 的新数据结构</font>，在 7.0 版本已经没有 ziplist 的配置了（6.0 版本仅部分数据类型作为过渡阶段在使用），listpack 已经替换了 ziplist 类似 hash-max-ziplist-entries 的配置</p></li><li><p>RDB 保存时间调整：将持久化文件 RDB 的保存规则发生了改变，尤其是时间记录频度变化</p></li><li><p>命令新增和变动：</p><ul><li>Zset (有序集合) 增加 ZMPOP、BZMPOP、ZINTERCARD 等命令</li><li>Set (集合) 增加 SINTERCARD 命令</li><li>LIST (列表) 增加 LMPOP、BLMPOP ，从提供的键名列表中的第一个非空列表键中弹出一个或多个元素</li></ul></li><li><p><strong>性能资源利用率、安全、等改进</strong>：自身<font color="red">底层部分优化</font>改动，Redis 核心在许多方面进行了重构和改进</p><ul><li><font color="red">主动碎片整理 V2</font>：增强版主动碎片整理，配合 Jemalloc 版本更新，更快更智能，延时更低</li><li><font color="red">HyperLogLog 改进</font>：在 Redis5.0 中，HyperLogLog 算法得到改进，优化了计数统计时的内存使用效率，7 更加优秀</li><li><font color="red">更好的内存统计报告</font></li><li>如果不为了 API 向后兼容，我们将<font color="red">不再使用 slave 一词</font>......(政治正确)</li></ul></li></ul><h2 id="redis-为什么这么快"><a class="anchor" href="#redis-为什么这么快">#</a> <mark>Redis 为什么这么快？</mark></h2><p>Redis 内部做了非常多的性能优化，比较重要的有下面 3 点：</p><ol><li>Redis <strong><font color="red">基于内存</font></strong>，内存的访问速度是磁盘的上千倍；</li><li>Redis 基于 Reactor 模式设计开发了 **<font color="red">一套高效的事件处理模型</font>**，主要是<font color="red">单线程事件循环</font>和<font color="red"> IO 多路复用</font>（Redis 线程模式后面会详细介绍到）；</li><li>Redis 内置了多种 **<font color="red">优化过后的数据类型 / 结构实现</font>**，性能非常高；</li></ol><blockquote><p>下面这张图片总结的挺不错的，分享一下，出自 <span class="exturl" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9hbGV4eHVieXRlL3N0YXR1cy8xNDk4NzAzODIyNTI4NTQ0Nzcw">Why is Redis so fast?</span></p></blockquote><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/why-redis-so-fast-E21l9uI2.png" alt="why-redis-so-fast"></p><h2 id="分布式缓存常见的技术选型方案"><a class="anchor" href="#分布式缓存常见的技术选型方案">#</a> 分布式缓存常见的技术选型方案</h2><p>分布式缓存的话，比较老牌同时也是使用的比较多的还是 <strong>Memcached</strong> 和 <strong>Redis</strong>。不过，<font color="red">现在基本没有看过还有项目使用 Memcached 来做缓存</font>，都是直接用 Redis。</p><p>Memcached 是分布式缓存最开始兴起的那会，比较常用的。后来，随着 Redis 的发展，大家慢慢都<font color="red">转而使用更加强大的 Redis 了</font>。</p><p>另外，腾讯也开源了一款类似于 Redis 的分布式高性能 KV 存储数据库，基于知名的开源项目 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZhY2Vib29rL3JvY2tzZGI=">RocksDB</span> 作为存储引擎 ，100% 兼容 Redis 协议和 Redis4.0 所有数据模型，名为 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1RlbmNlbnQvVGVuZGlz">Tendis</span>。</p><p>关于 Redis 和 Tendis 的对比，腾讯官方曾经发过一篇文章：<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvTWVZa2ZPSWRuVTZMWWxzR2IyNEtqUQ==">Redis vs Tendis：冷热混合存储版架构揭秘</span> ，可以简单参考一下。</p><p>从这个项目的 GitHub 提交记录可以看出，<font color="red">Tendis 开源版几乎已经没有被维护更新了，加上其关注度并不高，使用的公司也比较少</font>。因此，不建议你使用 Tendis 来实现分布式缓存。</p><h2 id="redis-和-memcached-的区别和共同点"><a class="anchor" href="#redis-和-memcached-的区别和共同点">#</a> Redis 和 Memcached 的区别和共同点</h2><p>现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！不过，了解 Redis 和 Memcached 的区别和共同点，有助于我们在做相应的技术选型的时候，能够做到有理有据！</p><p><strong>共同点</strong>：</p><ol><li><font color="red">都基于内存</font>，一般都用来当做缓存使用。</li><li><font color="red">都有过期策略</font>。</li><li><font color="red">性能都非常高</font>。</li></ol><p><strong>区别</strong>：</p><ol><li><strong><font color="red">Redis 支持更丰富的数据类型（支持更复杂的应用场景）</font></strong>。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 <font color="red">list，set，zset，hash</font> 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。</li><li><strong><font color="red">Redis 支持数据的持久化</font></strong>，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 把数据全部存在内存之中。</li><li><strong><font color="red">Redis 有灾难恢复机制</font></strong>。因为可以把缓存中的数据持久化到磁盘上。</li><li><strong>Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上</strong>。但是，Memcached 在服务器内存使用完之后，就会直接报异常。</li><li>Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 <strong>Redis 目前是原生支持 cluster 模式的。</strong></li><li>Memcached 是多线程，非阻塞 IO 复用的网络模型；<strong><font color="red">Redis 使用单线程的多路 IO 复用模型</font></strong>。（Redis 6.0 针对网络数据的读写引入了多线程）</li><li><strong>Redis 支持发布订阅模型、Lua 脚本、事务等功能</strong>，而 Memcached 不支持。并且，Redis 支持更多的编程语言。</li><li>Memcached 过期数据的删除策略只用了惰性删除，而 <strong>Redis 针对过期数据同时使用了惰性删除、定期删除。</strong></li></ol><p>相信看了上面的对比之后，我们已经没有什么理由可以选择使用 Memcached 来作为自己项目的分布式缓存了。</p><h2 id="为什么要用-redis或者缓存"><a class="anchor" href="#为什么要用-redis或者缓存">#</a> <mark>为什么要用 Redis（或者缓存）？</mark></h2><p>1、<strong><font color="red">高性能</font></strong></p><p>假如用户第一次访问数据库中的某些数据的话，这个过程是比较慢，毕竟是从硬盘中读取的。但是如果说，用户访问的数据属于高频数据并且不会经常改变的话，那么我们就可以很放心地<font color="red">将该用户访问的数据存在缓存中</font>。</p><p>这样有什么好处呢？那就是<font color="red">保证用户下一次再访问这些数据的时候，就可以直接从缓存中获取了</font>。操作缓存就是直接操作内存，所以速度相当快。</p><p>2、<strong><font color="red">高并发</font></strong></p><p>一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g），但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 Redis 的情况，Redis 集群的话会更高）。</p><blockquote><p><code>QPS（Query Per Second）</code> ：服务器每秒可以执行的查询次数；</p></blockquote><p>由此可见，<font color="red">直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的</font>，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高了系统整体的并发。</p><h2 id="常见的缓存读写策略"><a class="anchor" href="#常见的缓存读写策略">#</a> 常见的缓存读写策略</h2><p>指路→<a href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5%E6%9C%89%E5%93%AA%E5%87%A0%E7%A7%8D?">常见的缓存更新策略有哪几种？</a></p><h1 id="redis-应用"><a class="anchor" href="#redis-应用">#</a> Redis 应用</h1><h2 id="redis-除了做缓存还能做什么"><a class="anchor" href="#redis-除了做缓存还能做什么">#</a> Redis 除了做缓存，还能做什么？</h2><ul><li><p><strong><font color="red">分布式锁</font></strong>：通过 Redis 来做分布式锁是一种比较常见的方式。通常情况下，我们都是基于 <font color="red">Redisson</font> 来实现分布式锁。关于 Redis 实现分布式锁的详细介绍，可以看我写的这篇文章：<span class="exturl" data-url="aHR0cHM6Ly9qYXZhZ3VpZGUuY24vZGlzdHJpYnV0ZWQtc3lzdGVtL2Rpc3RyaWJ1dGVkLWxvY2suaHRtbA==">分布式锁详解</span>。</p></li><li><p><strong><font color="red">限流</font></strong>：一般是通过<font color="red"> Redis + Lua 脚本</font>的方式来实现限流。相关阅读：<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3Mva3lGQVdIM21WTkp2dXJRRHQ0dmNoQQ==">《我司用了 6 年的 Redis 分布式限流器，可以说是非常厉害了！》</span>。</p></li><li><p><strong><font color="red">消息队列</font></strong>：Redis 自带的 <font color="red">List</font> 数据结构可以作为一个简单的队列使用。Redis 5.0 中增加的 <font color="red">Stream</font> 类型的数据结构更加适合用来做消息队列。它比较<font color="red">类似于 Kafka，有主题和消费组的概念，支持消息持久化以及 ACK 机制</font>。</p></li><li><p><strong>延时队列</strong>：Redisson 内置了延时队列（基于 <font color="red">Sorted Set</font> 实现的）。</p></li><li><p><strong>分布式 Session</strong>：利用<font color="red"> String 或者 Hash </font>数据类型保存 Session 数据，所有的服务器都可以访问。</p></li><li><p><strong>复杂业务场景</strong>：通过 Redis 以及 Redis 扩展（比如 <font color="red">Redisson</font>）提供的数据结构，我们可以很方便地完成很多复杂的业务场景，比如<font color="red">通过 Bitmap 统计活跃用户、通过 Sorted Set 维护排行榜</font>。</p></li><li><p>…</p></li></ul><h2 id="redis-如何实现分布式锁"><a class="anchor" href="#redis-如何实现分布式锁">#</a> Redis 如何实现分布式锁？</h2><p>指路 -&gt;<span class="exturl" data-url="aHR0cHM6Ly9qYXZhZ3VpZGUuY24vZGlzdHJpYnV0ZWQtc3lzdGVtL2Rpc3RyaWJ1dGVkLWxvY2suaHRtbA=="> 分布式锁详解</span></p><h2 id="redis-可以做消息队列么"><a class="anchor" href="#redis-可以做消息队列么">#</a> Redis 可以做消息队列么？</h2><blockquote><p>实际项目中也没见谁使用 Redis 来做消息队列，对于这部分知识点大家了解就好了。</p></blockquote><p>先说结论：<strong><font color="red">可以是可以，但不建议使用 Redis 来做消息队列，因为它不如专业的消息队列</font></strong>。</p><h3 id="list-实现方式"><a class="anchor" href="#list-实现方式">#</a> List 实现方式</h3><p><strong>Redis 2.0 之前，如果想要使用 Redis 来做消息队列的话，只能通过 List 来实现。</strong></p><p>通过 <code>RPUSH/LPOP</code> 或者 <code>LPUSH/RPOP</code> 即可实现简易版消息队列：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 生产者生产消息</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token operator">></span> RPUSH myList msg1 msg2</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token operator">></span> RPUSH myList msg3</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">3</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># 消费者消费消息</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">></span> LPOP myList</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token string">"msg1"</span></pre></td></tr></table></figure><p>不过，通过 <code>RPUSH/LPOP</code> 或者 <code>LPUSH/RPOP</code> 这样的方式<font color="red">存在性能问题，需要不断轮询去调用 <code>RPOP</code> 或 <code>LPOP</code> 来消费消息</font>。当 List 为空时，大部分的轮询的请求都是无效请求，这种方式大量浪费了系统资源。</p><p>因此，Redis <font color="red">还提供了 <code>BLPOP</code> 、 <code>BRPOP</code> 这种阻塞式读取的命令</font>（带 B：Bloking 的都是阻塞式），并且还支持一个超时参数。<font color="red">如果 List 为空，Redis 服务端不会立刻返回结果</font>，它会等待 List 中有新数据后，再返回或者是等待最多一个超时时间后返回空。如果将超时时间设置为 0 时，即可无限等待，直到弹出消息。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 超时时间为 10s</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># 如果有数据则立刻返回，否则最多等待 10 秒</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> BRPOP myList <span class="token number">10</span></pre></td></tr><tr><td data-num="4"></td><td><pre>null</pre></td></tr></table></figure><p><strong><font color="red">List 实现消息队列功能太简单，像 <u>ACK 机制</u>等功能还需要我们自己实现，最要命的是没有<u>广播机制</u>，消息也只能被消费一次</font></strong>。</p><h3 id="发布订阅pubsub实现方式"><a class="anchor" href="#发布订阅pubsub实现方式">#</a> 发布订阅（pub/sub）实现方式</h3><p><strong>Redis 2.0 引入了发布订阅 (pub/sub) 功能，解决了 List 实现消息队列没有<u>广播机制</u>的问题。</strong></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-pub-sub.png" alt="Redis 发布订阅 (pub/sub) 功能"></p><center>Redis 发布订阅 (pub/sub) 功能</center><p>pub/sub 中引入了一个概念叫 <strong><font color="cornflowerblue">channel（频道）</font></strong>，发布订阅机制的实现就是基于这个 channel 来做的。</p><p>pub/sub 涉及两个角色：</p><ul><li><font color="cornflowerblue">发布者（Publisher）</font>：通过 <code>PUBLISH</code> 投递消息给指定 channel。</li><li><font color="cornflowerblue">订阅者（Subscriber，也叫消费者）</font>：通过 <code>SUBSCRIBE</code> 订阅它关心的 channel。并且，订阅者可以订阅一个或者多个 channel。</li></ul><p>这里启动 3 个 Redis 客户端来简单演示一下：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-pubsub-message-queue.png" alt="pub/sub 实现消息队列演示"></p><center>pub/sub 实现消息队列演示</center><p>pub/sub 既能单播又能广播，还支持 channel 的简单正则匹配。不过，<font color="red">消息丢失（客户端断开连接或者 Redis 宕机都会导致消息丢失）、消息堆积（发布者发布消息的时候不会管消费者的具体消费能力如何）等问题依然没有一个比较好的解决办法</font>。</p><h3 id="stream-实现方式"><a class="anchor" href="#stream-实现方式">#</a> Stream 实现方式</h3><p>为此，<font color="red">Redis 5.0</font> 新增加的一个数据结构 <code>Stream</code> 来做消息队列。 <code>Stream</code> 支持：</p><ul><li><font color="red">发布订阅（pub/sub）模式</font></li><li>按照<font color="red">消费者组</font>进行消费（借鉴了 Kafka 消费者组的概念）</li><li><font color="red">消息持久化（RDB 和 AOF）</font></li><li><font color="red">ACK 机制</font>（通过确认机制来告知已经成功处理了消息）</li><li><font color="red">阻塞式获取消息</font></li></ul><p><code>Stream</code> 的结构如下：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-stream-structure-ZjK8peV8.png" alt="img"></p><p><code>Stream</code> 使用起来相对要麻烦一些，这里就不演示了。而且，<font color="red"> <code>Stream</code> 在实际使用中依然会有一些小问题不太好解决</font>，比如在 Redis 发生故障恢复后不能保证消息至少被消费一次。</p><p><code>Stream</code> 被用作消息队列时，依赖于下面这些命令：</p><ul><li><code>XADD</code> ：向流中添加新的消息。</li><li><code>XREAD</code> ：从流中读取消息。</li><li><code>XREADGROUP</code> ：从消费组中读取消息。</li><li><code>XRANGE</code> ：根据消息 ID 范围读取流中的消息。</li><li><code>XREVRANGE</code> ：与 <code>XRANGE</code> 类似，但以相反顺序返回结果。</li><li><code>XDEL</code> ：从流中删除消息。</li><li><code>XTRIM</code> ：修剪流的长度，可以指定修建策略。</li><li><code>XLEN</code> ：获取流的长度。</li><li><code>XGROUP</code> ：管理消费组，包括创建、删除和修改。</li><li><code>XACK</code> ：确认消费组中的消息已被处理。</li><li><code>XPENDING</code> ：查询消费组中挂起（未确认）的消息。</li><li><code>XCLAIM</code> ：将挂起的消息从一个消费者转移到另一个消费者。</li><li><code>XINFO</code> ：获取流、消费组或消费者的详细信息。</li></ul><p>综上，和专业的消息队列相比，使用 Redis 来实现消息队列还是有很多欠缺的地方，比如<font color="red">消息丢失和堆积问题</font>不好解决。因此，我们<font color="red">通常建议不要使用 Redis 来做消息队列</font>，你完全可以选择市面上比较成熟的一些消息队列比如 RocketMQ、Kafka。不过，如果你就是想要用 Redis 来做消息队列的话，那我<font color="red">建议优先考虑 <code>Stream</code> </font>，这是目前相对最优的 Redis 消息队列实现。</p><p>相关阅读：<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvZ0NVVDVUY0NRUkF4WWtUSmZUUmpKdw==">Redis 消息队列发展历程 - 阿里开发者 - 2022</span>。</p><h1 id="redis-命令"><a class="anchor" href="#redis-命令">#</a> Redis 命令</h1><p>Redis 根据命令所操作对象的不同，可以分为三大类：</p><ul><li>对 Redis 进行基础性操作的命令</li><li>对 Key 的操作命令</li><li>对 Value 的操作命令</li></ul><h2 id="基础命令"><a class="anchor" href="#基础命令">#</a> 基础命令</h2><p>首先通过 <code>redis-cli</code> 命令进入到 Redis 命令行客户端，然后再运行下面的命令：</p><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td><code>PING</code></td><td><font color="red">心跳命令</font>，会看到 PONG 响应，则说明该客户端与 Redis 的连接是正常的。</td></tr><tr><td><code>SELECT</code> dbindex</td><td><font color="red">切换数据库</font>。Redis 默认有 16 个数据库，这个在 RDM 图形客户端中可以直观地看到。默认使用的是 0 号 DB，可以通过 select db 索引来切换 DB。</td></tr><tr><td><code>DBSIZE</code></td><td>查看当前数据库中 key 的数量</td></tr><tr><td><code>FLUSHDB</code></td><td>删除当前数据库中的数据</td></tr><tr><td><code>FLUSHALL</code></td><td>删除所有数据库中的数据</td></tr></tbody></table><p>使用 <code>exit</code> / <code>quit</code> 命令均可退出 Redis 命令行客户端。</p><h2 id="key-相关命令"><a class="anchor" href="#key-相关命令">#</a> key 相关命令</h2><p>因此，在介绍 Redis 中常用的 value 数据类型前，先介绍一下 key 相关的命令。</p><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td><code>DEL</code> key</td><td>key 存在时，删除 key</td></tr><tr><td><code>UNLINK</code> key</td><td>非阻塞删除 key，仅仅将 key 从 keyspace 元数据中删除，真正的删除会在后续异步中操作。</td></tr><tr><td>DUMP key</td><td>返回 key 被序列化后的值</td></tr><tr><td><code>EXISTS</code> key</td><td>检查 key 是否存在</td></tr><tr><td><code>EXPIRE</code> key seconds</td><td>以秒为单位，设置 key 的过期时间。<font color="red">默认 -1 表示永不过期</font>。（时间间隔）</td></tr><tr><td>PEXPIRE key milliseconds</td><td>以毫秒为单位，设置 key 过期时间。（时间间隔）</td></tr><tr><td><code>EXPIREAT</code> key timestamp</td><td>与 EXPIRE 类似，以秒为单位，不同点在于该命令接受的时间参数是 UNIX 时间戳（unix timestamp）<font color="red">（时刻）</font></td></tr><tr><td>PEXPIREAT key milliseconds-timestamp</td><td>以毫秒为单位，设置 key 过期时间的 UNIX 时间戳。<font color="red">（时刻）</font></td></tr><tr><td><code>KEYS</code> pattern</td><td>查找所有符合给定模式（pattern）的 key。例如 <code>KEYS *</code> 查看当前数据库的所有 key。</td></tr><tr><td><code>MOVE</code> key dbindex[0-15]</td><td>将当前数据库的 key 移动到指定数据库 [0-15] 中，默认为 0</td></tr><tr><td><code>SELECT</code> dbindex</td><td>切换到指定的数据库 [0-15]，默认为 0</td></tr><tr><td><code>DBSIZE</code></td><td>查看当前数据库的 key 数量</td></tr><tr><td><code>FLUSHDB</code></td><td>清空当前库</td></tr><tr><td><code>FLUSHALL</code></td><td>通杀所有库</td></tr><tr><td><code>PERSIST</code> key</td><td>持久保持 key，移除其过期时间</td></tr><tr><td><code>TTL</code> key</td><td>以秒为单位，返回 key 的剩余生存时间（TTL，time to live）。<font color="red">其中 -1 表示永不过期，-2 表示已过期</font>。</td></tr><tr><td>PTTL key</td><td>以毫秒为单位，返回 key 的剩余生存时间</td></tr><tr><td>RANDOMKEY</td><td>从当前数据库中随机返回一个 key</td></tr><tr><td>RENAME key newkey</td><td>将 key 改名为 newkey</td></tr><tr><td>RENAMENX key newkey</td><td>仅当 newkey 不存在时，将 key 改名为 newkey</td></tr><tr><td><code>TYPE</code> key</td><td>返回 key 所存储<font color="red"> value 的数据类型</font></td></tr></tbody></table><h1 id="redis-数据类型"><a class="anchor" href="#redis-数据类型">#</a> <mark>🌟Redis 数据类型</mark></h1><p>前文已声明过 Redis 是基于 Key-Value 的，而 <strong><font color="orange">key 类型一般是 String，这里所介绍的数据类型指的是 value 的数据类型</font></strong>。</p><h2 id="常用数据类型"><a class="anchor" href="#常用数据类型">#</a> <mark>🌟常用数据类型</mark></h2><blockquote><p>更多 Redis value 数据类型 命令以及详细使用指南，请查看 Redis 官网对应的介绍：<span class="exturl" data-url="aHR0cHM6Ly9yZWRpcy5pby9jb21tYW5kcw==">https://redis.io/commands</span></p></blockquote><p>Redis 中比较常见的数据类型有下面这些：</p><ul><li><strong><font color="red">5 种基础数据类型</font></strong>： <code>String</code> （字符串）、 <code>List</code> （列表）、 <code>Set</code> （集合）、 <code>Hash</code> （散列）、 <code>Zset</code> （有序集合）。</li><li><strong><font color="red">3 种特殊数据类型</font></strong>： <code>HyperLogLog</code> （基数统计）、 <code>Bitmap</code> （位图）、 <code>Geospatial</code> (地理位置)。</li></ul><p>除了上面提到的之外，还有一些其他的比如 <a target="_blank" rel="noopener" href="https://javaguide.cn/cs-basics/data-structure/bloom-filter.html"><code>Bloom filter</code> （布隆过滤器）</a>、 <code>Bitfield</code> （位域）。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231203143049962.png" alt="image-20231203143049962"></p><h3 id="5-种基础数据类型"><a class="anchor" href="#5-种基础数据类型">#</a> 5 种基础数据类型</h3><p>Redis 共有 5 种基本数据类型：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。</p><p>这 5 种数据类型是直接提供给用户使用的，是数据的保存形式，其底层实现主要依赖这 8 种数据结构：简单动态字符串（ <code>SDS</code> ）、 <code>LinkedList</code> （双向链表）、 <code>Dict</code> （哈希表 / 字典）、 <code>SkipList</code> （跳跃表）、 <code>Intset</code> （整数集合）、 <code>ZipList</code> （压缩列表）、 <code>QuickList</code> （快速列表）。</p><p>**<font color="red">5 种基本数据类型对应的底层数据结构</font>** 实现如下表所示：</p><table><thead><tr><th style="text-align:left">String</th><th style="text-align:left">List</th><th style="text-align:left">Hash</th><th style="text-align:left">Set</th><th style="text-align:left">Zset</th></tr></thead><tbody><tr><td style="text-align:left">SDS</td><td style="text-align:left">LinkedList/ZipList/QuickList</td><td style="text-align:left">Dict、ZipList</td><td style="text-align:left">Dict、Intset</td><td style="text-align:left">ZipList、SkipList</td></tr></tbody></table><p>Redis 3.2 之前，List 底层实现是 LinkedList 或者 ZipList。 Redis 3.2 之后，引入了 LinkedList 和 ZipList 的结合 QuickList，List 的底层实现变为 QuickList。从 Redis 7.0 开始， ZipList 被 ListPack 取代。</p><p>你可以在 Redis 官网上找到 Redis 数据类型 / 结构非常详细的介绍：</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly9yZWRpcy5jb20vcmVkaXMtZW50ZXJwcmlzZS9kYXRhLXN0cnVjdHVyZXMv">Redis Data Structures</span></li><li><span class="exturl" data-url="aHR0cHM6Ly9yZWRpcy5pby9kb2NzL21hbnVhbC9kYXRhLXR5cGVzL2RhdGEtdHlwZXMtdHV0b3JpYWwv">Redis Data types tutorial</span></li></ul><p>未来随着 Redis 新版本的发布，可能会有新的数据结构出现，通过查阅 Redis 官网对应的介绍，你总能获取到最靠谱的信息。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20220720181630203.png" alt="img"></p><h4 id="string字符串"><a class="anchor" href="#string字符串">#</a> String（字符串）</h4><h5 id="介绍"><a class="anchor" href="#介绍">#</a> 介绍</h5><p>String 是 Redis 中<font color="red">最简单、最常用</font>的一个数据类型。</p><p>String 是一种 **<font color="red">二进制安全</font>** 的数据类型，<font color="red">可以用来存储任何类型的数据</font>，比如字符串、整数、浮点数、图片（图片的 base64 编码或者解码或者图片的路径）、序列化后的对象。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20220719124403897.png" alt="img"></p><p>虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 <strong><font color="red">简单动态字符串</font></strong>（Simple Dynamic String， <code>SDS</code> ）。相比于 C 的原生字符串，Redis 的 <font color="red">SDS 不光可以保存文本数据，还可以保存二进制数据，并且获取字符串长度复杂度为 O (1)</font>（C 字符串为 O (N)）。此外，Redis 的 <font color="red">SDS API 是安全的，不会造成缓冲区溢出</font>。</p><h5 id="命令"><a class="anchor" href="#命令">#</a> 命令</h5><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td>SET key value</td><td>设置指定 key 的值</td></tr><tr><td><code>SETNX</code> key value</td><td>只有在<font color="red"> key 不存在时</font>设置 key 的值</td></tr><tr><td>GET key</td><td>获取指定 key 的值</td></tr><tr><td><code>MSET</code> key1 value1 key2 value2 ……</td><td>设置一个或<font color="red">多个</font>指定 key 的值</td></tr><tr><td>MGET key1 key2 ...</td><td>获取一个或多个指定 key 的值</td></tr><tr><td><code>STRLEN</code> key</td><td>返回 key 所储存的<font color="red">字符串值的长度</font></td></tr><tr><td><code>INCR</code> key</td><td>将 key 中储存的数字值增一</td></tr><tr><td><code>DECR</code> key</td><td>将 key 中储存的数字值减一</td></tr><tr><td>EXISTS key</td><td>判断指定 key 是否存在</td></tr><tr><td><code>DEL</code> key（通用）</td><td>删除指定的 key</td></tr><tr><td><code>EXPIRE</code> key seconds（通用）</td><td>给指定 key 设置过期时间</td></tr></tbody></table><p><strong>基本操作</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> SET key value</pre></td></tr><tr><td data-num="2"></td><td><pre>OK</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> GET key</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">"value"</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> EXISTS key</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">></span> STRLEN key</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">5</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token operator">></span> DEL key</pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token operator">></span> GET key</pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token punctuation">(</span>nil<span class="token punctuation">)</span></pre></td></tr></table></figure><p><strong>批量设置</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> MSET key1 value1 key2 value2</pre></td></tr><tr><td data-num="2"></td><td><pre>OK</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> MGET key1 key2 <span class="token comment"># 批量获取多个 key 对应的 value</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"value1"</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"value2"</span></pre></td></tr></table></figure><p><strong>计数器（字符串的内容为整数的时候可以使用）：</strong></p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> SET number <span class="token number">1</span></pre></td></tr><tr><td data-num="2"></td><td><pre>OK</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> INCR number <span class="token comment"># 将 key 中储存的数字值增一</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> GET number</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token string">"2"</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">></span> DECR number <span class="token comment"># 将 key 中储存的数字值减一</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token operator">></span> GET number</pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token string">"1"</span></pre></td></tr></table></figure><p><strong>设置过期时间（默认为永不过期）</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> EXPIRE key <span class="token number">60</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> SETEX key <span class="token number">60</span> value <span class="token comment"># 设置值并设置过期时间</span></pre></td></tr><tr><td data-num="4"></td><td><pre>OK</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> TTL key</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">56</span></pre></td></tr></table></figure><h5 id="string-应用"><a class="anchor" href="#string-应用">#</a> String 应用</h5><p><strong><font color="red">常规数据的缓存</font></strong></p><ul><li>举例：缓存 Session、Token、图片地址、序列化后的对象 (相比较于 Hash 存储更节省内存)。</li><li>相关命令： <code>SET</code> 、 <code>GET</code> 。</li></ul><p><strong>需要<font color="red">计数</font>的场景</strong></p><ul><li>举例：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。</li><li>相关命令： <code>SET</code> 、 <code>GET</code> 、 <code>INCR</code> 、 <code>DECR</code> 。</li></ul><p><strong><font color="red">分布式锁</font></strong></p><p>利用 <code>SETNX key value</code> 命令可以实现一个最简易的分布式锁（存在一些缺陷，通常不建议这样实现分布式锁）。</p><h4 id="list列表"><a class="anchor" href="#list列表">#</a> List（列表）</h4><h5 id="介绍-2"><a class="anchor" href="#介绍-2">#</a> 介绍</h5><p>Redis 中的 List 其实就是<font color="red">链表数据结构的实现</font>。我在 <span class="exturl" data-url="aHR0cHM6Ly9qYXZhZ3VpZGUuY24vY3MtYmFzaWNzL2RhdGEtc3RydWN0dXJlL2xpbmVhci1kYXRhLXN0cnVjdHVyZS5odG1s">线性数据结构：数组、链表、栈、队列</span> 这篇文章中详细介绍了链表这种数据结构，我这里就不多做介绍了。</p><p>许多高级编程语言都内置了链表的实现比如 Java 中的 <code>LinkedList</code> ，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 List 的实现为一个 **<font color="#B32015">双向链表</font>**，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20220719124413287.png" alt="img"></p><h5 id="命令-2"><a class="anchor" href="#命令-2">#</a> 命令</h5><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td><code>RPUSH</code> key value1 value2 ...</td><td>在指定列表的尾部（右边）添加一个或多个元素</td></tr><tr><td>LPUSH key value1 value2 ...</td><td>在指定列表的头部（左边）添加一个或多个元素</td></tr><tr><td><code>LSET</code> key index value</td><td>将指定列表索引 index 位置的值设置为 value</td></tr><tr><td><code>RPOP</code> key</td><td>移除并获取指定列表的最后一个元素 (最右边)</td></tr><tr><td>LPOP key</td><td>移除并获取指定列表的第一个元素 (最左边)</td></tr><tr><td><code>LLEN</code> key</td><td>获取列表元素数量</td></tr><tr><td><code>LRANGE</code> key start end</td><td>获取列表 start 和 end 之间 的元素</td></tr></tbody></table><p>通过 <code>RPUSH/LPOP</code> 或者 <code>LPUSH/RPOP</code> <strong>实现队列（先进先出）</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> RPUSH myList value1</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> RPUSH myList value2 value3</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">3</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> LPOP myList</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token string">"value1"</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">></span> LRANGE myList <span class="token number">0</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"value2"</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"value3"</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token operator">></span> LRANGE myList <span class="token number">0</span> <span class="token parameter variable">-1</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"value2"</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"value3"</span></pre></td></tr></table></figure><p>通过 <code>RPUSH/RPOP</code> 或者 <code>LPUSH/LPOP</code> <strong>实现栈（先进后出）</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> RPUSH myList2 value1 value2 value3</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">3</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> RPOP myList2 <span class="token comment"># 将 list 的最右边的元素取出</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">"value3"</span></pre></td></tr></table></figure><p>我专门画了一个图方便大家理解 <code>RPUSH</code> , <code>LPOP</code> , <code>lpush</code> , <code>RPOP</code> 命令：</p><p><img data-src="https://oss.javaguide.cn/github/javaguide/database/redis/redis-list.png" alt="img"></p><p>通过 <code>LRANGE</code> <strong>查看对应下标范围的列表元素</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> RPUSH myList value1 value2 value3</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">3</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> LRANGE myList <span class="token number">0</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"value1"</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"value2"</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token operator">></span> LRANGE myList <span class="token number">0</span> <span class="token parameter variable">-1</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"value1"</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"value2"</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token number">3</span><span class="token punctuation">)</span> <span class="token string">"value3"</span></pre></td></tr></table></figure><p>通过 <code>LRANGE</code> 命令，你可以<font color="red">基于 List 实现分页查询</font>，性能非常高！</p><p>通过 <code>LLEN</code> <strong>查看链表长度</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> LLEN myList</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">3</span></pre></td></tr></table></figure><h5 id="应用"><a class="anchor" href="#应用">#</a> 应用</h5><p><strong>信息流展示</strong></p><ul><li>举例：最新文章、最新动态。</li><li>相关命令： <code>LPUSH</code> 、 <code>LRANGE</code> 。</li></ul><p><strong>消息队列</strong></p><p><code>List</code> 可以用来做消息队列，只是<font color="red">功能过于简单且存在很多缺陷</font>，不建议这样做。</p><p>相对来说，Redis 5.0 新增加的一个数据结构 <code>Stream</code> 更适合做消息队列一些，只是功能依然非常简陋。和专业的消息队列相比，还是有很多欠缺的地方比如<font color="red">消息丢失和堆积问题</font>不好解决。</p><h4 id="hash哈希"><a class="anchor" href="#hash哈希">#</a> Hash（哈希）</h4><h5 id="介绍-3"><a class="anchor" href="#介绍-3">#</a> 介绍</h5><p>Redis 中的 Hash 是一个<font color="red"> String 类型的 field-value（键值对） </font>的映射表，特别适合用于<font color="red">存储对象</font>，后续操作的时候，你可以直接修改这个对象中的某些字段的值。</p><p>Hash 类似于 JDK1.8 前的 <code>HashMap</code> ，内部实现也差不多 (<font color="red">数组 + 链表</font>)。不过，Redis 的 Hash 做了更多优化。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20220719124421703.png" alt="img"></p><h5 id="命令-3"><a class="anchor" href="#命令-3">#</a> 命令</h5><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td><code>HSET</code> key field value</td><td>将指定哈希表 key 中指定字段 field 的值设置为 value</td></tr><tr><td>HSETNX key field value</td><td>仅当指定字段 field 不存在时，设置其值</td></tr><tr><td><code>HMSET</code> key field1 value1 field2 value2 ...</td><td>同时将一个或<font color="red">多个</font> field-value (域 - 值) 对设置到指定哈希表 key 中</td></tr><tr><td>HGET key field</td><td>获取指定哈希表中指定字段的<font color="red">值</font></td></tr><tr><td>HMGET key field1 field2 ...</td><td>获取指定哈希表中一个或者多个指定字段的<font color="red">值</font></td></tr><tr><td><code>HGETALL</code> key</td><td>获取指定哈希表 key 中所有的 **<font color="red">键值对</font>**</td></tr><tr><td><code>HEXISTS</code> key field</td><td>查看指定哈希表中指定的字段是否存在</td></tr><tr><td><code>HDEL</code> key field1 field2 ...</td><td>删除一个或多个哈希表字段</td></tr><tr><td><code>HLEN</code> key</td><td>获取指定哈希表中字段的数量</td></tr><tr><td><code>HINCRBY</code> key field increment</td><td>对指定哈希中的指定字段做运算操作（正数为加，负数为减）</td></tr></tbody></table><p><strong>模拟对象数据存储</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> HMSET userInfoKey name <span class="token string">"guide"</span> description <span class="token string">"dev"</span> age <span class="token number">24</span></pre></td></tr><tr><td data-num="2"></td><td><pre>OK</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> HEXISTS userInfoKey name <span class="token comment"># 查看 key 对应的 value 中指定的字段是否存在。</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> HGET userInfoKey name <span class="token comment"># 获取存储在哈希表中指定字段的值。</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token string">"guide"</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">></span> HGET userInfoKey age</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token string">"24"</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token operator">></span> HGETALL userInfoKey <span class="token comment"># 获取在哈希表中指定 key 的所有字段和值</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"name"</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"guide"</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token number">3</span><span class="token punctuation">)</span> <span class="token string">"description"</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token number">4</span><span class="token punctuation">)</span> <span class="token string">"dev"</span></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token number">5</span><span class="token punctuation">)</span> <span class="token string">"age"</span></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token number">6</span><span class="token punctuation">)</span> <span class="token string">"24"</span></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token operator">></span> HSET userInfoKey name <span class="token string">"GuideGeGe"</span></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token operator">></span> HGET userInfoKey name</pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token string">"GuideGeGe"</span></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token operator">></span> HINCRBY userInfoKey age <span class="token number">2</span></pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">26</span></pre></td></tr></table></figure><h5 id="应用-2"><a class="anchor" href="#应用-2">#</a> 应用</h5><p><strong><font color="#B32015">对象数据存储场景</font></strong></p><ul><li>举例：用户信息、商品信息、文章信息、购物车信息。</li><li>相关命令： <code>HSET</code> （设置单个字段的值）、 <code>HMSET</code> （设置多个字段的值）、 <code>HGET</code> （获取单个字段的值）、 <code>HMGET</code> （获取多个字段的值）。</li></ul><h4 id="set集合"><a class="anchor" href="#set集合">#</a> Set（集合）</h4><h5 id="介绍-4"><a class="anchor" href="#介绍-4">#</a> 介绍</h5><p>Redis 中的 Set 类型是一种无序集合，集合中的 **<font color="red">元素没有先后顺序，但都唯一（不重复）</font>**，有点类似于 Java 中的 <code>HashSet</code> 。当你需要存储一个列表数据，又不希望出现重复数据时，Set 是一个很好的选择，并且 Set 提供了判断某个元素是否在一个 Set 集合内的重要接口，这个也是 List 所不能提供的。</p><p>你可以基于 Set 轻易实现<font color="red">交集、并集、差集</font>的操作，比如你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。这样的话，Set 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20220719124430264.png" alt="img"></p><h5 id="命令-4"><a class="anchor" href="#命令-4">#</a> 命令</h5><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td><code>SADD</code> key member1 member2 ...</td><td>向指定集合添加一个或多个元素</td></tr><tr><td><code>SMEMBERS</code> key</td><td>获取指定集合中的所有元素</td></tr><tr><td><code>SCARD</code> key</td><td>获取指定集合的元素数量</td></tr><tr><td><code>SISMEMBER</code> key member</td><td>判断指定元素是否在指定集合中</td></tr><tr><td><code>SINTER</code> key1 key2 ...</td><td>获取给定所有集合的交集</td></tr><tr><td>SINTERSTORE destination key1 key2 ...</td><td>将给定所有集合的交集存储在 destination 中</td></tr><tr><td><code>SUNION</code> key1 key2 ...</td><td>获取给定所有集合的并集</td></tr><tr><td>SUNIONSTORE destination key1 key2 ...</td><td>将给定所有集合的并集存储在 destination 中</td></tr><tr><td><code>SDIFF</code> key1 key2 ...</td><td>获取给定所有集合的差集</td></tr><tr><td>SDIFFSTORE destination key1 key2 ...</td><td>将给定所有集合的差集存储在 destination 中</td></tr><tr><td><code>SPOP</code> key count</td><td>随机移除并获取指定集合中一个或多个元素</td></tr><tr><td><code>SRANDMEMBER</code> key count</td><td>随机获取指定集合中指定数量的元素</td></tr></tbody></table><p><strong>基本操作</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> SADD mySet value1 value2</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> SADD mySet value1 <span class="token comment"># 不允许有重复元素，因此添加失败</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> SMEMBERS mySet</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"value1"</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"value2"</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token operator">></span> SCARD mySet</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token operator">></span> SISMEMBER mySet value1</pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token operator">></span> SADD mySet2 value2 value3</pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr></table></figure><ul><li><code>mySet</code> : <code>value1</code> 、 <code>value2</code></li><li><code>mySet2</code> ： <code>value2</code> 、 <code>value3</code></li></ul><p><strong>求交集</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> SINTERSTORE mySet3 mySet mySet2</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> SMEMBERS mySet3</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"value2"</span></pre></td></tr></table></figure><p><strong>求并集</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> SUNION mySet mySet2</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"value3"</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"value2"</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">3</span><span class="token punctuation">)</span> <span class="token string">"value1"</span></pre></td></tr></table></figure><p><strong>求差集</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> SDIFF mySet mySet2 <span class="token comment"># 差集是由所有属于 mySet 但不属于 A 的元素组成的集合</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"value1"</span></pre></td></tr></table></figure><h5 id="set-应用"><a class="anchor" href="#set-应用">#</a> Set 应用</h5><p><strong>需要存放的<font color="red">数据不能重复</font>的场景</strong></p><ul><li>举例：<font color="red">网站 UV （Unique Visitor，独立访客）统计</font>（数据量巨大的场景还是 <code>HyperLogLog</code> 更适合一些）、<font color="red">点赞数统计</font>等场景。</li><li>相关命令： <code>SCARD</code> （获取集合数量）。</li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20220719073733851.png" alt="img"></p><p><strong>需要获取多个数据源<font color="red">交集、并集和差集</font>的场景</strong></p><ul><li>举例：共同好友 (交集)、共同粉丝 (交集)、共同关注 (交集)、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集 + 交集） 等场景。</li><li>相关命令： <code>SINTER</code> （交集）、 <code>SINTERSTORE</code> （交集）、 <code>SUNION</code> （并集）、 <code>SUNIONSTORE</code> （并集）、 <code>SDIFF</code> （差集）、 <code>SDIFFSTORE</code> （差集）。</li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20220719074543513.png" alt="img"></p><p><strong>需要<font color="red">随机获取数据源中的元素</font>的场景</strong></p><ul><li>举例：<font color="red">抽奖系统、随机点名</font>等场景。</li><li>相关命令： <code>SPOP</code> （随机获取集合中的元素并移除，适合<font color="red">不允许重复中奖</font>的场景）、 <code>SRANDMEMBER</code> （随机获取集合中的元素，适合<font color="red">允许重复中奖</font>的场景）。</li></ul><h4 id="sorted-setzset有序集合"><a class="anchor" href="#sorted-setzset有序集合">#</a> Sorted Set/Zset（有序集合）</h4><h5 id="介绍-5"><a class="anchor" href="#介绍-5">#</a> 介绍</h5><p>Sorted Set 也称 Zset，和 Set 相比 **<font color="red">增加了一个权重参数</font>** <code>score</code> ，使得集合中的元素能够按 <code>score</code> 进行 **<font color="red">有序排列</font>**，还可以通过 <code>score</code> 的范围来获取元素的列表。有点像是 Java 中 <code>HashMap</code> 和 <code>TreeSet</code> 的结合体。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20220719124437791.png" alt="img"></p><h5 id="命令-5"><a class="anchor" href="#命令-5">#</a> 命令</h5><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td><code>ZADD</code> key score1 member1 score2 member2 ...</td><td>向指定有序集合添加一个或多个元素</td></tr><tr><td><code>ZCARD</code> KEY</td><td>获取指定有序集合的元素数量</td></tr><tr><td><code>ZSCORE</code> key member</td><td>获取指定有序集合中指定元素的 score 值</td></tr><tr><td><code>ZINTERSTORE</code> destination numkeys key1 key2 ...</td><td>将给定所有有序集合的交集存储在 destination 中，<strong><font color="red">对相同元素对应的 score 值进行 SUM 聚合操作</font></strong>，<font color="red">numkeys 为集合数量</font></td></tr><tr><td><code>ZUNIONSTORE</code> destination numkeys key1 key2 ...</td><td>求并集，其它和 ZINTERSTORE 类似</td></tr><tr><td><code>ZDIFFSTORE</code> destination numkeys key1 key2 ...</td><td>求差集，其它和 ZINTERSTORE 类似</td></tr><tr><td><code>ZRANGE</code> key start end</td><td>获取指定有序集合 start 和 end 之间的元素（<font color="red">score 从低到高</font>）</td></tr><tr><td><code>ZREVRANGE</code> key start end</td><td>获取指定有序集合 start 和 end 之间的元素（<font color="red">score 从高到底</font>）</td></tr><tr><td><code>ZREVRANK</code> key member</td><td>获取指定有序集合中指定元素的排名 (<font color="red">score 从大到小排序</font>)</td></tr></tbody></table><p><strong>基本操作</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> ZADD myZset <span class="token number">2.0</span> value1 <span class="token number">1.0</span> value2</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> ZCARD myZset</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">2</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> ZSCORE myZset value1</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token number">2.0</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">></span> ZRANGE myZset <span class="token number">0</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"value2"</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"value1"</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token operator">></span> ZREVRANGE myZset <span class="token number">0</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"value1"</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"value2"</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token operator">></span> ZADD myZset2 <span class="token number">4.0</span> value2 <span class="token number">3.0</span> value3</pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr></table></figure><ul><li><code>myZset</code> : <code>value1</code> (2.0)、 <code>value2</code> (1.0) 。</li><li><code>myZset2</code> ： <code>value2</code> （4.0）、 <code>value3</code> (3.0) 。</li></ul><p><strong>获取指定元素的排名</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> ZREVRANK myZset value1</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">0</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> ZREVRANK myZset value2</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">1</span></pre></td></tr></table></figure><p><strong>求交集</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> ZINTERSTORE myZset3 <span class="token number">2</span> myZset myZset2</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> ZRANGE myZset3 <span class="token number">0</span> <span class="token number">1</span> WITHSCORES</pre></td></tr><tr><td data-num="4"></td><td><pre>value2</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">5</span></pre></td></tr></table></figure><p><strong>求并集</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> ZUNIONSTORE myZset4 <span class="token number">2</span> myZset myZset2</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">3</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> ZRANGE myZset4 <span class="token number">0</span> <span class="token number">2</span> WITHSCORES</pre></td></tr><tr><td data-num="4"></td><td><pre>value1</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">2</span></pre></td></tr><tr><td data-num="6"></td><td><pre>value3</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token number">3</span></pre></td></tr><tr><td data-num="8"></td><td><pre>value2</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token number">5</span></pre></td></tr></table></figure><p><strong>求差集</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> ZDIFF <span class="token number">2</span> myZset myZset2 WITHSCORES</pre></td></tr><tr><td data-num="2"></td><td><pre>value1</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2</span></pre></td></tr></table></figure><h5 id="zset-应用"><a class="anchor" href="#zset-应用">#</a> Zset 应用</h5><p><strong>需要<font color="red">根据某个权重对元素进行排序（排行榜）</font>的场景</strong></p><ul><li>举例：各种排行榜比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等。</li><li>相关命令： <code>ZRANGE</code> (从小到大排序)、 <code>ZREVRANGE</code> （从大到小排序）、 <code>ZREVRANK</code> (获取指定元素的排名)。</li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/2021060714195385.png" alt="img"></p><hr><p>Sorted Set 能够轻松应对百万级别的用户数据排序，简直就是专门为排行榜设计的数据结构！下面详细介绍一下如何使用 Sorted Set 来设计制作一个排行榜：</p><table><thead><tr><th>User</th><th>Score</th></tr></thead><tbody><tr><td>user1</td><td>112.0</td></tr><tr><td>user2</td><td>100.0</td></tr><tr><td>user3</td><td>123.0</td></tr><tr><td>user4</td><td>100.0</td></tr><tr><td>user5</td><td>33.0</td></tr><tr><td>user6</td><td>993.0</td></tr></tbody></table><p>把上表中的数据添加到 Sorted Set 中：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 通过 zadd 命令添加了 6 个元素到 cus_order_set 中</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZADD cus_order_set <span class="token number">112.0</span> user1 <span class="token number">100.0</span> user2 <span class="token number">123.0</span> user3 <span class="token number">100.0</span> user4 <span class="token number">33.0</span> user5 <span class="token number">993.0</span> user6</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">6</span></pre></td></tr></table></figure><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/up-c25cf4cc1d4d3a484b4db93672138b8c104.png" alt="img"></p><p><strong>查看包含所有用户的排行榜：</strong> 通过 ZRANGE (从小到大排序) / ZREVRANGE （从大到小排序）</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># -1 代表的是全部的用户数据，</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZREVRANGE cus_order_set <span class="token number">0</span> <span class="token parameter variable">-1</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"user6"</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"user3"</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">3</span><span class="token punctuation">)</span> <span class="token string">"user1"</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token number">4</span><span class="token punctuation">)</span> <span class="token string">"user4"</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token number">5</span><span class="token punctuation">)</span> <span class="token string">"user2"</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token number">6</span><span class="token punctuation">)</span> <span class="token string">"user5"</span></pre></td></tr></table></figure><p><strong>查看只包含前 3 名的排行榜:</strong> 限定范围区间即可。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 0 为 start  2 为 stop</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZREVRANGE cus_order_set <span class="token number">0</span> <span class="token number">2</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"user6"</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"user3"</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">3</span><span class="token punctuation">)</span> <span class="token string">"user1"</span></pre></td></tr></table></figure><p><strong>查询某个用户的分数:</strong> 通过 <code>ZSCORE</code> 命令即可。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZSCORE  cus_order_set <span class="token string">"user1"</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">"112"</span></pre></td></tr></table></figure><p><strong>查询某个用户的排名:</strong> 通过 <code>ZREVRANK</code> 命令即可。</p><pre><code class="language-bahs">127.0.0.1:6379&gt; ZREVRANK  cus_order_set &quot;user3&quot;
(integer) 1 # user3 排名第2
</code></pre><p><strong>对用户的排名数据进行更新:</strong> 通过 <code>ZINCRBY</code> 命令即可。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 对 user1 的分数加 2</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZINCRBY cus_order_set +2 <span class="token string">"user1"</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token string">"114"</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># 对 user1 的分数减 1</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZINCRBY cus_order_set <span class="token parameter variable">-1</span> <span class="token string">"user1"</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token string">"113"</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment"># 查看 user1 的分数</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZSCORE  cus_order_set <span class="token string">"user1"</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token string">"113"</span></pre></td></tr></table></figure><p>除了我上面提到的之外，还有一些其他的命令来帮助你解决更多排行榜场景的需求，想要深入研究的小伙伴可以仔细学习哦！</p><p>不过，需要注意的一点是：<strong><font color="red">Redis 中只保存了排行榜展示所需的数据，需要用户的具体信息数据的话，还是需要去对应的数据库（比如 MySQL）中查。</font></strong></p><p>你以为这样就完事了？ 不存在的！还有一些无法仅仅通过 Redis 提供的命令解决的场景。</p><p>比如，<strong>如何实现多条件排序？</strong> 其实，答案也比较简单，对于大部分场景，我们直接对 score 值做文章即可。</p><p>更具体点的话就是，我们<font color="red">根据特定的条件来拼接 score 值即可</font>。比如我们还要加上时间先后条件的话，直接在 score 值添加上时间戳即可。</p><p>再比如，<strong>如何实现指定日期（比如最近 7 天）的用户数据排序？</strong></p><p>我说一种比较简单的方法：我们把每一天的数据都按照日期为名字，比如 20350305 就代表 2035 年 3 月 5 号。</p><p>如果我们需要查询最近 n 天的排行榜数据的话，直接 ZUNIONSTORE 来求 n 个 <code>sorted set</code> 的并集即可。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>ZUNIONSTORE last_n_days n <span class="token number">20350305</span> <span class="token number">20350306</span><span class="token punctuation">..</span><span class="token punctuation">..</span></pre></td></tr></table></figure><p>我不知道大家看懂了没有，我这里还是简单地造一些数据模拟一下吧！</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 分别添加了 3 天的数据</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZADD <span class="token number">20350305</span> <span class="token number">112.0</span> user1 <span class="token number">100.0</span> user2 <span class="token number">123.0</span> user3</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">3</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZADD <span class="token number">20350306</span> <span class="token number">100.0</span> user4</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZADD <span class="token number">20350307</span> <span class="token number">33.0</span> user5 <span class="token number">993.0</span> user6</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr></table></figure><p>通过 ZUNIONSTORE 命令来查看最近 3 天的排行榜情况：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZUNIONSTORE last_n_days <span class="token number">3</span> <span class="token number">20350305</span> <span class="token number">20350306</span> <span class="token number">20350307</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">6</span></pre></td></tr></table></figure><p>现在，这 3 天的数据都集中在了 last_n_days 中。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZREVRANGE last_n_days <span class="token number">0</span> <span class="token parameter variable">-1</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"user6"</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"user3"</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">3</span><span class="token punctuation">)</span> <span class="token string">"user1"</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">4</span><span class="token punctuation">)</span> <span class="token string">"user4"</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token number">5</span><span class="token punctuation">)</span> <span class="token string">"user2"</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token number">6</span><span class="token punctuation">)</span> <span class="token string">"user5"</span></pre></td></tr></table></figure><p>如果一个用户同时在多个 <code>sorted set</code> 中的话，它最终的 <code>score</code> 值就等于这些 <code>sorted set</code> 中该用户的 <code>score</code> 值之和。</p><p>既然可以求并集，那必然也可以求交集。你可以通过 <code>ZINTERSTORE</code> 命令来求多个 n 个 <code>sorted set</code> 的交集。</p><p><strong>有哪些场景可以用到多个 <code>sorted set</code> 的交集呢？</strong> 比如每日打卡的场景，你对某一段时间每天打卡的人进行排序。</p><p>这个命令还有一个常用的权重参数 <code>weights</code> （默认为 1）。在进行并集 / 交集的过程中，每个集合中的元素会将自己的 <code>score</code> * <code>weights</code> 。</p><p>我下面演示一下这个参数的作用。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># staff_set 存放员工的排名信息</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZADD staff_set <span class="token number">3.0</span> staff1 <span class="token number">4.0</span> staff2</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># staff_set 存放管理者的排名信息</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZADD manager_set <span class="token number">1.0</span> manager1 <span class="token number">2.0</span> manager2</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr></table></figure><p>如果，我们需要将员工和管理者放在一起比较，不过，两者权重分别为 1 和 3。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># staff_set 的权重为 1 manager_set 的权重为 3</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZUNIONSTORE all_user_set <span class="token number">2</span> staff_set manager_set WEIGHTS <span class="token number">1</span> <span class="token number">3</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">4</span></pre></td></tr></table></figure><p>最终排序的结果如下：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ZREVRANGE all_user_set <span class="token number">0</span> <span class="token parameter variable">-1</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span><span class="token string">"manager2"</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span><span class="token string">"staff2"</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">3</span><span class="token punctuation">)</span><span class="token string">"staff1"</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">4</span><span class="token punctuation">)</span><span class="token string">"manager1"</span></pre></td></tr></table></figure><hr><p><strong>需要存储的<font color="red">数据有优先级</font>的场景</strong> 比如<font color="red">优先级任务队列</font>。</p><ul><li>举例：优先级任务队列。</li><li>相关命令： <code>ZRANGE</code> (从小到大排序)、 <code>ZREVRANGE</code> （从大到小排序）、 <code>ZREVRANK</code> (指定元素排名)。</li></ul><h4 id="小结"><a class="anchor" href="#小结">#</a> 小结</h4><table><thead><tr><th>数据类型</th><th>说明</th></tr></thead><tbody><tr><td>String</td><td>一种二进制安全的数据类型，可以用来存储<font color="red">任何类型的数据</font>比如字符串、整数、浮点数、图片（图片的 base64 编码或者解码或者图片的路径）、序列化后的对象。</td></tr><tr><td>List</td><td>Redis 的 List 的实现为一个<font color="red">双向链表</font>，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。</td></tr><tr><td>Hash</td><td>一个 String 类型的 <font color="red">field-value（键值对）</font> 的映射表，特别适合用于<font color="red">存储对象</font>，后续操作的时候，你可以直接修改这个对象中的某些字段的值。</td></tr><tr><td>Set</td><td><font color="red">无序集合</font>，集合中的元素没有先后顺序但都唯一，有点类似于 Java 中的 <code>HashSet</code> 。</td></tr><tr><td>Zset</td><td>和 Set 相比，Sorted Set 增加了一个权重参数 <code>score</code> ，使得集合中的元素能够按 <code>score</code> 进行<font color="red">有序排列</font>，还可以通过 <code>score</code> 的范围来获取元素的列表。有点像是 Java 中 <code>HashMap</code> 和 <code>TreeSet</code> 的结合体。</td></tr></tbody></table><h3 id="3-种特殊数据类型"><a class="anchor" href="#3-种特殊数据类型">#</a> 3 种特殊数据类型</h3><h4 id="bitmap位图"><a class="anchor" href="#bitmap位图">#</a> Bitmap（位图）</h4><h5 id="介绍-6"><a class="anchor" href="#介绍-6">#</a> 介绍</h5><blockquote><p>官网介绍：Bitmap 不是 Redis 中的实际数据类型，而<strong>是在 String 类型上定义的一组面向位的操作，将其视为位向量</strong>。由于字符串是二进制安全的块，且最大长度为 512 MB，它们适合用于设置最多 2<sup>32</sup> 个不同的位。</p></blockquote><p>Bitmap 存储的是 **<font color="red">连续的二进制数字</font>**（0 和 1），通过 Bitmap，只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 Bitmap 本身会极大的节省储存空间。</p><p>你可以将 Bitmap 看作是一个存储二进制数字（0 和 1）的数组，数组中<font color="red">每个元素的下标叫做 offset（偏移量）</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20220720194154133.png" alt="img"></p><h5 id="命令-6"><a class="anchor" href="#命令-6">#</a> 命令</h5><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td><code>SETBIT</code> key offset value</td><td>设置指定 offset 位置的值</td></tr><tr><td><code>GETBIT</code> key offset</td><td>获取指定 offset 位置的值</td></tr><tr><td><code>BITCOUNT</code> key start end</td><td>获取 start 和 end 之前<font color="red">值为 1 </font>的元素个数</td></tr><tr><td><code>BITOP</code> operation destkey key1 key2 ...</td><td>对一个或多个 Bitmap 进行运算，可用运算符有 <font color="red">AND, OR, XOR 以及 NOT</font></td></tr></tbody></table><p>Bitmap 基本操作演示：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># SETBIT 会返回之前位的值（默认是 0）这里会生成 7 个位</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token operator">></span> SETBIT mykey <span class="token number">7</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token operator">></span> SETBIT mykey <span class="token number">7</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token operator">></span> GETBIT mykey <span class="token number">7</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token operator">></span> SETBIT mykey <span class="token number">6</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token operator">></span> SETBIT mykey <span class="token number">8</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment"># 通过 bitcount 统计被被设置为 1 的位的数量。</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token operator">></span> BITCOUNT mykey</pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr></table></figure><h5 id="bitmap-应用"><a class="anchor" href="#bitmap-应用">#</a> Bitmap 应用</h5><p><strong>需要保存<font color="red">状态信息（0/1 即可表示）</font>的场景</strong></p><ul><li>举例：用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。</li><li>相关命令： <code>SETBIT</code> 、 <code>GETBIT</code> 、 <code>BITCOUNT</code> 、 <code>BITOP</code> 。</li></ul><h4 id="hyperloglog基数统计"><a class="anchor" href="#hyperloglog基数统计">#</a> HyperLogLog（基数统计）</h4><h5 id="介绍-7"><a class="anchor" href="#介绍-7">#</a> 介绍</h5><p>HyperLogLog 是一种有名的<font color="red">基数计数概率算法</font> ，基于 LogLog Counting (LLC) 优化改进得来，并不是 Redis 特有的，Redis 只是实现了这个算法并提供了一些开箱即用的 API。</p><p>Redis 提供的 HyperLogLog <font color="red">占用空间非常非常小，只需要 12k 的空间就能存储接近 2<sup>64</sup> 个不同元素</font>。这是真的厉害，这就是数学的魅力么！并且，Redis 对 HyperLogLog 的存储结构做了优化，采用两种方式计数：</p><ul><li><strong>稀疏矩阵</strong>：计数较少的时候，占用空间很小。</li><li><strong>稠密矩阵</strong>：计数达到某个阈值的时候，占用 12k 的空间。</li></ul><p>Redis 官方文档中有对应的详细说明：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231206160533080.png" alt="image-20231206160533080"></p><p>基数计数概率算法 **<font color="red">为了节省内存并不会直接存储元数据，而是通过一定的概率统计方法预估基数值（集合中包含元素的个数）</font><strong>。因此，</strong><font color="red">HyperLogLog 的计数结果并不是一个精确值，存在一定的误差</font>**（标准误差为 <code>0.81%</code> ）。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231206160401312.png" alt="image-20231206160401312"></p><p>HyperLogLog 的使用非常简单，但原理非常复杂。HyperLogLog 的原理以及在 Redis 中的实现可以看这篇文章：<span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uY24vcG9zdC82ODQ0OTAzNzg1NzQ0MDU2MzMz">HyperLogLog 算法的原理讲解以及 Redis 是如何应用它的</span> 。</p><p>再推荐一个可以帮助理解 HyperLogLog 原理的工具：<span class="exturl" data-url="aHR0cDovL2NvbnRlbnQucmVzZWFyY2gubmV1c3Rhci5iaXovYmxvZy9obGwuaHRtbA==">Sketch of the Day: HyperLogLog — Cornerstone of a Big Data Infrastructure</span> 。</p><p>除了 HyperLogLog 之外，Redis 还提供了其他的概率数据结构，对应的官方文档地址：<span class="exturl" data-url="aHR0cHM6Ly9yZWRpcy5pby9kb2NzL2RhdGEtdHlwZXMvcHJvYmFiaWxpc3RpYy8=">https://redis.io/docs/data-types/probabilistic/</span> 。</p><h5 id="命令-7"><a class="anchor" href="#命令-7">#</a> 命令</h5><p>HyperLogLog 相关的命令非常少，最常用的也就 3 个。</p><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td><code>PFADD</code> key element1 element2 ...</td><td>添加一个或多个元素到 HyperLogLog 中</td></tr><tr><td><code>PFCOUNT</code> key1 key2</td><td>获取一个或者多个 HyperLogLog 的唯一计数。</td></tr><tr><td><code>PFMERGE</code> destkey sourcekey1 sourcekey2 ...</td><td>将多个 HyperLogLog 合并到 destkey 中，destkey 会结合多个源，算出对应的唯一计数。</td></tr></tbody></table><p><strong>HyperLogLog 基本操作演示</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> PFADD hll foo bar zap</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> PFADD hll zap zap zap</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> PFADD hll foo bar</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">></span> PFCOUNT hll</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">3</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token operator">></span> PFADD some-other-hll <span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token operator">></span> PFCOUNT hll some-other-hll</pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">6</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token operator">></span> PFMERGE desthll hll some-other-hll</pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token string">"OK"</span></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token operator">></span> PFCOUNT desthll</pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">6</span></pre></td></tr></table></figure><h5 id="应用-3"><a class="anchor" href="#应用-3">#</a> 应用</h5><p><strong><font color="red">数据量巨大（百万、千万级别以上）的计数场景</font></strong></p><ul><li>举例：热门网站每日 / 每周 / 每月访问 ip 数统计、热门帖子 uv 统计</li><li>相关命令： <code>PFADD</code> 、 <code>PFCOUNT</code></li></ul><h4 id="geospatial地理位置"><a class="anchor" href="#geospatial地理位置">#</a> Geospatial（地理位置）</h4><h5 id="介绍-8"><a class="anchor" href="#介绍-8">#</a> 介绍</h5><p>Geospatial index（地理空间索引，简称 GEO） 主要 **<font color="red">用于存储地理位置信息，基于 Sorted Set 实现</font>**。</p><p>通过 GEO 我们可以轻松实现<font color="red">两个位置距离的计算、获取指定位置附近的元素</font>等功能。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20220720194359494.png" alt="img"></p><h5 id="命令-8"><a class="anchor" href="#命令-8">#</a> 命令</h5><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td><code>GEOADD</code> key longitude1 latitude1 member1 ...</td><td>添加一个或多个元素对应的经纬度信息到 GEO 中</td></tr><tr><td><code>GEOPOS</code> key member1 member2 ...</td><td>返回给定元素的经纬度信息</td></tr><tr><td><code>GEODIST</code> key member1 member2 M/KM/FT/MI</td><td>返回两个给定元素之间的距离</td></tr><tr><td><code>GEORADIUS</code> key longitude latitude radius distance</td><td>获取指定位置<font color="red">附近 distance 范围内</font>的其他元素，支持 ASC (由近到远)、DESC（由远到近）、Count (数量) 等参数</td></tr><tr><td><code>GEORADIUSBYMEMBER</code> key member radius distance</td><td>类似于 GEORADIUS 命令，只是<font color="red">参照的中心点是 GEO 中的元素</font></td></tr></tbody></table><p><strong>基本操作</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> GEOADD personLocation <span class="token number">116.33</span> <span class="token number">39.89</span> user1 <span class="token number">116.34</span> <span class="token number">39.90</span> user2 <span class="token number">116.35</span> <span class="token number">39.88</span> user3</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">3</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> GEOPOS personLocation user1</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">116.3299986720085144</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">39.89000061669732844</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token operator">></span> GEODIST personLocation user1 user2 km</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token number">1.4018</span></pre></td></tr></table></figure><p>通过 Redis 可视化工具查看 <code>personLocation</code> ，果不其然，底层就是 Sorted Set。</p><p>GEO 中存储的地理位置信息的经纬度数据通过 GeoHash 算法转换成了一个整数，这个整数作为 Sorted Set 的 score (权重参数) 使用。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20220721201545147.png" alt="img"></p><p><strong>获取指定位置范围内的其他元素</strong>：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> GEORADIUS personLocation <span class="token number">116.33</span> <span class="token number">39.87</span> <span class="token number">3</span> km</pre></td></tr><tr><td data-num="2"></td><td><pre>user3</pre></td></tr><tr><td data-num="3"></td><td><pre>user1</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token operator">></span> GEORADIUS personLocation <span class="token number">116.33</span> <span class="token number">39.87</span> <span class="token number">2</span> km</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> GEORADIUS personLocation <span class="token number">116.33</span> <span class="token number">39.87</span> <span class="token number">5</span> km</pre></td></tr><tr><td data-num="6"></td><td><pre>user3</pre></td></tr><tr><td data-num="7"></td><td><pre>user1</pre></td></tr><tr><td data-num="8"></td><td><pre>user2</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token operator">></span> GEORADIUSBYMEMBER personLocation user1 <span class="token number">5</span> km</pre></td></tr><tr><td data-num="10"></td><td><pre>user3</pre></td></tr><tr><td data-num="11"></td><td><pre>user1</pre></td></tr><tr><td data-num="12"></td><td><pre>user2</pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token operator">></span> GEORADIUSBYMEMBER personLocation user1 <span class="token number">2</span> km</pre></td></tr><tr><td data-num="14"></td><td><pre>user1</pre></td></tr><tr><td data-num="15"></td><td><pre>user2</pre></td></tr></table></figure><p><code>GEORADIUS</code> 命令的底层原理解析可以看看阿里的这篇文章：<span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uY24vcG9zdC82ODQ0OTAzOTY2MDYxMzYzMjA3">Redis 到底是怎么实现 “附近的人” 这个功能的呢？</span> 。</p><p><strong>移除元素</strong>：</p><p>GEO 底层是 Sorted Set ，你可以对 GEO 使用 Sorted Set 相关的命令。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> ZREM personLocation user1</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> ZRANGE personLocation <span class="token number">0</span> <span class="token parameter variable">-1</span></pre></td></tr><tr><td data-num="4"></td><td><pre>user3</pre></td></tr><tr><td data-num="5"></td><td><pre>user2</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token operator">></span> ZSCORE personLocation user2</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token number">4069879562983946</span></pre></td></tr></table></figure><h5 id="应用-4"><a class="anchor" href="#应用-4">#</a> 应用</h5><p><strong>需要管理使用<font color="red">地理空间数据</font>的场景</strong></p><ul><li>举例：附近的人</li><li>相关命令: <code>GEOADD</code> 、 <code>GEORADIUS</code> 、 <code>GEORADIUSBYMEMBER</code></li></ul><h4 id="小结-2"><a class="anchor" href="#小结-2">#</a> 小结</h4><table><thead><tr><th>数据类型</th><th>说明</th></tr></thead><tbody><tr><td>Bitmap</td><td>可以将 Bitmap 看作一个存储二进制数字（0 和 1）的数组，数组中每个元素的下标叫做 offset（偏移量）。通过 Bitmap，只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 Bitmap 本身会极大的节省储存空间。</td></tr><tr><td>HyperLogLog</td><td>Redis 提供的<font color="red"> HyperLogLog 占用空间非常非常小</font>，只需要 12k 的空间就能存储接近 <code>2^64</code> 个不同元素。不过，HyperLogLog 的计数结果并不是一个精确值，<font color="red">存在一定的误差</font>（标准误差为 <code>0.81%</code> ）。</td></tr><tr><td>Geospatial index</td><td>Geospatial index（地理空间索引，简称 GEO） 主要<font color="red">用于存储地理位置信息，基于 Sorted Set 实现</font>。</td></tr></tbody></table><h2 id="string-应用场景"><a class="anchor" href="#string-应用场景">#</a> String 应用场景</h2><p>[String 应用](#String 应用)</p><h2 id="对象数据的存储建议使用-string"><a class="anchor" href="#对象数据的存储建议使用-string">#</a> 对象数据的存储建议使用 String</h2><ul><li><strong><font color="red">String 存储的是序列化后的对象数据，存放的是整个对象</font></strong>。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。<font color="red">如果对象中某些字段需要经常变动，或者需要经常单独查询对象中的个别字段信息，Hash 就非常适合</font>。</li><li><strong><font color="red">String 存储对象相对更加节省内存</font></strong>，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。并且，<font color="red">String 存储具有多层嵌套的对象时，也方便很多</font>。如果系统对性能和资源消耗非常敏感的话，String 就非常适合。</li></ul><p>在绝大部分情况，我们建议使用 String 来存储对象数据即可！</p><h2 id="string-的底层实现sds"><a class="anchor" href="#string-的底层实现sds">#</a> <mark>🌟String 的底层实现：SDS</mark></h2><h3 id="sds-介绍"><a class="anchor" href="#sds-介绍">#</a> SDS 介绍</h3><p>Redis 是基于 C 语言编写的，但 Redis 的 String 类型的底层实现并不是 C 语言中的字符串（即以空字符 <code>\0</code> 结尾的字符数组），而是自己编写了 **<font color="cornflowerblue"><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FudGlyZXovc2Rz">SDS</span>（Simple Dynamic String，简单动态字符串）</font>** 来作为底层实现。</p><p>SDS 最早是 Redis 作者为日常 C 语言开发而设计的 C 字符串，后来被应用到了 Redis 上，并经过了大量的修改完善以适合<font color="red">高性能操作</font>。</p><h3 id="sds-结构"><a class="anchor" href="#sds-结构">#</a> SDS 结构</h3><p>Redis7.0 的 SDS 的部分<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JlZGlzL3JlZGlzL2Jsb2IvNy4wL3NyYy9zZHMuaA==">源码</span>如下：</p><figure class="highlight c"><figcaption data-lang="c"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">/* Note: sdshdr5 is never used, we just access the flags byte directly.</span></pre></td></tr><tr><td data-num="2"></td><td><pre> * However is here to document the layout of type 5 SDS strings. */</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">struct</span> <span class="token keyword">__attribute__</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>__packed__<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token class-name">sdshdr5</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">unsigned</span> <span class="token keyword">char</span> flags<span class="token punctuation">;</span> <span class="token comment">/* 3 lsb of type, and 5 msb of string length */</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token keyword">char</span> buf<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token punctuation">&#125;</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">struct</span> <span class="token keyword">__attribute__</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>__packed__<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token class-name">sdshdr8</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token class-name">uint8_t</span> len<span class="token punctuation">;</span> <span class="token comment">/* used */</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token class-name">uint8_t</span> alloc<span class="token punctuation">;</span> <span class="token comment">/* excluding the header and null terminator */</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token keyword">unsigned</span> <span class="token keyword">char</span> flags<span class="token punctuation">;</span> <span class="token comment">/* 3 lsb of type, 5 unused bits */</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">char</span> buf<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token punctuation">&#125;</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">struct</span> <span class="token keyword">__attribute__</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>__packed__<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token class-name">sdshdr16</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token class-name">uint16_t</span> len<span class="token punctuation">;</span> <span class="token comment">/* used */</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token class-name">uint16_t</span> alloc<span class="token punctuation">;</span> <span class="token comment">/* excluding the header and null terminator */</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">unsigned</span> <span class="token keyword">char</span> flags<span class="token punctuation">;</span> <span class="token comment">/* 3 lsb of type, 5 unused bits */</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">char</span> buf<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token punctuation">&#125;</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token keyword">struct</span> <span class="token keyword">__attribute__</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>__packed__<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token class-name">sdshdr32</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    <span class="token class-name">uint32_t</span> len<span class="token punctuation">;</span> <span class="token comment">/* used */</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token class-name">uint32_t</span> alloc<span class="token punctuation">;</span> <span class="token comment">/* excluding the header and null terminator */</span></pre></td></tr><tr><td data-num="22"></td><td><pre>    <span class="token keyword">unsigned</span> <span class="token keyword">char</span> flags<span class="token punctuation">;</span> <span class="token comment">/* 3 lsb of type, 5 unused bits */</span></pre></td></tr><tr><td data-num="23"></td><td><pre>    <span class="token keyword">char</span> buf<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="24"></td><td><pre><span class="token punctuation">&#125;</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="25"></td><td><pre><span class="token keyword">struct</span> <span class="token keyword">__attribute__</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>__packed__<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token class-name">sdshdr64</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    <span class="token class-name">uint64_t</span> len<span class="token punctuation">;</span> <span class="token comment">/* used */</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token class-name">uint64_t</span> alloc<span class="token punctuation">;</span> <span class="token comment">/* excluding the header and null terminator */</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    <span class="token keyword">unsigned</span> <span class="token keyword">char</span> flags<span class="token punctuation">;</span> <span class="token comment">/* 3 lsb of type, 5 unused bits */</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token keyword">char</span> buf<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="30"></td><td><pre><span class="token punctuation">&#125;</span><span class="token punctuation">;</span></pre></td></tr></table></figure><p>通过源码可以看出，SDS 共有五种实现方式 SDS_TYPE_5（并未用到）、SDS_TYPE_8、SDS_TYPE_16、SDS_TYPE_32、SDS_TYPE_64，其中只有后四种实际用到。<font color="red">Redis 会根据初始化的长度决定使用哪种类型的 SDS，从而减少内存的使用</font>。</p><table><thead><tr><th>类型</th><th>字节</th><th>位</th></tr></thead><tbody><tr><td>sdshdr5</td><td>&lt; 1</td><td>&lt;8</td></tr><tr><td>sdshdr8</td><td>1</td><td>8</td></tr><tr><td>sdshdr16</td><td>2</td><td>16</td></tr><tr><td>sdshdr32</td><td>4</td><td>32</td></tr><tr><td>sdshdr64</td><td>8</td><td>64</td></tr></tbody></table><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis_sdshdr5.png" alt="redis字符窜数据结构简述 - 知乎"></p><center>SDSHDR5</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231206204849898.png" alt="image-20231206204849898"></p><center>SDSHDR 结构示意图</center><p>对于后四种实现都包含了下面这 4 个属性：</p><ul><li><code>len</code> ：字符串的长度，即<font color="red">已使用的</font>字节数</li><li><code>alloc</code> ：<font color="red">总共可用的</font>字符空间大小（字节数），<font color="red">不包括 <code>\0</code> </font>，alloc-len 就是 SDS 剩余的空间大小</li><li><code>buf[]</code> ：<font color="red">实际存储字符串的数组</font></li><li><code>flags</code> ：大小为 1 个字节，其中<font color="red">低 3 位保存类型标志</font>，高 5 位闲置</li></ul><h3 id="sds-相比-c-字符串的优势"><a class="anchor" href="#sds-相比-c-字符串的优势">#</a> SDS 相比 C 字符串的优势</h3><p>SDS 相比于 C 语言中的字符串有如下提升：</p><ol><li><strong><font color="red">可以避免缓冲区溢出</font></strong>：C 语言中的字符串被修改（比如拼接）时，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。SDS 被修改时，会先根据 len 属性检查空间大小是否满足要求，如果不满足，则先扩展至所需大小再进行修改操作。</li><li><strong><font color="red">获取字符串长度的复杂度较低</font></strong>：C 语言中的字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O (n)。SDS 的长度获取<font color="red">直接读取 len 属性即可，时间复杂度为 O (1)</font>。</li><li><strong><font color="red">减少内存分配次数</font></strong>：为了避免修改（增加 / 减少）字符串时，每次都需要重新分配内存（C 语言的字符串是这样的），SDS 实现了<font color="cornflowerblue">空间预分配</font>和<font color="cornflowerblue">惰性空间释放</font>两种优化策略。当 SDS 需要增加字符串时，Redis 会为 SDS 分配好内存，并且根据特定的算法分配多余的内存，这样可以减少连续执行字符串增长操作所需的内存重分配次数。当 SDS 需要减少字符串时，这部分内存不会立即被回收，会被记录下来，等待后续使用（支持手动释放，有对应的 API）。</li><li><strong><font color="red">二进制安全</font></strong>：C 语言中的字符串以空字符 <code>\0</code> 作为字符串结束的标识，这存在一些问题，像一些二进制文件（比如图片、视频、音频）就可能包括空字符，C 字符串无法正确保存。<font color="red">SDS 使用 len 属性判断字符串是否结束，不存在这个问题</font>。</li></ol><h3 id="sds-旧版本结构"><a class="anchor" href="#sds-旧版本结构">#</a> SDS 旧版本结构</h3><p>🤐 多提一嘴，很多文章里 SDS 的定义是下面这样的：</p><figure class="highlight c"><figcaption data-lang="c"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">struct</span> <span class="token class-name">sdshdr</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> len<span class="token punctuation">;</span> <span class="token comment">// 记录 buf 数组中已使用字节的数量 = sds 所保存字符串的长度</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> free<span class="token punctuation">;</span> <span class="token comment">// 记录 buf 数组中未使用字节的数量</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">char</span> buf<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// 字节数组，用于保存字符串</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">&#125;</span><span class="token punctuation">;</span></pre></td></tr></table></figure><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/v2-3423339183d978aed32dca64447d728d_b.jpg" alt="img"></p><center>SDS旧版本结构</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis_sds_1.png" alt="img"></p><p>这个也没错，<font color="red">Redis 3.2 之前就是这样定义的</font>。后来，由于这种方式的定义存在问题， <code>len</code> 和 <code>free</code> 的定义用了 4 个字节，造成了浪费。Redis 3.2 之后，Redis 改进了 SDS 的定义，将其划分为了现在的 5 种类型。</p><h2 id="购物车信息的存储建议使用-hash"><a class="anchor" href="#购物车信息的存储建议使用-hash">#</a> 购物车信息的存储建议使用 Hash</h2><blockquote><p>你肯定会问：购物车信息也是对象数据，前文不是说了建议使用 String 存储对象数据吗？</p></blockquote><p><strong><font color="red">因为购物车中的商品频繁修改和变动</font></strong>，购物车信息建议使用 Hash 存储：</p><ul><li>用户 id 为 key</li><li>商品 id 为 field，商品数量为 value</li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231206193856739.png" alt="Hash维护简单的购物车信息"></p><center>Hash维护简单的购物车信息</center><p>那用户购物车信息的维护具体应该怎么操作呢？</p><ul><li>用户添加商品就是往 Hash 里面增加新的 field 与 value；</li><li>查询购物车信息就是遍历对应的 Hash；</li><li>更改商品数量直接修改对应的 value 值（直接 set 或者做运算皆可）；</li><li>删除商品就是删除 Hash 中对应的 field；</li><li>清空购物车直接删除对应的 key 即可。</li></ul><p>这里只是以业务比较简单的购物车场景举例，实际电商场景下，field 只保存一个商品 id 是没办法满足需求的。</p><h2 id="使用-sorted-set-实现排行榜"><a class="anchor" href="#使用-sorted-set-实现排行榜">#</a> 使用 Sorted Set 实现排行榜</h2><p>[Zset 应用](#Zset 应用)</p><h2 id="set-应用场景"><a class="anchor" href="#set-应用场景">#</a> Set 应用场景</h2><p>[Set 应用](#Set 应用)</p><h2 id="使用-set-实现抽奖系统"><a class="anchor" href="#使用-set-实现抽奖系统">#</a> 使用 Set 实现抽奖系统</h2><p>如果想要使用 <code>Set</code> 实现一个简单的抽奖系统的话，直接使用下面这几个命令就可以了：</p><ul><li><code>SADD key member1 member2 ...</code> ：向指定集合添加一个或多个元素。</li><li><code>SPOP key count</code> ：随机移除并获取指定集合中一个或多个元素，适合不允许重复中奖的场景。</li><li><code>SRANDMEMBER key count</code> ：随机获取指定集合中指定数量的元素，适合允许重复中奖的场景。</li></ul><h2 id="集合的底层实现"><a class="anchor" href="#集合的底层实现">#</a> <mark>🌟集合的底层实现</mark></h2><p>Redis 中<font color="red">对于 Set 类型的底层实现，直接采用了 hashTable</font>。</p><p><font color="red">对于 Hash 与 ZSet 集合，其底层的实现实际有两种</font>：</p><ul><li><code>zipList</code> （<font color="cornflowerblue">压缩列表</font>）</li><li><code>skipList</code> （<font color="cornflowerblue">跳跃列表</font>）</li></ul><p>这两种实现对于用户来说是透明的，但用户写入不同的数据，系统会自动使用不同的实现。只要同时满足配置文件 redis.conf 中相关集合<font color="red">元素数量阈值</font>、<font color="red">元素大小阈值</font>两个条件，使用的就是压缩列表 zipList；只要有一个条件不满足，使用的就是跳跃列表 skipList。</p><p>例如，对于 ZSet 集合中这两个条件如下：</p><ul><li>集合元素个数小于 redis.conf 中 zset-max-ziplist-entries 属性的值，其默认值为 128</li><li>每个集合元素大小都小于 redis.conf 中 zset-max-ziplist-value 属性的值，其默认值为 64 字节</li></ul><h3 id="ziplist压缩列表"><a class="anchor" href="#ziplist压缩列表">#</a> zipList（压缩列表）</h3><p>zipList，通常称为压缩列表，是一个<font color="red">经过特殊编码</font>的用于<font color="red">存储字符串或整数</font>的 **<font color="red">双向链表</font>**。</p><p>其底层数据结构由<font color="red">在内存上是连续存放的三部分</font>构成：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231206212946057.png" alt="image-20231206212946057"></p><center>zipList 结构</center><ul><li><strong><font color="green">head</font></strong>：10 字节<ul><li><font color="gree">zlbytes（列表长度）</font>：4 字节，存放 zipList 列表整体数据结构所占的字节数，包括 zlbytes 本身的长度。</li><li><font color="gree">zltail（尾 entry 的偏移量）</font>：4 字节，用于存放 zipList 中最后一个 entry 在整个数据结构中的偏移量（字节）。该数据的存在可以快速定位列表的尾 entry 位置，以方便操作。</li><li><font color="gree">zllen（entry 个数）</font>：2 字节，用于存放 zipList 包含的 entry 个数。由于其只有 16 位，所以 zipList 最多可以含有的 entry 个数为 2<sup>16</sup>-1 = 65535 个。</li></ul></li><li><strong><font color="green">entries</font></strong>：真正的列表，由很多的元素 entry 构成。由于不同的元素类型、数值的不同，从而导致每个 entry 的长度不同。<ul><li><strong><font color="gree">prevlength（前一个 entry 的长度）</font></strong>： <font color="red">1/3 字节</font>，用于记录前一个 entry 的长度，<font color="red">以实现逆序遍历</font>。默认长度为 1 字节，只要上一个 entry 的长度小于 254 字节， prevlength 就占 1 字节，否则其会自动扩展为 3 字节长度。</li><li><font color="gree">encoding（data 具体类型）</font>：<font color="red">1/2/5 字节</font>，用于标志后面的 data 的具体类型。如果 data 为整数类型， encoding 固定长度为 1 字节。如果 data 为字符串类型，则 encoding 长度可能会是 1 字节、 2 字<br>节或 5 字节。 <font color="red">data 字符串不同的长度，对应着不同的 encoding 长度</font>。</li><li><font color="gree">data（真正的数据）</font>：数据类型只能是<font color="red">整数类型或字符串类型</font>，不同的数据占用的字节长度不同。</li></ul></li><li><strong><font color="green">end</font></strong>：只包含一部分<ul><li><font color="gree">zlend（zipList 结束标记）</font>：1 字节，值固定为 255，即<font color="red">二进制位为全 1</font>，表示一个 zipList 列表的结束。</li></ul></li></ul><h3 id="listpack紧凑列表"><a class="anchor" href="#listpack紧凑列表">#</a> listPack（紧凑列表）</h3><blockquote><p>重写并替代 zipList（压缩列表）</p></blockquote><p>ziplist 实现复杂，为了逆序遍历，每个 entry 中包含前一个 entry 的长度，这样会导致<font color="red">在 ziplist 中间修改或者插入 entry 时需要进行级联更新</font>，在高并发的写操作场景下会极度降低 Redis 的性能。为了实现更紧凑、更快的解析，更简单的实现，<strong><font color="red">重写实现了 ziplist，并命名为 listPack</font></strong>。</p><p><font color="red">在 Redis 7.0 中，已经将 zipList 全部替换为了 listPack</font>，但为了兼容性，在配置中也保留了 zipList 的相关属性。</p><p>与 zipList 一样，listPack 也是一个<font color="red">经过特殊编码</font>的用于<font color="red">存储字符串或整数</font>的 **<font color="red">双向链表</font>**。</p><p>其底层数据结构也由在内存上也是连续存放的三部分构成：</p><blockquote><p>listPack 与 zipList 的 **<font color="red">重大区别：head 与 entry 的结构</font>**。表示列表结束的 end 与 zipList 的 zlend 是相同的，占一个字节，且 8 位全为 1</p></blockquote><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207093508520.png" alt="image-20231207093508520"></p><center>listPack 结构</center><ul><li><p><strong><font color="green">head</font></strong>：6 字节</p><blockquote><p>与 zipList 的 head 相比最大的变化：<strong><font color="red">不再记录尾 entry 的偏移量</font></strong></p></blockquote><ul><li><font color="gree">totalBytes（列表长度）</font>：4 字节，用于存放 listPack 列表<font color="red">整体数据结构</font>所占的字节数，包括 totalBytes 本身的长度。</li><li><font color="gree">elemNum（entry 个数）</font>：2 字节，用于存放列表包含的<font color="red"> entry 个数</font>。其意义与 zipList 中 zllen 的相同。</li></ul></li><li><p><strong><font color="green">entries</font></strong>：真正的列表，由很多的元素 entry 构成。由于不同的元素类型、数值的不同，从而导致每个 entry 的长度不同。</p><blockquote><p>与 zipList 的 entries 相比最大的变化：<strong><font color="red">不再记录前一个 entry 长度的 prevlength，而是记录当前 entry 长度的 element-total-len</font></strong>。而这个改变<font color="red">仍然可以实现逆序遍历，但却避免了由于在列表中间修改或插入 entry 时引发的级联更新</font>。</p></blockquote><ul><li><font color="gree">encoding（data 具体类型）</font>：1/2/3/4/5/9 字节，用于标志后面的 data 的具体类型。如果 data 为整数类型，encoding 长度可能会是 1、 2、 3、 4、 5 或 9 字节。不同的字节长度，其标识位不同。如果 data 为字符串类型，则 encoding 长度可能会是 1、 2 或 5 字节。 data 字符串不同的长度，对应着不同的 encoding 长度。</li><li><font color="gree">data（真正的数据）</font>：只能是<font color="red">整数类型或字符串类型</font>。不同的数据占用的字节长度不同。</li><li><strong><font color="gree">element-total-len（当前 entry 的长度）</font></strong>：1/2/3/4/5 字节，用于记录当前 entry 的长度，以实现逆序遍历。由于其特殊的记录方式，使其本身占有的字节数据可能会是 1、 2、 3、 4 或 5 字节。</li></ul></li><li><p><strong><font color="green">end</font></strong>：只包含一部分</p><ul><li><font color="gree">zlend（zipList 结束标记）</font>：1 字节，值固定为 255，即<font color="red">二进制位为全 1</font>，表示一个 zipList 列表的结束。</li></ul></li></ul><h3 id="skiplist跳跃列表跳表"><a class="anchor" href="#skiplist跳跃列表跳表">#</a> <mark>🌟skipList（跳跃列表 / 跳表）</mark></h3><p>skipList，跳跃列表，简称跳表，是一种<font color="red">随机化的</font>数据结构，基于<font color="red">并联的链表</font>，实现简单，查找效率较高。简单来说跳表也是链表的一种，只不过它 **<font color="red">在链表的基础上增加了跳跃功能</font>**。也正是这个跳跃功能，使得在<font color="red">查找元素时，能够提供较高的效率</font>。</p><h4 id="原理-3"><a class="anchor" href="#原理-3">#</a> 原理</h4><p>假设有一个<font color="red">带头、尾结点的有序链表</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207150413317.png" alt="image-20231207150413317"></p><p>在该链表中，如果要查找某个数据，需要从头开始逐个进行比较，直到找到包含数据的那个节点，或者找到第一个比给定数据大的节点，或者找到最后尾结点，后两种都属于没有找到的情况。同样，当我们要插入新数据的时候，也要经历同样的查找过程，从而确定插入位置。</p><p>为了提升查找效率，<strong><font color="red">在偶数结点上增加一个指针，让其指向下一个偶数结点，形成一个新的链表（<font color="cornflowerblue">高层链表</font>）</font></strong>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207150636138.png" alt="image-20231207150636138"></p><p>当然，高层链表包含的节点个数只是原来链表的一半。此时再想查找某个数据时，<font color="red">先沿着高层链表进行查找，当遇到第一个比待查数据大的节点时，立即从前一个节点，再回到原链表中进行查找</font>。</p><p>例如，若想插入一个数据 20，则先在（8， 19，31， 42）的链表中查找，找到第一个比 20 大的节点 31，然后再在高层链表中找到 31 节点的前一个节点 19，然后再在原链表中获取到其下一个节点值为 23。比 20 大，则将 20 插入到 19 节点与 23 节点之间。若插入的是 25，比节点 23 大，则插入到 23 节点与 31 节点之间。</p><p>该方式明显<font color="red">可以减少比较次数，提高查找效率</font>。如果链表元素较多，为了进一步提升查找效率，可以将原链表构建为三层链表，或再高层级链表。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207151233404.png" alt="image-20231207151233404"></p><p>层级越高，查找效率就会越高。</p><h4 id="存在问题"><a class="anchor" href="#存在问题">#</a> 存在问题</h4><p>这种对链表分层级的方式从原理上看确实提升了查找效率，但在实际操作时就出现了问题：<strong><font color="red">由于固定序号的元素拥有固定层级，所以列表元素出现增加或删除的情况下，会导致列表整体元素层级大调整，但这样势必会大大降低系统性能</font></strong>。</p><p>例如，对于划分两级的链表，可以规定奇数结点为高层级链表，偶数结点为低层级链表。对于划分三级的链表，可以按照节点序号与 3 取模结果进行划分。但如果插入了新的节点，或删除的原来的某些节点，那么定会按照原来的层级划分规则进行重新层级划分，那么势必会大大降低系统性能。</p><h4 id="算法优化"><a class="anchor" href="#算法优化">#</a> 算法优化</h4><p>为了避免前面的问题，skipList 采用了 **<font color="#B32015">随机分配层级</font>** 方式。即<font color="red">在确定了总层级后，每添加一个新的元素时会自动为其随机分配一个层级</font>。这种随机性就<font color="red">解决了节点序号与层级间的固定关系问题</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207151544039.png" alt="image-20231207151544039"></p><center>skipList 在生成过程中为每个元素随机分配层级的过程</center><p>从这个 skiplist 的创建和插入过程可以看出，每一个节点的层级数都是随机分配的。而且<font color="red">新插入一个节点不会影响到其它节点的层级数，只需要修改插入节点前后的指针</font>，这就降低了插入操作的复杂度。</p><p>skipList 指的就是除了最下面第 1 层链表之外，它会产生若干层稀疏的链表，这些链表里面的指针跳过了一些节点，并且越高层级的链表跳过的节点越多。<strong><font color="red">在查找数据的时先在高层级链表中进行查找，然后逐层降低，最终可能会降到第 1 层链表来精确地确定数据位置</font></strong>。在这个过程中由于跳过了一些节点，从而加快了查找速度。</p><h3 id="quicklist快速列表快表"><a class="anchor" href="#quicklist快速列表快表">#</a> quickList（快速列表 / 快表）</h3><blockquote><p>从 Redis 3.2 开始成为是 List 的底层实现，替代了 zipList 和 LinkedList</p></blockquote><h4 id="原理-4"><a class="anchor" href="#原理-4">#</a> 原理</h4><p>quickList，快速列表， quickList 本身是一个<font color="red">双向无循环链表</font>，它的 **<font color="red">每个节点都是一个 zipList</font>**。</p><p>zipList 与 linkedList 都存在有明显不足，而 quickList 则对它们进行了改进：吸取了 zipList 和 linkedList 的优点，避开了它们的不足。</p><p>quickList 本质上 **<font color="red">是 zipList 和 linkedList 的混合体</font>**，<font color="red">将 linkedList 按段切分，每一段使用 zipList 来紧凑存储若干真正的数据元素，多个 zipList 之间使用双向指针串接起来</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207153821870.png" alt="image-20231207153821870"></p><p>当然，对于<font color="red">每个 zipList 中最多可存放多大容量的数据元素</font>，在配置文件中通过 <code>list-max-ziplist-size</code> 属性可以指定。</p><h4 id="检索操作"><a class="anchor" href="#检索操作">#</a> 检索操作</h4><p>为了更深入的理解 quickList 的工作原理，通过对检索、插入、删除等操作的实现分析来加深理解。</p><p>对于 List 元素的检索，都是以其索引 index 为依据的。quickList 由一个个的 zipList 构成，每个 zipList 的 zllen 中记录的就是当前 zipList 中包含的 entry 的个数，即包含的真正数据元素的个数。<font color="red">根据要检索元素的 index，从 quickList 的头节点开始，<strong>逐个对 zipList 的 zllen 做 sum 求和</strong>，直到找到第一个求和后 sum 大于 index 的 zipList，那么要检索的这个元素就在这个 zipList 中</font>。</p><h4 id="插入操作"><a class="anchor" href="#插入操作">#</a> 插入操作</h4><p>由于 zipList 是有大小限制的，所以在 quickList 中插入一个元素在逻辑上相对就比较复杂一些。假设要插入的元素的大小为 <code>insertBytes</code> ，而查找到的插入位置所在的 zipList 当前的大小为 <code>zlBytes</code> ，那么具体可分为下面几种情况：</p><ul><li>情况一：<font color="red">当 insertBytes + zlBytes &lt;= list-max-ziplist-size 时</font>， 直接插入到 zipList 中相应位置即可</li><li>情况二：<font color="red">当 insertBytes + zlBytes &gt; list-max-ziplist-size，且插入的位置位于该 zipList 的首部位置</font>，此时需要查看该 zipList 的前一个 zipList 的大小 <code>prev_zlBytes</code> 。<ul><li>若 insertBytes + prev_zlBytes&lt;= list-max-ziplist-size 时，直接将元素插入到前一个 zipList 的尾部位置即可</li><li>若 insertBytes + prev_zlBytes&gt; list-max-ziplist-size 时，直接将元素自己构建为一个新的 zipList，并连入 quickList 中</li></ul></li><li>情况三：<font color="red">当 insertBytes + zlBytes &gt; list-max-ziplist-size，且插入的位置位于该 zipList 的尾部位置</font>，此时需要查看该 zipList 的后一个 zipList 的大小 <code>next_zlBytes</code> 。<ul><li>若 insertBytes + next_zlBytes&lt;= list-max-ziplist-size 时，直接将元素插入到后一个 zipList 的头部位置即可</li><li>若 insertBytes + next_zlBytes&gt; list-max-ziplist-size 时，直接将元素自己构建为一个新的 zipList，并连入 quickList 中</li></ul></li><li>情况四：<font color="red">当 insertBytes + zlBytes &gt; list-max-ziplist-size，且插入的位置位于该 zipList 的中间位置</font>，则将当前 zipList 分割为两个 zipList 连接入 quickList 中，然后将元素插入到分割后的前面 zipList 的尾部位置。</li></ul><h4 id="删除操作"><a class="anchor" href="#删除操作">#</a> 删除操作</h4><p>对于删除操作，只需要注意一点，<font color="red">在相应的 zipList 中删除元素后，如果该 zipList 中没有其它元素了，则将该 zipList 删除，将其前后两个 zipList 相连接</font>。</p><h2 id="使用-bitmap-统计活跃用户"><a class="anchor" href="#使用-bitmap-统计活跃用户">#</a> 使用 Bitmap 统计活跃用户</h2><blockquote><p>[Bitmap 应用](#Bitmap 应用)</p></blockquote><p>如果想要使用 Bitmap 统计活跃用户的话，<font color="red">可以使用日期（精确到天）作为 key，然后用户 ID 为 offset，如果当日活跃过就设置为 1</font>。</p><p>初始化数据：</p><figure class="highlight sh"><figcaption data-lang="sh"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> SETBIT <span class="token number">20210308</span> <span class="token number">1</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> SETBIT <span class="token number">20210308</span> <span class="token number">2</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> SETBIT <span class="token number">20210309</span> <span class="token number">1</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">0</span></pre></td></tr></table></figure><p>统计 20210308~20210309 总活跃用户数：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> BITOP and desk1 <span class="token number">20210308</span> <span class="token number">20210309</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> BITCOUNT desk1</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr></table></figure><p>统计 20210308~20210309 在线活跃用户数：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> BITOP or desk2 <span class="token number">20210308</span> <span class="token number">20210309</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> BITCOUNT desk2</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">2</span></pre></td></tr></table></figure><h2 id="使用-hyperloglog-统计页面-uv独立访客"><a class="anchor" href="#使用-hyperloglog-统计页面-uv独立访客">#</a> 使用 HyperLogLog 统计页面 UV（独立访客）</h2><p>使用 HyperLogLog 统计页面 UV 主要需要用到下面这两个命令：</p><ul><li><code>PFADD key element1 element2 ...</code> ：添加一个或多个元素到 HyperLogLog 中。</li><li><code>PFCOUNT key1 key2</code> ：获取一个或者多个 HyperLogLog 的唯一计数。</li></ul><p>1、将访问指定页面的每个用户 ID 添加到 <code>HyperLogLog</code> 中。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>PFADD PAGE_1:UV USER1 USER2 <span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span> USERn</pre></td></tr></table></figure><p>2、统计指定页面的 UV。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>PFCOUNT PAGE_1:UV</pre></td></tr></table></figure><h1 id="redis-持久化机制"><a class="anchor" href="#redis-持久化机制">#</a> <mark>🌟Redis 持久化机制</mark></h1><p>Redis 为什么需要持久化？Redis 是一个内存数据库，所以其运行效率非常高。但也存在一个问题：<font color="red">内存中的数据是不持久的，若主机宕机或 Redis 关机重启，则内存中的数据全部丢失</font>。</p><p>为了<font color="red">重用数据（比如重启机器、机器故障之后恢复数据）</font>/<font color="red">数据同步（比如 Redis 集群的主从节点通过 RDB 文件同步数据）</font>，Redis 需要持久化功能。</p><p>Redis 会按照设置以<font color="cornflowerblue">快照</font>或<font color="cornflowerblue">操作日志</font>的形式将数据持久化到磁盘，对应两种持久化方式：RDB 与 AOF。但实际上，Redis 支持 3 种持久化方式：</p><ul><li><font color="gree">RDB</font>（ <code>R</code> edis <code>D</code> ata <code>B</code> ase）：快照</li><li><font color="gree">AOF</font>（ <code>A</code> ppend <code>O</code> nly <code>F</code> ile）：只追加文件</li><li><font color="gree">RDB + AOF</font>：RDB 和 AOF 的混合持久化 (Redis 4.0 新增)</li></ul><h2 id="持久化基本原理"><a class="anchor" href="#持久化基本原理">#</a> 持久化基本原理</h2><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207165444513.png" alt="image-20231207165444513"></p><p>Redis 持久化也称为<font color="red"> <code>钝化</code> ，是指将内存中数据库的状态描述信息保存到磁盘中</font>。只不过不同的持久化技术，对数据的状态描述信息是不同的，生成的持久化文件也是不同的。但它们的作用都是相同的：<font color="red">避免数据意外丢失</font>。</p><p>通过手动方式，或自动定时方式，或自动条件触发方式，将内存中数据库的状态描述信息写入到指定的持久化文件中。<font color="red">当系统重新启动时，自动加载持久化文件，并根据文件中数 \ 据库状态描述信息将数据恢复到内存中，这个数据恢复过程也称为 <code>激活</code> </font>。这个钝化与激活的过程就是 Redis 持久化的基本原理。</p><p>不过从以上分析可知，对于 Redis 单机状态下，无论是手动方式，还是定时方式或条件触发方式，都存在<font color="red"> <code>数据丢失问题</code> ：在尚未手动 / 自动保存时发生了 Redis 宕机状况，那么从上次保存到宕机期间产生的数据就会丢失</font>。不同的持久化方式，其数据的丢失率也是不同的。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207165853136.png" alt="image-20231207165853136"></p><p>需要注意的是，<strong><font color="red">RDB 是默认持久化方式</font></strong>。但 Redis 允许 RDB 与 AOF 两种持久化技术同时开启，此时系统会使用 AOF 方式做持久化，即<font color="red"> AOF 持久化技术的优先级要更高</font>。同样的道理，两种技术同时开启状态下，系统启动时若两种持久化文件同时存在，则优先加载 AOF 持久化文件。</p><h2 id="rdb-持久化"><a class="anchor" href="#rdb-持久化">#</a> RDB 持久化</h2><h3 id="rdb-简介"><a class="anchor" href="#rdb-简介">#</a> RDB 简介</h3><p>RDB（Redis DataBase）将内存中某一时刻的数据以 **<font color="red">全量快照</font>** 的形式写入磁盘中的<font color="red"> rdb 文件</font>。RDB 持久化默认是开启的。当 Redis 启动时会自动读取 rdb 快照文件，将数据从硬盘载入到内存，以恢复 Redis 关机前的数据库状态。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230806005245328.png" alt="image-20230806005245328"></p><h3 id="rdb-快照的触发方式"><a class="anchor" href="#rdb-快照的触发方式">#</a> RDB 快照的触发方式</h3><h4 id="手动-save-命令"><a class="anchor" href="#手动-save-命令">#</a> 手动 save 命令</h4><blockquote><p><strong>线上严禁使用！</strong></p></blockquote><p>通过在 redis-cli 客户端中手动执行 save 命令，可立即让 Redis 保存一次数据库的快照。<font color="red">但是，save 命令在执行期间<strong>会阻塞</strong> redis-server 进程，导致 Redis 不能处理任何读写请求，无法对外提供缓存服务，直至持久化过程完毕</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230806123508579.png" alt="image-20230806123508579"></p><h4 id="手动-bgsave-命令"><a class="anchor" href="#手动-bgsave-命令">#</a> 手动 bgsave 命令</h4><blockquote><p>默认使用</p></blockquote><p>通过在 redis-cli 客户端中执行 bgsave 命令，可立即让 Redis 保存一次数据库的快照。不同于 save 命令的是，正如该命令的名称一样，background save，后台运行 save。<font color="red">bgsave 命令会使服务器进程 redis-server 通过 fork () 生成一个子进程，由该子进程负责完成保存过程，<strong>不会阻塞</strong> redis-server 进程对客户端读写请求的处理</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230806145215893.png" alt="image-20230806145215893"></p><h4 id="自动条件触发"><a class="anchor" href="#自动条件触发">#</a> 自动条件触发</h4><blockquote><p>本质：<strong><font color="red">定时自动执行 bgsave 命令</font></strong></p></blockquote><p>用户可修改配置文件 <code>redis.conf</code> 中 SNAPSHOTTING 的 save 参数，从而设置自动触发快照的时间间隔。比如 <code>save m n</code> 表示每隔 m 秒检测一次数据集，如果检测出超过 n 次变化时，自动触发 RDB 持久化条件，执行快照。</p><blockquote><p>注意，这里说的是<strong>每隔 m 秒检测一次，<font color="red">对变化的计数是累加的</font>，只要在某次检测中发现变化数累加值达到 n 次，就会触发 RDB 持久化。<font color="red">而不是要求 n 次变化都集中发生在某个 m 秒内！</font></strong></p></blockquote><p><strong><font color="cornflowerblue">Redis 6.0.16 及之前</font></strong>：</p><ul><li>save 900 1：每隔 900s (15min) 检测一次，如果有超过 1 个 key 发生了变化，就写一份新的 RDB 文件</li><li>save 300 10：每隔 300s (5min) 检测一次，如果有超过 10 个 key 发生了变化，就写一份新的 RDB 文件</li><li>save 60 10000：每隔 60s (1min) 检测一次，如果有超过 10000 个 key 发生了变化，就写一份新的 RDB 文件</li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230806010837837.png" alt="image-20230806010837837"></p><p><strong><font color="cornflowerblue">Redis 6.0.16 以后至今</font></strong>：</p><ul><li>每隔 3600s（1hour）检测一次，如果有超过 1 处变化，就写一份新的 RDB 文件</li><li>每隔 300s（5min）检测一次，如果有超过 100 处变化，就写一份新的 RDB 文件</li><li>每隔 60s（1min）检测一次，如果有超过 10000 处变化，就写一份新的 RDB 文件</li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230806010819707.png" alt="image-20230806010819707"></p><h3 id="rdb-持久化过程工作机制"><a class="anchor" href="#rdb-持久化过程工作机制">#</a> RDB 持久化过程（工作机制）</h3><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230806145215893.png" alt="image-20230806145215893"></p><p>Redis 进行 bgsave 持久化时，服务器进程 redis-server 会执行以下操作:</p><ul><li>服务器进程（父进程）调用 <font color="red">forks</font> 生成一个 bgsave 子进程</li><li>bgsave 子进程调用 <font color="red">dump</font> 将内存数据写入到一个 RDB 临时文件中</li><li>新 RDB 文件<font color="red">覆盖</font>原来的 RDB 文件</li></ul><p>bgsave 子进程以 **<font color="red">异步方式</font>** 完成持久化，该过程<font color="red">不会阻塞 redis-server 进程</font>，Redis 可以继续接收并处理用户的读写请求。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/Redis%E5%86%99%E6%97%B6%E5%A4%8D%E5%88%B6.png" alt="Redis写时复制"></p><center>Redis写时复制</center><p>其中，bgsave 子进程的详细工作原理如下：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207202547716.png" alt="image-20231207202547716"></p><p>由于子进程可以继承父进程的所有资源，且父进程不能拒绝子进程的继承权。所以，bgsave 子进程有权读取到 redis-server 进程写入到内存中的用户数据，使得将内存数据持久化到 dump.rdb 成为可能。</p><p>bgsave 子进程在持久化时首先会将内存中的全量数据 <font color="red">copy</font> 到磁盘中的一个 RDB 临时文件，copy 结束后，再将该文件 <font color="red">rename</font> 为 dump.rdb，替换掉原来的同名文件。</p><p>不过，在进行持久化过程中，如果 redis-server 进程接收到了用户写请求，则系统会将内存中发生数据修改的物理块 copy 出一个副本。等内存中的全量数据 copy 结束后，会再将副本中的数据 copy 到 RDB 临时文件。这个副本的生成是由于 Linux 系统的<font color="red"><strong>写时复制技术</strong>（ <code>Copy-On-Write</code> ）</font>实现的。</p><blockquote><p>copy-on-write 是 Linux 系统的一种进程管理技术。</p><p>原本在 Unix 系统中，当一个主进程通过 fork () 系统调用创建子进程后，内核进程会<font color="red">复制主进程的整个内存空间中的数据，并将其分配给子进程</font>。这种方式存在的问题有以下几点：</p><ul><li>这个过程非常耗时</li><li>这个过程降低了系统性能</li><li>如果主进程修改了其内存数据，子进程副本中的数据是没有修改的。即出现了数据冗余，而冗余数据最大的问题是<font color="red">数据一致性</font>无法保证。</li></ul><p>现代的 Linux 则采用了更为有效的方式：<strong><font color="#B32015">写时复制</font></strong>。子进程会继承父进程的所有资源，其中就包括主进程的内存空间。即<font color="red">子进程与父进程共享内存</font>。只要内存被共享，那么该内存就是只读的（写保护的）。而 **<font color="red">写时复制则是在任何一方需要写入数据到共享内存时，都会出现异常，此时内核进程就会将需要写入的数据 copy 出一个副本，写入到另外一块非共享内存区域</font>**。</p></blockquote><h3 id="rdb-配置项"><a class="anchor" href="#rdb-配置项">#</a> RDB 配置项</h3><blockquote><p>RDB 相关的配置在配置文件 <code>redis.conf</code> 中的 SNAPSHOTTING 部分</p></blockquote><table><thead><tr><th>配置参数</th><th>介绍</th><th>示例</th></tr></thead><tbody><tr><td><code>save</code> &lt;seconds&gt; &lt;changes&gt;</td><td>设置快照自动触发的条件（<font color="red">时间间隔、变化数</font>）。默认情况下持久化条件为 save 3600 1 300 100 60 10000</td><td><code>save m n</code> 表示每隔 m 秒检测一次数据集，如果检测出超过 n 次变化（累积）时，自动触发 RDB 持久化条件，执行快照。</td></tr><tr><td><code>dbfilename</code></td><td>设置 rdb 文件的名称，默认为 dump.rdb</td><td>dbfilename dump.rdb</td></tr><tr><td><code>dir</code></td><td>设置 rdb 文件的保存路径，默认为 Redis 安装根目录</td><td>dir ./</td></tr><tr><td><code>stop-write-on-bgsave-error</code></td><td>当子进程执行快照保存出现错误时，<font color="red">是否让主进程停止接收新的写请求</font>，默认为 yes</td><td>stop-write-on-bgsave-error yes</td></tr><tr><td><code>rdbcompression</code></td><td>对于存储到磁盘中的快照，<font color="red">是否采用 LZF 算法对字符串对象进行压缩</font>，默认为 yes。可大幅降低文件的大小，方便保存到磁盘，加速主从集群中从节点的数据同步。</td><td>rdbcompression yes</td></tr><tr><td><code>rdbchecksum</code></td><td><font color="red">是否采用 CRC64 算法对快照文件进行数据校验</font>，默认为 yes</td><td>rdbchecksum yes</td></tr><tr><td><code>sanitize-dump-payload</code></td><td>设置在加载 RDB 文件或进行持久化时<font color="red">是否开启对 zipList、 listPack 等数据的全面安全检测</font>，该检测可以降低命令处理时发生系统崩溃的可能，默认为 no</td><td>sanitize-dump-payload clients 表示只有当客户端连接时检测，排除了加载 RDB 文件与进行持久化时的检测。</td></tr><tr><td><code>rdb-del-sync-files</code></td><td><font color="red">主从复制时，是否删除用于同步的从机上的 RDB 文件</font>。默认是 no，不删除。不过需要注意，只有当从机的 RDB 和 AOF 持久化功能都未开启时才生效。</td><td>rdb-del-sync-files no</td></tr></tbody></table><h3 id="rdb-文件结构"><a class="anchor" href="#rdb-文件结构">#</a> RDB 文件结构</h3><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207205049480.png" alt="image-20231207205049480"></p><p>RDB 持久化文件 dump.rdb 由五部分构成：</p><ul><li><p><font color="cornflowerblue">SOF（文件开始标识）</font>：是一个长度为 5 的字符串常量 &quot;REDIS&quot;，标识 RDB 文件的开始，以便在加载 RDB 文件时可以迅速判断出文件是否是 RDB 文件。</p></li><li><p><font color="cornflowerblue">rdb_version（文件版本号）</font>：是一个长度为 4 字节的整数</p></li><li><p><font color="cornflowerblue">EOF（文件结束标识）</font>：长度为 1 字节的常量，用于标识 RDB 数据的结束，校验和的开始。</p></li><li><p><font color="cornflowerblue">check_sum（校验和）</font>：<font color="red">用于判断 RDB 文件中是否出现数据异常</font>，采用的是 <font color="red">CRC 校验算法</font>。</p><blockquote><p>CRC 校验算法：</p><p>在持久化时，先将 SOF、rdb_version 及内存数据库中的数据快照这三者的二进制数据拼接起来，形成一个二进制数（假设称为数 a），然后再使用这个 a 除以校验和 check_sum，此时可获取到一个余数 b，然后再将这个 b 拼接到 a 的后面，形成 databases。</p><p>在加载时，需要先使用 check_sum 对 RDB 文件进行数据损坏验证。验证过程：只需将 RDB 文件中除 EOF 与 check_sum 外的数据除以 check_sum。只要除得的余数不是 0，就说明文件发生损坏。当然，如果余数是 0，也不能肯定文件没有损坏。</p><p><font color="red">这种验证算法，是数据损坏校验，而不是数据没有损坏的校验</font>。</p></blockquote></li><li><p><strong><font color="cornflowerblue">databases（数据库）</font></strong>：可以包含任意多个非空数据库 database，每个 database 又由三部分构成：</p><ul><li><p><font color="blue">SODB（数据库开始标识）</font></p></li><li><p><font color="blue">db_number（数据库编号）</font></p></li><li><p><font color="blue">key_value_pairs（键值对数据）</font>：每个键值对又由多个描述数据构成：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207211310010.png" alt="image-20231207211310010"></p><ul><li>VALUE_TYPE</li><li>EXPIRETIME_UNIT（过期时间的单位）</li><li>time（当前键值对的过期时间）</li></ul></li></ul></li></ul><h3 id="rdb-优缺点"><a class="anchor" href="#rdb-优缺点">#</a> RDB 优缺点</h3><p>RDB 持久化的优点：</p><ul><li>适合<font color="red">大规模</font>的数据恢复</li><li>按照业务，<font color="red">定时备份</font></li><li>对数据完整性和一致性要求不高</li><li>dump.rdb 文件在内存中的<font color="red">加载速度</font>要比 AOF 快得多</li></ul><p>RDB 持久化的缺点：</p><ul><li>一定间隔时间做一次备份，所以如果 Redis 意外 down 掉的话，就会丢失从当前至最近一次快照期间的数据，<strong><font color="red">快照之间的数据会丢失</font></strong></li><li>内存数据的全量同步，如果数据量太大会导致<font color="red"> I/O 严重影响服务器性能</font></li><li>RDB 依赖于主进程的 fork，在更大的数据集中，这可能会导致<font color="red">服务请求的瞬间延迟</font></li><li>fork 的时候内存中的数据被克降了一份，<font color="red">大致 2 倍的数据膨胀性</font>，需要考虑</li></ul><h3 id="如何禁用-rdb"><a class="anchor" href="#如何禁用-rdb">#</a> 如何禁用 RDB</h3><p>将配置文件中的 save 参数设置为空串 &quot;&quot;，有两种方式：</p><ul><li><p>命令： <code>res-cli config set save &quot;&quot;</code></p></li><li><p>修改配置文件：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230806152126685.png" alt="image-20230806152126685"></p></li></ul><h3 id="如何恢复-rdb-文件"><a class="anchor" href="#如何恢复-rdb-文件">#</a> 如何恢复 RDB 文件</h3><p>当 dump.rdb 文件破损时可以使用 <code>redis-check-rdb</code> 命令进行修复。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230806151515656.png" alt="image-20230806151515656"></p><h3 id="rdb-小结"><a class="anchor" href="#rdb-小结">#</a> RDB 小结</h3><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230806153628002.png" alt="image-20230806153628002"><h2 id="aof-持久化"><a class="anchor" href="#aof-持久化">#</a> AOF 持久化</h2><h3 id="aof-简介"><a class="anchor" href="#aof-简介">#</a> AOF 简介</h3><blockquote><p>动机：对于 RDB 持久化的快照，如果 Redis 因为某些原因而造成故障停机，那么服务器<font color="red">将丢失最近写入、但仍未保存到快照中的那些数据</font>。因此，Redis 增加了一种 **<font color="red">完全耐久、实时性更好</font>** 的持久化方式：AOF 持久化。</p></blockquote><p>AOF（ <code>A</code> ppend <code>O</code> nly <code>F</code> ile）<font color="red">以<strong>日志文件</strong>（ <code>appendonly.aof</code> 文件）的形式来<strong>追加</strong>记录 Redis 执行过的每个<strong>写操作指令</strong></font>。Redis 重启时就根据日志文件的内容将写指令从前到后重新执行一次，以完成数据的恢复工作。</p><p><font color="red">Redis 6.0 之前默认关闭 AOF，Redis 6.0 之后默认开启 AOF</font>。开启 AOF 功能需要在配置文件 <code>redis.conf</code> 中设置配置: <code>appendonly yes</code> 。</p><h3 id="aof-文件格式"><a class="anchor" href="#aof-文件格式">#</a> AOF 文件格式</h3><p>从 Redis 7 开始，采用 <strong><font color="#B32015">Multi Part AOF</font></strong> 机制，将原来的单个 AOF 文件拆分成三类多个 AOF 文件：</p><ul><li><font color="gree">基本文件（base.rdb/aof）</font>：可以是 RDB / AOF 格式，默认为 RDB 格式，即混合式持久化。一般由子线程通过 rewrite 产生，该文件最多只有一个。</li><li><font color="gree">增量文件（incr.aof）</font>：以操作日志形式记录写命令，一般在 rewrite 开始执行时创建，该文件可以有多个。</li><li>历史文件：由 BASE 和 INCR AOF 变化而来，每次 AOFRW 成功完成时，本次 AOFRW 之前对应的 BASE 和 INCR AOF 都将变为 HISTORY，HISTORY 类型的 AOF 会被 Redis 自动删除。</li></ul><p>此外，还有<font color="gree">清单文件（manifest）</font>：该文件首先会按照 seq 序号列举出所有<font color="red">基本文件</font>，基本文件 type 类型为 b，然后再按照 seq 序号再列举出所有<font color="red">增量文件</font>，增量文件 type 类型为 i。对于 Redis 启动时的数据恢复，也会按照该文件由上到下依次加载它们中的数据。可以维护 AOF 文件的创建顺序，保障激活时的应用顺序。</p><p>其中基本文件一般为 rdb 格式，在前面已经研究过了。下面就来看一下增量文件与清单文件的内容格式。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230806210712843.png" alt="image-20230806210712843"></p><h3 id="aof-配置项"><a class="anchor" href="#aof-配置项">#</a> AOF 配置项</h3><table><thead><tr><th>配置参数</th><th>介绍</th><th>示例</th></tr></thead><tbody><tr><td><code>appendonly</code></td><td>是否开启 AOF</td><td>appendonly yes</td></tr><tr><td><code>appendfilename</code></td><td>设置 AOF 文件的名称</td><td>appendfilename &quot;appendonly.aof&quot;</td></tr><tr><td><code>aof-use-rdb-preamble</code></td><td>设置基本文件为 RDF 格式 / AOF 格式，<font color="red">默认为 yes（RDB 格式），即混合式持久化</font></td><td>aof-use-rdb-preamble yes</td></tr><tr><td><code>appenddirname</code></td><td>设置 AOF 文件目录，默认为 Redis 安装目录</td><td>appenddirname &quot;appendonlydir&quot;</td></tr><tr><td><code>appendfsync</code></td><td>设置同步方式（刷盘时机）</td><td>appendfsync <font color="red">always/everysec/no</font></td></tr><tr><td><code>no-appendfsync-on-rewrite</code></td><td>AOF rewrite 期间是否同步（刷盘）</td><td></td></tr><tr><td><code>auto-aof-rewrite-percentage</code><br><code>auto-aof-rewrite-min-size</code></td><td>rewrite 触发配置、文件重写策略</td><td>auto-aof-rewrite-percentage 100<br>auto-aof-rewrite-min-size 64mb</td></tr></tbody></table><h3 id="aof-持久化过程工作基本流程"><a class="anchor" href="#aof-持久化过程工作基本流程">#</a> AOF 持久化过程（工作基本流程）</h3><p>AOF 持久化功能的实现可以简单分为 5 步：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231208165553752.png" alt="image-20231208165553752"></p><center>AOF 工作基本流程</center><ol><li><p><strong><font color="#B32015">命令追加（append）</font></strong>：所有的写命令会 <code>append</code> 到内存中的<font color="gree"> AOF 缓冲区</font>。</p></li><li><p><strong><font color="#B32015">文件写入（write）</font></strong>：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用 <code>write</code> 函数（系统调用）将数据写入到了<font color="gree">系统内核缓冲区</font>之后<font color="red">直接返回了（延迟写）</font>。注意！！！<font color="red">此时并没有同步到磁盘</font>。</p></li><li><p><strong><font color="#B32015">文件同步（fsync）</font></strong>：AOF 缓冲区根据对应的持久化方式（ <code>fsync</code> 策略）向<font color="gree">硬盘</font>做同步操作。这一步需要调用 <code>fsync</code> 函数（系统调用）， <code>fsync</code> 针对单个文件操作，对其进行强制硬盘同步， <code>fsync</code> 将<font color="red">阻塞</font>直到写入磁盘完成后返回，保证了数据持久化。</p></li><li><p><strong><font color="#B32015">文件重写（rewrite）</font></strong>：随着<font color="red">磁盘上</font>的 AOF 文件越来越大，到达 rewrite 条件时，主线程会 fork 一个子线程 bgrewriteaof 定期 AOF 文件进行重写（<font color="red">根据规则去合并写命令</font>），达到<font color="red">压缩</font>的目的。</p><blockquote><p>如果在 rewrite 过程中又有写操作命令追加，那么这些数据会暂时写入 aof_rewrite_buf 缓冲区。等将全部 rewrite 计算结果写入临时文件后，会先将 aof_rewrite_buf 缓冲区中的数据写入临时文件，然后再 rename 为磁盘文件的原名称，覆盖原文件。</p></blockquote></li><li><p><strong><font color="#B32015">重启加载（load）</font></strong>：当 Redis 重启时，可以加载磁盘上的 AOF 文件，执行其中的写命令，进行数据恢复。</p></li></ol><blockquote><p>Linux 系统直接提供了一些函数用于对文件和设备进行访问和控制，这些函数被称为<strong>系统调用（syscall）</strong>。</p></blockquote><p>这里对上面提到的一些 Linux 系统调用再做一遍解释：</p><ul><li><code>write</code> ：<font color="red">写入系统内核缓冲区之后直接返回（仅仅是写到缓冲区），不会立即同步到硬盘</font>。虽然提高了效率，但也带来了<font color="red">数据丢失的风险</font>。同步硬盘操作通常依赖于系统调度机制，Linux 内核通常为 30s 同步一次，具体值取决于写出的数据量和 I/O 缓冲区的状态。</li><li><code>fsync</code> ：用于<font color="red">强制刷新系统内核缓冲区（同步到到磁盘）</font>，会一直阻塞直到确保写磁盘操作结束才会返回。</li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231208170306808.png" alt="image-20231208170306808"></p><h3 id="aof-缓冲区的三种写回刷盘策略fsync-策略"><a class="anchor" href="#aof-缓冲区的三种写回刷盘策略fsync-策略">#</a> AOF 缓冲区的三种写回 / 刷盘策略（ <code>fsync</code> 策略）</h3><blockquote><p>主要区别在于 <strong><font color="red">fsync 同步 AOF 文件的时机（刷盘）</font></strong></p></blockquote><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231208165553752.png" alt="image-20231208165553752"></p><p>AOF 缓冲区需要将它保存的写命令写入磁盘上的 AOF 文件，可以修改配置文件中的 <code>参数 appendfsync</code> ，有三种策略：</p><ul><li><code>always</code> ：<strong><font color="gree">同步写回</font></strong>，主线程调用 write 后，后台线程会立即调用 fsync 函数同步 AOF 文件（刷盘）。fsync 完成后线程返回，这会严重降低 Redis 的性能<font color="red">（write + fsync）</font></li><li><code>everysec</code> ：<strong><font color="gree">每秒写回</font></strong>，主线程调用 write 后立即返回，由后台线程每秒调用 fsync 函数同步一次 AOF 文件<font color="red">（write + fsync，其中 fsync 间隔为 1 秒）</font></li><li><code>no</code> ：<strong><font color="gree">操作系统控制的写回</font></strong>，主线程调用 write 后立即返回，让操作系统决定何时进行同步（刷盘）。Linux 中一般为 30 秒一次<font color="red">（write 但不 fsync，其中 fsync 的时机由操作系统决定）</font></li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230806200107294.png" alt="image-20230806200107294"></p><h3 id="aof-重写机制rewrite"><a class="anchor" href="#aof-重写机制rewrite">#</a> <mark>🌟AOF 重写机制（Rewrite）</mark></h3><h4 id="何为-rewrite"><a class="anchor" href="#何为-rewrite">#</a> 何为 rewrite</h4><p>当 AOF 变得太大时，Redis 能够在后台产生一个新的 AOF 文件，该文件与原有的 AOF 文件所保存的<font color="red">数据库状态一样，但体积更小</font>。</p><blockquote><p>AOF 重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。</p></blockquote><p><font color="orange">AOF 重写机制</font>：启动 AOF 文件的内容压缩，<font color="red">合并其中的命令，只保留可以恢复数据的最小指令集</font>。</p><blockquote><p><strong><font color="red">重写完成后</font></strong>：</p><ul><li>重写结果被保存到一个新的 BASE AOF 文件中，文件名上的标号加 1。</li><li>同时，新建一个空的 INCR AOF 文件，文件名上的标号加 1，旧的被删除。</li></ul></blockquote><h4 id="rewrite-触发方式"><a class="anchor" href="#rewrite-触发方式">#</a> rewrite 触发方式</h4><p>AOF 重写机制有<font color="red">两种触发方式</font>：</p><ul><li><p><font color="cornflowerblue">自动触发</font>：当 INCR AOF 文件<font color="red">同时满足</font>以下两个条件时，Redis 就会<font color="red">自动</font>启动重写机制，只保留可以恢复数据的最小指令集</p><blockquote><p>INCR AOF 文件负责记录从 AOF 缓冲区写回的写命令</p></blockquote><ul><li>当 INCR AOF 文件的大小超过上一次重写结果（即 BASE AOF 文件）大小 1 倍（可以通过配置 <code>auto-aof-rewrite-percentage</code> 修改）</li><li>当 INCR AOF 文件的大小超过 64MB（可以通过配置 <code>auto-aof-rewrite-min-size</code> 修改）</li></ul></li><li><p><font color="cornflowerblue">手动触发</font>：可以手动使用命令 <code>bgrewriteaof</code> 来重写。</p></li></ul><p>具体过程见脑图，这里只演示 AOF 重写后的效果：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807004504357.png" alt="image-20230807004504357"></p><center>自动重写</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807004613263.png" alt="image-20230807004613263"></p><center>手动重写</center><p>结论：</p><ul><li>AOF 文件重写并不是对原文件进行重新整理，而是<font color="red">直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令</font>，生成一个新的文件后去替换原来的 AOF 文件。</li><li>AOF 文件重写触发机制：通过 redis.conf 配置文件中的 <code>auto-aof-rewrite-percentage</code> : 默认值为 100，以及 <code>auto-aof-rewrite·min-size</code> : 64mb 配置，也就是说默认 Redis 会记录上次重写时的 AOF 大小，默认配置是当 AOF 文件大小是上次 rewrite 后大小的一倍<strong>且</strong>文件大于 64M 时触发。</li></ul><h4 id="rewrite-原理"><a class="anchor" href="#rewrite-原理">#</a> rewrite 原理</h4><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/2032648-20220207170749957-1755223036.png" alt="img"></p><ol><li><p>在重写开始前，Redis 会创建一个重写子进程 <code>bgrewriteaof</code> ，这个子进程会读取现有的 AOF 文件，并将其包含的指令进行<font color="red">分析、压缩</font>，写入到一个临时文件中。</p></li><li><p>与此同时，主进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的 AOF 文件中，这样做是保证原有的 AOF 文件的可用性，避免在重写过程中出现意外。</p></li><li><p>当重写子进程完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新 AOF 文件中</p></li><li><p>当追加结束后，Redis 就会用新 AOF 文件来<font color="red">代替</font>旧 AOF 文件，之后再有新的写指令，就都会追加到新的 AOF 文件中</p></li><li><p>重写 AOF 文件的操作，并没有读取旧的 AOF 文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的 AOF 文件，这点和快照有点类似</p></li></ol><h3 id="aof-校验机制"><a class="anchor" href="#aof-校验机制">#</a> AOF 校验机制</h3><p>AOF 校验机制是 Redis 在启动时对 AOF 文件进行检查，以<font color="red">判断文件是否完整，是否有损坏或者丢失的数据</font>。这个机制的原理其实非常简单，就是通过使用一种叫做 **<font color="#B32015">校验和（checksum）</font>** 的数字来验证 AOF 文件。这个校验和是通过对整个 AOF 文件内容进行<font color="red"> CRC64 算法</font>计算得出的数字。如果文件内容发生了变化，那么校验和也会随之改变。因此，Redis 在启动时会比较计算出的校验和与文件末尾保存的校验和（计算的时候会把最后一行保存校验和的内容给忽略点），从而判断 AOF 文件是否完整。如果发现文件有问题，Redis 就会拒绝启动并提供相应的错误信息。AOF 校验机制十分简单有效，可以提高 Redis 数据的可靠性。</p><p>类似地，<font color="red">RDB 文件也有类似的校验机制</font>来保证 RDB 文件的正确性，这里就不重复进行介绍了。</p><h3 id="aof-记录日志过程"><a class="anchor" href="#aof-记录日志过程">#</a> AOF 记录日志过程</h3><p>关系型数据库（如 MySQL）通常都是执行命令之前记录日志（方便故障恢复），而 <font color="red">Redis AOF 持久化机制是在执行完命令之后再记录日志</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-aof-write-log-disc.png" alt="AOF 记录日志过程"></p><center>AOF 记录日志过程</center><p><strong>为什么是在执行完命令之后记录日志呢？</strong></p><ul><li><font color="red">避免额外的检查开销</font>，AOF 记录日志不会对命令进行语法检查；</li><li>在命令执行完之后再记录，<font color="red">不会阻塞当前的命令执行</font>。</li></ul><p>这样也带来了风险（我在前面介绍 AOF 持久化的时候也提到过）：</p><ul><li>如果刚执行完命令 Redis 就宕机<font color="red">会导致对应的修改丢失</font>；</li><li><font color="red">可能会阻塞后续其他命令的执行</font>（AOF 记录日志是在 Redis 主线程中进行的）。</li></ul><h3 id="aof-优缺点"><a class="anchor" href="#aof-优缺点">#</a> AOF 优缺点</h3><p>AOF 有以下优点：</p><ul><li><p>更好地保护数据不丢失</p><blockquote><p>使用 AOF Redis 更加持久∶您可以有<font color="red">不同的 fsync 策略</font>：根本不 fsync、每秒 fsync、每次查询时 fsync。使用每秒 fsync 的默认策略，写入性能仍然很棒。fsync 是使用后台线程执行的，当没有 fsync 正在进行时，主线程将努力执行写入，因此您<font color="red">只能丢失一秒钟的写入</font>。</p></blockquote></li><li><p>易修复</p><blockquote><p>AOF 日志是一个仅附加日志，因此不会出现寻道问题，也不会在断电时出现损坏问题。即使由于某种原因（磁盘已满或其他原因）日志以写一半的命令结尾， <code>redis-check-aof</code> 工具也能够轻松修复它。</p></blockquote></li><li><p>得益于 AOF 的重写机制，能够自我压缩</p><blockquote><p>当 AOF 变得太大时，Redis 能够在后台自动重写 AOF。重写是完全安全的，因为当 Redis 继续附加到旧文件时，会使用创建当前数据集所需的最少操作集生成一个全新的文件，一旦第二个文件准备就绪，Redis 就会切换两者并开始附加到新的那一个。</p></blockquote></li><li><p>性能高</p></li><li><p>文件内容易理解</p><blockquote><p>AOF 以易于理解和解析的格式依次包含所有操作的日志。您甚至可以轻松导出 AOF 文件。</p></blockquote></li><li><p>可做紧急恢复</p><blockquote><p>即使您不小心使用该 <code>FLUSHALL</code> 命令刷新了所有内容，只要在此期间没有执行日志重写，您仍然可以通过停止服务器、<font color="red">删除最新命令</font>并重新启动 Redis 来保存您的数据集。</p></blockquote></li></ul><p>AOF 有以下缺点：</p><ul><li>对于相同的数据集而言，aof 文件要 **<font color="red">远大于 rdb 文件</font>，<font color="red">恢复速度慢于 rdb</font>**</li><li>aof**<font color="red">运行效率要慢于 rdb</font>**，每秒同步策略效率较好，不同步效率和 rdb 相同</li></ul><h3 id="aof-小结"><a class="anchor" href="#aof-小结">#</a> AOF 小结</h3><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807005534144.png" alt="image-20230807005534144"></p><h2 id="rdb-aof-混合持久化"><a class="anchor" href="#rdb-aof-混合持久化">#</a> RDB-AOF 混合持久化</h2><p>Redis**<font color="red">默认仅使用 RDB 持久化</font><strong>，禁用 AOF 持久化。但是，当我们</strong><font color="red">手动启用 AOF 持久化后，AOF 的优先级高于 RDB</font>**！对应的数据恢复顺序和加载流程如下图：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207165853136.png" alt="image-20231207165853136"></p><h2 id="rdb-与-aof-对比持久化技术选型"><a class="anchor" href="#rdb-与-aof-对比持久化技术选型">#</a> <mark>🌟RDB 与 AOF 对比（持久化技术选型）</mark></h2><blockquote><p>RDB：定时一锅端</p></blockquote><p>二者各自的特点如下：</p><ul><li><font color="cornflowerblue">RDB 持久化（定时一锅端）</font>：能够在指定的时间间隔对数据库进行全量快照存储</li><li><font color="cornflowerblue">AOF 持久化（实时记录写命令）</font>：记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，命令以 Redis 协议追加保存每次写的操作到文件末尾。</li></ul><p>RDB 优点：</p><ul><li>RDB 文件较小</li><li>数据恢复速度快</li></ul><p>RDB 不足：</p><ul><li>数据安全性较差</li><li>写时复制会降低性能</li><li>RDB 文件的可读性较差</li></ul><p>AOF 优点：</p><ul><li>数据安全性高（仅追加新执行的写命令）</li><li>AOF 文件的可读性强，以一种易于理解和解析的格式包含所有写操作的日志</li></ul><p>AOF 不足：</p><ul><li>AOF 文件较大</li><li>数据恢复速度慢</li><li>写操作会影响性能</li></ul><p>RDB + AOF 同时开启时的情况：</p><ul><li>当 redis 重启的时候会<font color="red">优先载入 AOF 文件</font>来恢复原始的数据，因为在通常情况下 AOF 文件保存的数据集要比 RDB 文件保存的数据集<font color="red">更完整</font></li><li>RDB 的数据不实时，同时使用两者时服务器重启也只会找 AOF 文件。<font color="red">但是作者建议不要只使用 AOF</font>，因为 RDB 更适合用于备份数据库 (AOF 在不断变化不好备份)，<font color="red">留着 rdb 以防万一</font></li></ul><p>综上，</p><ul><li><p><strong><font color="orange">官方推荐 RDB+AOF 混合方式</font></strong>，既能快速加载又能避免丢失过多的数据。配置方式：</p><ol><li><p>对应配置文件中的 <code>aof-use-rdb-preamble</code> ，默认为 yes</p></li><li><p><font color="red">开启 AOF 持久化</font>，对应配置文件中的 <code>appendonly</code> 设置为 yes，默认为 no</p></li></ol></li><li><p>若对数据安全性要求不高，则推荐使用纯 RDB 持久化方式</p></li><li><p>不推荐使用纯 AOF 持久化方式，因为 RDB 更适合备份数据库</p></li><li><p>若 Redis 仅用于缓存，则无需使用任何持久化技术</p></li></ul><blockquote><p>采用 RDB+AOF 混合持久化时，<font color="red">RDB 做<strong>全量</strong>持久化，AOF 做<strong>增量</strong>持久化</font>：</p><ul><li>先使用 RDB 进行快照存储</li><li>然后使用 AOF 持久化记录所有的写操作</li><li>当重写策略满足或手动触发重写的时候，将最新的数据存储为新的 RDB 记录。</li><li>这样的话，重启服务的时候会从 RDB 和 AOF 两部分恢复数据，既保证了数据完整性，又提高了恢复数据的性能。</li></ul><p>简单来说：混合持久化方式产生的文件一部分是 RDB 格式，一部分是 AOF 格式。<strong>----》<font color="red">AOF 包括了 RDB 头部 + AOF 混写</font></strong></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807011820642.png" alt="image-20230807011820642"></p></blockquote><h2 id="纯缓存模式"><a class="anchor" href="#纯缓存模式">#</a> 纯缓存模式</h2><blockquote><p>Redis 作为基于 key-value 的内存数据库，<strong>Redis 最主要的功能是用作缓存</strong>，而 Redis 持久化会消耗 Redis 的性能，因此可以<strong>同时关闭 RDB+AOF</strong>。</p></blockquote><p><strong><font color="cornflowerblue">禁用 RDB</font></strong>：</p><blockquote><p>此时仍然可以手动使用命令 <code>SAVE</code> 和 <code>BGSAVE</code> 生成 rdb 文件</p></blockquote><ul><li><p>命令： <code>res-cli config set save &quot;&quot;</code></p></li><li><p>修改配置文件：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807012414863.png" alt="image-20230807012414863"></p></li></ul><p><strong><font color="cornflowerblue">禁用 AOF</font></strong>：</p><blockquote><p>此时仍然可以手动使用命令 <code>BGREWRITEAOF</code> 生成 aof 文件</p></blockquote><ul><li>命令： <code>res-cli config set appendonly no</code></li><li>修改配置文件：将 <code>redis.conf</code> 中 APPEND ONLY MODE 模块下的 <code>参数appendonly</code> 设置为 no</li></ul><h1 id="redis-线程io模型"><a class="anchor" href="#redis-线程io模型">#</a> Redis 线程（IO）模型</h1><p>Redis 客户端提交的各种请求是如何最终被 Redis 处理的？<font color="red">Redis 处理客户端请求所采用的处理架构，称为 Redis 的 IO 模型</font>。不同版本的 Redis 采用的 IO 模型是不同的。</p><p>对于读写命令来说，Redis 一直是单线程模型。不过，<font color="red">在 Redis 4.0 版本之后引入了多线程来执行一些大键值对的异步删除操作</font>，<font color="red">Redis 6.0 版本之后引入了多线程来处理网络请求（提高网络 IO 读写性能）</font>。</p><h2 id="单线程模型"><a class="anchor" href="#单线程模型">#</a> 单线程模型</h2><blockquote><p>Redis 3.0 及其以前版本</p></blockquote><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231208205447709.png" alt="image-20231208205447709"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231208210519289.png" alt="image-20231208210519289"></p><p>Redis 的单线程模型：<font color="red">所有客户端的请求全部由一个线程处理</font>，采用了 <strong><font color="#B32015">IO 多路复用（multiplexing）技术</font></strong>。</p><p>Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为 **<font color="cornflowerblue">文件事件处理器（file event handler）</font>**。</p><ul><li>文件事件处理器使用<font color="cornflowerblue"> I/O 多路复用程序</font>来同时监听多个<font color="cornflowerblue">套接字（socket）</font>，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。</li><li>当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。</li></ul><p>文件事件处理器（file event handler）主要是包含 4 个部分：</p><ul><li>多个 socket（客户端连接）</li><li>IO 多路复用程序（支持多个客户端连接的关键）</li><li>文件事件分派器（将 socket 关联到相应的事件处理器）</li><li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-event-handler.png" alt="文件事件处理器（file event handler）"></p><center>文件事件处理器（file event handler）</center><p><strong><font color="#B32015">虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字</font></strong>，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。</p><blockquote><p>IO 多路复用技术是一种处理多个 IO 流的技术。它允许单个进程同时监视多个文件描述符（file descriptor，fd），当一个或多个 fd 准备好读或写时，它就可以立即响应。这种技术可以提高系统的并发性和响应能力，减少系统资源的浪费。</p><p>在 Linux 中，epoll、select、poll 都是 IO 多路复用的实现方式，都可以监视多个 fd，一旦某个 fd 就绪 (一般是读就绪或者写就绪)，能够通知程序进行相应的读写操作。</p><p>对于 IO 多路复用的实现方式常见的有三种：</p><ul><li><font color="cornflowerblue">select 模型</font>：最早的 IO 多路复用机制，<font color="red">同时监视 fd 的数量不超过 1024 个，而且每次只能监视一部分 fd 的状态变化</font>。</li><li><font color="cornflowerblue">poll 模型</font>：与 select 类似，采用的是<font color="red">轮询算法</font>，但是可以同时监视 fd 的数量更多（65536 个），该模型对客户端的就绪处理是有延迟的。</li><li><font color="cornflowerblue">epoll 模型</font>：是 Linux 所特有的，采用的是<font color="red">回调方式</font>，支持更多的 fd 数量（8192 个），根据就绪事件发生后的处理方式的不同，又可分为 LT 模型与 ET 模型。</li></ul></blockquote><p>每个<font color="gree">客户端</font>若要向 Redis 提交请求，都需要与 Redis 建立一个 <font color="gree">socket 连接</font>，并向<font color="gree">事件分发器</font>注册一个事件。一旦该事件发生就表明该连接已经就绪。而一旦连接就绪，事件分发器就会感知到，然后获取客户端通过该连接发送的请求，并将由该事件分发器所绑定的这个<font color="red">唯一的线程</font>来处理。如果该线程还在处理多个任务，则将该任务写入到<font color="gree">任务队列</font>等待线程处理。</p><p>之所以称为事件分发器，是因为它会根据不同的就绪事件，将任务交由不同的<font color="gree">事件处理器</font>去处理。</p><h2 id="混合线程模型"><a class="anchor" href="#混合线程模型">#</a> 混合线程模型</h2><blockquote><p>Redis 4.0 开始</p></blockquote><p>从 Redis 4.0 版本开始，Redis 中就开始加入了多线程元素。处理客户端请求的仍是单线程模型，但<font color="red">对于一些比较耗时但又不影响对客户端的响应的操作，就由后台其它线程来处理</font>。例如，持久化、对 AOF 的 rewrite、对失效连接的清理等。</p><h2 id="多线程模型"><a class="anchor" href="#多线程模型">#</a> 多线程模型</h2><blockquote><p>Redis 6.0 开始</p></blockquote><p><font color="red">Redis 6.0 版本，才是真正意义上的多线程模型</font>。因为其 **<font color="red">对于客户端请求的处理采用的是多线程模型</font>**。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231208211428194.png" alt="image-20231208211428194"></p><p>多线程 IO 模型中的<font color="red">“多线程” 仅用于接受、解析客户端的请求，然后将解析出的请求写入到任务队列</font>。而 **<font color="red">对具体任务（命令）的处理，仍是由主线程处理</font>**。这样做使得用户无需考虑线程安全问题，无需考虑事务控制，无需考虑像 LPUSH/LPOP 等命令的执行顺序问题。</p><h2 id="优缺点总结"><a class="anchor" href="#优缺点总结">#</a> 优缺点总结</h2><p>单线程模型：</p><ul><li>优点：<ul><li>可维护性高</li><li>不存在并发读写情况，所以也就不存在执行顺序的不确定性，不存在线程切换开销，不存在死锁问题，不存在为了数据安全而进行的加锁 / 解锁<br>开销</li></ul></li><li>缺点：<ul><li>性能低</li><li>会形成处理器浪费（单线程只能使用一个处理器）</li></ul></li></ul><p>多线程模型：</p><ul><li>优点：<ul><li>结合了多线程与单线程的优点，避开了它们的所有不足</li></ul></li><li>缺点：<ul><li>非是一个真正意义上的 “多线程”，因为真正处理 “任务” 的线程仍是单线程。所以，其对性能也是有些影响的。</li></ul></li></ul><h2 id="redis-60-之前为什么不使用多线程"><a class="anchor" href="#redis-60-之前为什么不使用多线程">#</a> Redis 6.0 之前为什么不使用多线程？</h2><p>虽然说 Redis 是单线程模型，但是实际上，<strong>Redis 在 4.0 之后的版本中就已经加入了对多线程的支持。</strong></p><p>不过，<font color="red">Redis 4.0 增加的多线程主要是针对一些大键值对的删除操作的命令</font>，使用这些命令就会使用主线程之外的其他线程来 “异步处理”。</p><p>为此，Redis 4.0 之后新增了 <code>UNLINK</code> （可以看作是 <code>DEL</code> 的异步版本）、 <code>FLUSHALL ASYNC</code> （清空所有数据库的所有 key，不仅仅是当前 <code>SELECT</code> 的数据库）、 <code>FLUSHDB ASYNC</code> （清空当前 <code>SELECT</code> 数据库中的所有 key）等异步命令。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis4.0-more-thread.png" alt="redis4.0 more thread"></p><center>redis4.0 more thread</center><p>大体上来说，Redis 6.0 之前主要还是单线程处理。</p><p><strong>那 Redis6.0 之前为什么不使用多线程？</strong> 我觉得主要原因有 3 点：</p><ul><li><font color="red">单线程编程容易并且更容易维护</font>；</li><li>Redis 的性能瓶颈不在 CPU ，主要在内存和网络；</li><li><font color="red">多线程就会存在死锁、线程上下文切换等问题</font>，甚至会影响性能。</li></ul><p>相关阅读：<span class="exturl" data-url="aHR0cHM6Ly9kcmF2ZW5lc3MubWUvd2h5cy10aGUtZGVzaWduLXJlZGlzLXNpbmdsZS10aHJlYWQv">为什么 Redis 选择单线程模型？</span></p><h2 id="redis60-之后为何引入了多线程"><a class="anchor" href="#redis60-之后为何引入了多线程">#</a> Redis6.0 之后为何引入了多线程？</h2><p><strong><font color="red">Redis6.0 引入多线程主要是为了提高网络 IO 读写性能</font></strong>，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。</p><p>虽然，Redis6.0 引入了多线程，<font color="red">但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行</font>。因此，你也不需要担心线程安全问题。</p><p><font color="red">Redis6.0 的多线程默认是禁用的，只使用主线程</font>。如需开启需要设置 IO 线程数 &gt; 1，需要修改 redis 配置文件 <code>redis.conf</code> ：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>io-threads <span class="token number">4</span> <span class="token comment">#设置 1 的话只会开启主线程，官网建议 4 核的机器建议设置为 2 或 3 个线程，8 核的建议设置为 6 个线程</span></pre></td></tr></table></figure><p>另外：</p><ul><li>io-threads 的个数一旦设置，不能通过 config 动态设置。</li><li>当设置 ssl 后，io-threads 将不工作。</li></ul><p>开启多线程后，默认只会使用多线程进行 IO 写入 writes，即发送数据给客户端，如果需要开启多线程 IO 读取 reads，同样需要修改 redis 配置文件 <code>redis.conf</code> :</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>io-threads-do-reads <span class="token function">yes</span></pre></td></tr></table></figure><p>但是 **<font color="red">官网描述开启多线程读并不能有太大提升，因此一般情况下并不建议开启</font>**。</p><p>相关阅读：</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvRlp1M2Fjd0s2enJDQlpRXzNIb1Vndw==">Redis 6.0 新特性 - 多线程连环 13 问！</span></li><li><span class="exturl" data-url="aHR0cHM6Ly9zZWdtZW50ZmF1bHQuY29tL2EvMTE5MDAwMDAzOTIyMzY5Ng==">Redis 多线程网络模型全面揭秘</span>（推荐）</li></ul><h2 id="redis-后台线程了解吗"><a class="anchor" href="#redis-后台线程了解吗">#</a> Redis 后台线程了解吗？</h2><p>我们虽然经常说 Redis 是单线程模型（主要逻辑是单线程完成的），但实际还有一些后台线程用于执行一些比较耗时的操作：</p><ul><li><code>bio_close_file</code> 后台线程：释放 AOF / RDB 等过程中产生的临时文件资源。</li><li><code>bio_aof_fsync</code> 后台线程：调用 <code>fsync</code> 函数将系统内核缓冲区还未同步到到磁盘的数据强制刷到磁盘（ AOF 文件）。</li><li><code>bio_lazy_free</code> 后台线程：释放大对象（已删除）占用的内存空间。</li></ul><p>在 <code>bio.h</code> 文件中有定义（Redis 6.0 版本，源码地址：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JlZGlzL3JlZGlzL2Jsb2IvNi4wL3NyYy9iaW8uaCVFRiVCQyU4OSVFRiVCQyU5QQ==">https://github.com/redis/redis/blob/6.0/src/bio.h）：</span></p><figure class="highlight java"><figcaption data-lang="java"></figcaption><table><tr><td data-num="1"></td><td><pre>#ifndef __BIO_H</pre></td></tr><tr><td data-num="2"></td><td><pre>#define __BIO_H</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">/* Exported API */</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">void</span> <span class="token function">bioInit</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">void</span> <span class="token function">bioCreateBackgroundJob</span><span class="token punctuation">(</span><span class="token keyword">int</span> type<span class="token punctuation">,</span> <span class="token keyword">void</span> <span class="token operator">*</span>arg1<span class="token punctuation">,</span> <span class="token keyword">void</span> <span class="token operator">*</span>arg2<span class="token punctuation">,</span> <span class="token keyword">void</span> <span class="token operator">*</span>arg3<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="7"></td><td><pre>unsigned <span class="token keyword">long</span> <span class="token keyword">long</span> <span class="token function">bioPendingJobsOfType</span><span class="token punctuation">(</span><span class="token keyword">int</span> type<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="8"></td><td><pre>unsigned <span class="token keyword">long</span> <span class="token keyword">long</span> <span class="token function">bioWaitStepOfType</span><span class="token punctuation">(</span><span class="token keyword">int</span> type<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="9"></td><td><pre>time_t <span class="token function">bioOlderJobOfType</span><span class="token punctuation">(</span><span class="token keyword">int</span> type<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token keyword">void</span> <span class="token function">bioKillThreads</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment">/* Background job opcodes */</span></pre></td></tr><tr><td data-num="13"></td><td><pre>#define <span class="token constant">BIO_CLOSE_FILE</span>    <span class="token number">0</span> <span class="token comment">/* Deferred close(2) syscall. */</span></pre></td></tr><tr><td data-num="14"></td><td><pre>#define <span class="token constant">BIO_AOF_FSYNC</span>     <span class="token number">1</span> <span class="token comment">/* Deferred AOF fsync. */</span></pre></td></tr><tr><td data-num="15"></td><td><pre>#define <span class="token constant">BIO_LAZY_FREE</span>     <span class="token number">2</span> <span class="token comment">/* Deferred objects freeing. */</span></pre></td></tr><tr><td data-num="16"></td><td><pre>#define <span class="token constant">BIO_NUM_OPS</span>       <span class="token number">3</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>#endif</pre></td></tr></table></figure><p>关于 Redis 后台线程的详细介绍可以查看 <span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uY24vcG9zdC83MTAyNzgwNDM0NzM5NjI2MDE0">Redis 6.0 后台线程有哪些？</span> 这篇就文章。</p><h1 id="redis-内存管理缓存数据管理"><a class="anchor" href="#redis-内存管理缓存数据管理">#</a> Redis 内存管理（缓存数据管理）</h1><h2 id="redis-给缓存数据设置过期时间的意义"><a class="anchor" href="#redis-给缓存数据设置过期时间的意义">#</a> Redis 给缓存数据设置过期时间的意义</h2><p><font color="red">因为内存是有限的</font>，如果缓存中的所有数据都是一直保存的话，分分钟直接 Out of memory。</p><p>Redis 自带了给缓存数据设置过期时间的功能，比如：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> expire key <span class="token number">60</span> <span class="token comment"># 数据在 60s 后过期</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> setex key <span class="token number">60</span> value <span class="token comment"># 数据在 60s 后过期 (setex:[set] + [ex] pire)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>OK</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> ttl key <span class="token comment"># 查看数据还有多久过期</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">56</span></pre></td></tr></table></figure><blockquote><p>注意：<strong>Redis 中除了字符串类型有自己独有设置过期时间的命令 <code>setex</code> 外，其他方法都需要依靠 <code>expire</code> 命令来设置过期时间。另外， <code>persist</code> 命令可以移除一个键的过期时间。</strong></p></blockquote><p><strong>过期时间除了<font color="red">有助于缓解内存的消耗</font>，还有什么其他用么？</strong></p><p>很多时候，我们的 **<font color="red">业务场景就是需要某个数据只在某一时间段内存在</font>**，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 Token 可能只在 1 天内有效。</p><p>如果使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多。</p><h2 id="过期数据的判断"><a class="anchor" href="#过期数据的判断">#</a> 过期数据的判断</h2><p>Redis 通过一个叫做 **<font color="cornflowerblue">过期字典</font>**（可以看作是 hash 表）来保存数据过期的时间。过期字典的<font color="red">键指向 Redis 数据库中的某个 key (键)</font>，过期字典的<font color="red">值是一个 long long 类型的整数</font>，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-expired-dictionary.png" alt="redis过期字典"></p><center>redis过期字典</center><p>过期字典是存储在 <code>redisDb</code> 这个结构里的：</p><figure class="highlight c"><figcaption data-lang="c"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">redisDb</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>    dict <span class="token operator">*</span>dict<span class="token punctuation">;</span>     <span class="token comment">// 数据库键空间，保存着数据库中所有键值对</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    dict <span class="token operator">*</span>expires   <span class="token comment">// 过期字典，保存着键的过期时间</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token punctuation">&#125;</span> redisDb<span class="token punctuation">;</span></pre></td></tr></table></figure><h2 id="过期的数据的删除策略"><a class="anchor" href="#过期的数据的删除策略">#</a> 过期的数据的删除策略</h2><p>如果假设你设置了一批 key 只能存活 1 分钟，那么 1 分钟后，Redis 是怎么对这批 key 进行删除的呢？</p><p>常用的过期数据的删除策略就两个（重要！自己造缓存轮子的时候需要格外考虑的东西）：</p><ol><li><strong><font color="cornflowerblue">惰性删除</font></strong>：<font color="red">只会在取出 key 的时候才对数据进行过期检查</font>。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。</li><li><strong><font color="cornflowerblue">定期删除</font></strong>：<font color="red">每隔一段时间抽取一批 key 执行删除过期 key 操作</font>。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。</li></ol><p>定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 <strong><font color="cornflowerblue">定期删除 + 惰性删除</font></strong> 。</p><p>但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是<font color="red">可能存在定期删除和惰性删除漏掉了很多过期 key 的情况</font>。这样就导致大量过期 key 堆积在内存里，然后就 Out of memory 了。</p><p>怎么解决这个问题呢？答案就是：<strong><font color="#B32015">Redis 内存淘汰机制</font></strong>。</p><h2 id="redis-内存淘汰机制"><a class="anchor" href="#redis-内存淘汰机制">#</a> <mark>🌟Redis 内存淘汰机制</mark></h2><blockquote><p>相关问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，<font color="red">如何保证 Redis 中的数据都是热点数据？</font></p></blockquote><p>Redis 提供 6 种数据淘汰策略：</p><ol><li><strong>volatile-lru（least recently used）</strong>：从<u>已设置过期时间的数据集</u>（ <code>server.db[i].expires</code> ）中挑选<font color="red">最近最少使用的</font>数据淘汰。</li><li><strong>volatile-ttl</strong>：从<u>已设置过期时间的数据集</u>（ <code>server.db[i].expires</code> ）中挑选<font color="red">将要过期的</font>数据淘汰。</li><li><strong>volatile-random</strong>：从<u>已设置过期时间的数据集</u>（ <code>server.db[i].expires</code> ）中<font color="red">任意选择</font>数据淘汰。</li><li><strong>allkeys-lru（least recently used）</strong>：当内存不足以容纳新写入数据时，在<u>键空间中</u>，移除<font color="red">最近最少使用的</font> key（这个是<font color="gree">最常用的</font>）。</li><li><strong>allkeys-random</strong>：从数据集（ <code>server.db[i].dict</code> ）中<font color="red">任意选择</font>数据淘汰。</li><li><strong>no-eviction</strong>：<font color="red">禁止驱逐数据</font>，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！</li></ol><p>Redis 4.0 版本后增加以下两种：</p><ol start="7"><li><p><strong>volatile-lfu（least frequently used）</strong>：从<u>已设置过期时间的数据集</u>（ <code>server.db[i].expires</code> ）中挑选<font color="red">最不经常使用的</font>数据淘汰。</p></li><li><p><strong>allkeys-lfu（least frequently used）</strong>：当内存不足以容纳新写入数据时，在<u>键空间中</u>，移除<font color="red">最不经常使用的</font> key。</p></li></ol><h1 id="redis-事务"><a class="anchor" href="#redis-事务">#</a> Redis 事务</h1><h2 id="简介"><a class="anchor" href="#简介">#</a> 简介</h2><p>Redis 的事务的本质是 **<font color="red">一组命令的批处理</font>**。这组命令在执行过程中会被<font color="red">按顺序、一次性、串行化</font>全部执行完毕，只要没有出现语法错误，这组命令在执行期间是<font color="red">不会被中断（其他命令无法插入）</font>。</p><h2 id="常用命令"><a class="anchor" href="#常用命令">#</a> 常用命令</h2><table><thead><tr><th>命令</th><th>描述</th><th>返回值</th></tr></thead><tbody><tr><td><code>MULTI</code></td><td><font color="red">标记一个事务块的开始</font>。随后的一系列指令将在执行 <code>EXEC</code> 时作为一个原子执行。</td><td>OK</td></tr><tr><td><code>WATCH key [key ...]</code></td><td><font color="red">监视若干个 key</font>，如果在事务执行前这些 key 发生改动，那么事务将被打断。在事务中有条件的执行（<font color="red">乐观锁</font>）。</td><td>OK</td></tr><tr><td><code>EXEC</code></td><td><font color="red">执行事务块中所有在排队等待的指令</font>，并将链接状态恢复到正常。<br>当使用 <code>WATCH</code> 时，只有当被监视的键没有被修改，且允许检查设定机制时， <code>EXEC</code> 会被执行。</td><td>每个元素与原子事务中的指令一一对应。<br>使用 <code>WATCH</code> 时，如果被终止， <code>EXEC</code> 则返回一个空的应答集合。</td></tr><tr><td><code>UNWATCH</code></td><td><font color="red">释放所有被 <code>WATCH</code> 命令监视的 key</font><br>如果执行 <code>EXEC</code> 或者 <code>DISCARD</code> ，则不需要手动执行该命令。</td><td>OK</td></tr><tr><td><code>DISCARD</code></td><td><font color="red">取消事务，放弃执行事务块中的所有指令</font>。<br>同时，<font color="red">释放所有被 <code>WATCH</code> 命令监视的 key</font>。</td><td>OK</td></tr></tbody></table><p>Redis 可以通过 <code>MULTI</code> ， <code>EXEC</code> ， <code>DISCARD</code> 和 <code>WATCH</code> 等命令来实现事务 (Transaction) 功能。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> MULTI</pre></td></tr><tr><td data-num="2"></td><td><pre>OK</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> SET PROJECT <span class="token string">"JavaGuide"</span></pre></td></tr><tr><td data-num="4"></td><td><pre>QUEUED</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> GET PROJECT</pre></td></tr><tr><td data-num="6"></td><td><pre>QUEUED</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">></span> EXEC</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> OK</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"JavaGuide"</span></pre></td></tr></table></figure><p><a target="_blank" rel="noopener" href="https://redis.io/commands/multi"><code>MULTI</code> </a>命令后可以输入多个命令，Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 <a target="_blank" rel="noopener" href="https://redis.io/commands/exec"><code>EXEC</code> </a>命令后，再执行所有的命令。</p><p>这个过程是这样的：</p><ol><li>开始事务（ <code>MULTI</code> ）；</li><li>命令入队（批量操作 Redis 的命令，先进先出（FIFO）的顺序执行）；</li><li>执行事务（ <code>EXEC</code> ）。</li></ol><p>你也可以通过 <a target="_blank" rel="noopener" href="https://redis.io/commands/discard"><code>DISCARD</code> </a>命令取消一个事务，它会清空事务队列中保存的所有命令。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> MULTI</pre></td></tr><tr><td data-num="2"></td><td><pre>OK</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> SET PROJECT <span class="token string">"JavaGuide"</span></pre></td></tr><tr><td data-num="4"></td><td><pre>QUEUED</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> GET PROJECT</pre></td></tr><tr><td data-num="6"></td><td><pre>QUEUED</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">></span> DISCARD</pre></td></tr><tr><td data-num="8"></td><td><pre>OK</pre></td></tr></table></figure><p>你可以通过 <a target="_blank" rel="noopener" href="https://redis.io/commands/watch"><code>WATCH</code> </a>命令监听指定的 Key，当调用 <code>EXEC</code> 命令执行事务时，如果一个被 <code>WATCH</code> 命令监视的 Key 被 <strong>其他客户端 / Session</strong> 修改的话，整个事务都不会被执行。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 客户端 1</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token operator">></span> SET PROJECT <span class="token string">"RustGuide"</span></pre></td></tr><tr><td data-num="3"></td><td><pre>OK</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token operator">></span> WATCH PROJECT</pre></td></tr><tr><td data-num="5"></td><td><pre>OK</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token operator">></span> MULTI</pre></td></tr><tr><td data-num="7"></td><td><pre>OK</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token operator">></span> SET PROJECT <span class="token string">"JavaGuide"</span></pre></td></tr><tr><td data-num="9"></td><td><pre>QUEUED</pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment"># 客户端 2</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment"># 在客户端 1 执行 EXEC 命令提交事务之前修改 PROJECT 的值</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token operator">></span> SET PROJECT <span class="token string">"GoGuide"</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token comment"># 客户端 1</span></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token comment"># 修改失败，因为 PROJECT 的值被客户端 2 修改了</span></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token operator">></span> EXEC</pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token punctuation">(</span>nil<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token operator">></span> GET PROJECT</pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token string">"GoGuide"</span></pre></td></tr></table></figure><p>不过，如果 <strong>WATCH</strong> 与 <strong>事务</strong> 在同一个 Session 里，并且被 <strong>WATCH</strong> 监视的 Key 被修改的操作发生在事务内部，这个事务是可以被执行成功的（相关 issue：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1NuYWlsY2xpbWIvSmF2YUd1aWRlL2lzc3Vlcy8xNzE0">WATCH 命令碰到 MULTI 命令时的不同效果</span>）。</p><p>事务内部修改 WATCH 监视的 Key：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> SET PROJECT <span class="token string">"JavaGuide"</span></pre></td></tr><tr><td data-num="2"></td><td><pre>OK</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> WATCH PROJECT</pre></td></tr><tr><td data-num="4"></td><td><pre>OK</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> MULTI</pre></td></tr><tr><td data-num="6"></td><td><pre>OK</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">></span> SET PROJECT <span class="token string">"JavaGuide1"</span></pre></td></tr><tr><td data-num="8"></td><td><pre>QUEUED</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token operator">></span> SET PROJECT <span class="token string">"JavaGuide2"</span></pre></td></tr><tr><td data-num="10"></td><td><pre>QUEUED</pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token operator">></span> SET PROJECT <span class="token string">"JavaGuide3"</span></pre></td></tr><tr><td data-num="12"></td><td><pre>QUEUED</pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token operator">></span> EXEC</pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span> OK</pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span> OK</pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token number">3</span><span class="token punctuation">)</span> OK</pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> GET PROJECT</pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token string">"JavaGuide3"</span></pre></td></tr></table></figure><p>事务外部修改 WATCH 监视的 Key：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> SET PROJECT <span class="token string">"JavaGuide"</span></pre></td></tr><tr><td data-num="2"></td><td><pre>OK</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">></span> WATCH PROJECT</pre></td></tr><tr><td data-num="4"></td><td><pre>OK</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token operator">></span> SET PROJECT <span class="token string">"JavaGuide2"</span></pre></td></tr><tr><td data-num="6"></td><td><pre>OK</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">></span> MULTI</pre></td></tr><tr><td data-num="8"></td><td><pre>OK</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token operator">></span> GET <span class="token environment constant">USER</span></pre></td></tr><tr><td data-num="10"></td><td><pre>QUEUED</pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token operator">></span> EXEC</pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token punctuation">(</span>nil<span class="token punctuation">)</span></pre></td></tr></table></figure><p>Redis 官网相关介绍 <span class="exturl" data-url="aHR0cHM6Ly9yZWRpcy5pby90b3BpY3MvdHJhbnNhY3Rpb25z">https://redis.io/topics/transactions</span> 如下：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-transactions.png" alt="Redis 事务"></p><h2 id="特性"><a class="anchor" href="#特性">#</a> 特性</h2><blockquote><p>Redis 的事务和我们平时理解的关系型数据库的事务不同。我们知道事务具有四大特性：</p><ol><li>** 原子性（Atomicity）：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成（commit），要么完全不起作用（rollback）；</li><li>** 一致性（Consistency）：** 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；</li><li>** 隔离性（Isolation）：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</li><li>** 持久性（Durability）：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</li></ol></blockquote><p><strong><font color="red">Redis 事务仅保证了数据的一致性（C），不具有像 DBMS 一样的 ACID 特性</font></strong>。</p><ul><li>这组命令中的<font color="red">某些命令的执行失败不会影响其它命令的执行，不会引发回滚，因此不具备原子性（A）</font>。</li><li>这组命令<font color="red">仅通过<strong>乐观锁机制</strong>实现了简单的隔离性</font>，没有复杂的隔离级别（I）。</li><li>这组命令的<font color="red">执行结果是被写入到内存的，是否持久（D）取决于 Redis 的持久化策略，与事务无关</font>。而且，Redis 的持久化策略也存在数据丢失的问题，更加没法保证持久性。</li></ul><h3 id="不具备原子性a"><a class="anchor" href="#不具备原子性a">#</a> 不具备原子性（A）</h3><p>Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，<font color="red">Redis 事务是不支持回滚（roll back）操作的</font>。因此，Redis 事务其实是不满足原子性的。</p><p>Redis 官网也解释了自己为啥不支持回滚。简单来说就是<font color="red"> Redis 开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好</font>。Redis 开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。</p><h3 id="实现了简单的隔离性i"><a class="anchor" href="#实现了简单的隔离性i">#</a> 实现了简单的隔离性（I）</h3><p>从 Redis 2.2 开始，允许以<font color="red">乐观锁</font>的形式为 Redis 事务操作提供额外保证，其方式与 <code>check-and-set</code> （CAS）操作非常相似。稍后将对此进行记录，具体可见<a href="#%E9%9A%94%E7%A6%BB%E6%9C%BA%E5%88%B6">隔离机制</a>。</p><h3 id="无法保证持久性d"><a class="anchor" href="#无法保证持久性d">#</a> 无法保证持久性（D）</h3><p>Redis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持 3 种持久化方式:</p><ul><li>快照（snapshotting，RDB）</li><li>只追加文件（append-only file, AOF）</li><li>RDB 和 AOF 的混合持久化 (Redis 4.0 新增)</li></ul><p>与 RDB 持久化相比，AOF 持久化的实时性更好。在 Redis 的配置文件中存在三种不同的 AOF 持久化方式（ <code>fsync</code> 策略），它们分别是：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>appendfsync always    <span class="token comment">#每次有数据修改发生时都会调用 fsync 函数同步 AOF 文件，fsync 完成后线程返回，这样会严重降低 Redis 的速度</span></pre></td></tr><tr><td data-num="2"></td><td><pre>appendfsync everysec  <span class="token comment">#每秒钟调用 fsync 函数同步一次 AOF 文件</span></pre></td></tr><tr><td data-num="3"></td><td><pre>appendfsync no        <span class="token comment">#让操作系统决定何时进行同步，一般为 30 秒一次</span></pre></td></tr></table></figure><p><font color="red">AOF 持久化的 <code>fsync</code> 策略为 no、everysec 时都会存在数据丢失的情况</font>。always 下可以基本是可以满足持久性要求的，但性能太差，实际开发过程中不会使用。</p><p>因此，Redis 事务的持久性也是没办法保证的。</p><h2 id="异常处理"><a class="anchor" href="#异常处理">#</a> 异常处理</h2><h3 id="语法错误"><a class="anchor" href="#语法错误">#</a> 语法错误</h3><p><font color="red">当事务中的命令出现语法错误时，整个事务在 <code>exec</code> 执行时会被取消</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231209124406832.png" alt="image-20231209124406832"></p><p>exec 的提示是 exec 被忽略，事务被取消，因为之前的错误。</p><p>此时访问 age 的值，发现其仍为 19，并没有变为事务中设置的 20。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231209124451759.png" alt="image-20231209124451759"></p><h3 id="执行异常"><a class="anchor" href="#执行异常">#</a> 执行异常</h3><p><font color="red">如果事务中的命令没有语法错误，但在执行过程中出现异常，该异常不会影响其它命令的执行</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231209124658817.png" alt="image-20231209124658817"></p><p>以上事务中第 2 条命令在执行时出现异常。因为 score 并非是整型，无法被增加 20 的操作。但该异常并不会影响其前后命令的正确执行。查看 score 与 name 的值，发现是执行成功的结果。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231209124800203.png" alt="image-20231209124800203"></p><h2 id="隔离机制"><a class="anchor" href="#隔离机制">#</a> 隔离机制</h2><h3 id="为什么需要隔离机制"><a class="anchor" href="#为什么需要隔离机制">#</a> 为什么需要隔离机制</h3><p>在并发场景下可能会出现多个客户端对同一个数据进行修改的情况。</p><p>例如：有两个客户端 C 左与 C 右， C 左需要申请 40 个资源， C 右需要申请 30 个资源。它们首先查看了当前拥有的资源数量，即 resources 的值。它们查看到的都是 50，都感觉资源数量可以满足自己的需求，于是修改资源数量，以占有资源。但结果却是资源出现了 “超卖” 情况。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231209123019238.png" alt="image-20231209123019238"></p><p>为了解决这种情况，Redis 事务通过 **<font color="#B32015">乐观锁机制</font>** 实现了多线程下的执行隔离。</p><h3 id="隔离的实现"><a class="anchor" href="#隔离的实现">#</a> 隔离的实现</h3><p>Redis 通过 <code>watch</code> 命令再配合事务实现了多线程下的执行隔离。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231209123108530.png" alt="image-20231209123108530"></p><p>以上两个客户端执行的时间顺序为：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231209123147370.png" alt="image-20231209123147370"></p><p>当 C 左客户端在 <code>exec</code> 事务前发现其 <code>watch</code> 的数据发生了改动，则会打断事务执行。</p><h3 id="实现原理"><a class="anchor" href="#实现原理">#</a> <mark>🌟实现原理</mark></h3><p>其内部的执行过程如下：</p><ol><li><p>当某一客户端对 key 执行了 <code>watch</code> 后，系统就会为该 key 添加一个 <font color="gree">version 乐观锁</font>，并初始化 version。例如初值为 1.0。</p></li><li><p>此后客户端 C 左将对该 key 的修改语句写入到了事务命令队列中，虽未执行，但其将该 key 的 value 值与 version 进行了读取并保存到了当前客户端缓存。此时读取并保存的是 version 的初值 1.0。</p></li><li><p>此后客户端 C 右对该 key 的值进行了修改，这个修改不仅修改了 key 的 value 本身，同时也增加了 version 的值，例如使其 version 变为了 2.0，并将该 version 记录到了该 key 信息中。</p></li><li><p>此后客户端 C 左执行 exec，开始执行事务中的命令。不过，其在执行到对该 key 进行修改的命令时，该命令<font color="red">首先对当前客户端缓存中保存的 version 值与当前 key 信息中的 version 值进行比较</font>。如果缓存 version 小于 key 的 version，则说明客户端缓存的 key 的 value 已经过时，该写操作如果执行可能会破坏数据的一致性。所以该写操作不执行。</p></li></ol><h2 id="redis事务-vs-数据库事务"><a class="anchor" href="#redis事务-vs-数据库事务">#</a> Redis 事务 v.s 数据库事务</h2><ol><li><p><strong>单独的隔离操作</strong>：Redis 的事务仅仅是保证事务里的操作会被连续独占的执行，redis 命令执行是单线程架构，<font color="red">在执行完事务内所有指令前，是不可能再去同时执行其他客户端的请求</font>的</p></li><li><p><strong><font color="#B32015">没有隔离级别的概念</font></strong>：因为<font color="red">事务提交前任何指令都不会被实际执行</font>，也就不存在 “事务内的查询要看到事务里的更新，在事务外查询不能看到” 这种问题了</p><blockquote><p>因此<font color="red">不存在 “三大读问题”：不可重复读、脏读、幻读</font></p></blockquote></li><li><p><strong><font color="#B32015">不保证原子性</font></strong>：Redis 的事务 **<font color="red">不保证原子性</font>**，也就是不保证所有指令同时成功或同时失败，只有决定是否开始执行全部指令的能力，<font color="red">没有回滚能力</font></p></li><li><p><strong>排它性</strong>：Redis 会保证一个事务内的命令依次执行，而<font color="red">不会被其它命令插入</font></p></li></ol><h2 id="如何解决-redis-事务的缺陷"><a class="anchor" href="#如何解决-redis-事务的缺陷">#</a> 如何解决 Redis 事务的缺陷</h2><p>Redis 从 2.6 版本开始支持执行 Lua 脚本，它的功能和事务非常类似。<font color="red">可以利用 Lua 脚本来批量执行多条 Redis 命令</font>，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。</p><p>一段 Lua 脚本可以视作一条命令执行，<font color="red">一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行</font>，保证了操作不会被其他指令插入或打扰。</p><p>不过，<font color="red">如果 Lua 脚本运行时出错并中途结束，出错之后的命令是不会被执行的</font>。并且，<font color="red">出错之前执行的命令是无法被撤销的，无法实现类似关系型数据库执行失败可以回滚的那种原子性效果</font>。因此， 严格来说的话，<strong><font color="red">通过 Lua 脚本来批量执行 Redis 命令实际也是不完全满足原子性的</font></strong>。</p><p>如果想要让 Lua 脚本中的命令全部执行，必须保证语句语法和命令都是对的。</p><p>另外，Redis 7.0 新增了 <span class="exturl" data-url="aHR0cHM6Ly9yZWRpcy5pby9kb2NzL21hbnVhbC9wcm9ncmFtbWFiaWxpdHkvZnVuY3Rpb25zLWludHJvLw==">Redis functions</span> 特性，你可以将 Redis functions 看作是比 Lua 更强大的脚本。</p><h1 id="redis-管道pipeline"><a class="anchor" href="#redis-管道pipeline">#</a> Redis 管道（pipeline）</h1><blockquote><p>Redis 管道 与 Redis 事务 之间的关系，类似于雷锋与雷峰塔的关系，Java 与 JavaScript 的关系，<font color="red">看上去相似，但实际没有任何关系！</font></p></blockquote><h2 id="引言"><a class="anchor" href="#引言">#</a> 引言</h2><p>如何优化命令频繁往返造成的性能瓶颈？</p><p>Redis 是一种基于<font color="red">客户端 - 服务端模型</font>以及请求 / 响应协议的 TCP 服务。一个请求会遵循以下步骤：</p><ol><li><p><font color="red">客户端向服务端发送命令</font>(分四步：发送命令→命令排队→命令执行→返回结果)，并监听 Socket 返回，通常<font color="red">以<strong>阻塞模式</strong>等待服务端响应</font>。</p></li><li><p><font color="red">服务端处理命令，并将结果返回给客户端</font>。</p></li></ol><p>上述两步的总耗时称为：<strong><font color="#B32015">Round Trip Time（即 RTT，数据包往返于两端的时间)</font></strong>。</p><blockquote><p>如果同时需要执行大量的命令，那么就<font color="red">要等待上一条命令应答后再执行</font>，这中间不仅仅多了 RTT（Round Time Trip），而且还频繁调用系统 IO，发送网络请求，同时需要 redis 调用多次 read () 和 write () 系统方法，系统方法会将数据从用户态转移到内核态，这样就会对进程上下文有比较大的影响了，<font color="red">性能不太好</font>o(╥﹏╥)o</p></blockquote><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807140057973.png" alt="image-20230807140057973"></p><h2 id="简介-2"><a class="anchor" href="#简介-2">#</a> 简介</h2><blockquote><p>通过 **<font color="red">批处理 Redis 命令</font>** 来<font color="red">优化往返时间 RTT</font></p></blockquote><p><strong>Redis 管道 (pipeline)</strong>：为了优化 RTT 往返时间，可以<font color="orange">一次性打包发送多条命令</font>给服务端，而<font color="red">无需等待对每个命令的响应</font>。等待服务端依次处理完完毕后，<font color="red">通过一条响应一次性将结果返回</font>，通过减少客户端与 redis 的通信次数来实现降低往返延时时间。pipeline 的<font color="orange">实现原理是队列</font>，先进先出特性就保证数据的顺序性。</p><blockquote><p>是<strong>一种批处理命令的变种优化措施</strong>，类似 Redis 原生的批命令（例如 mget 和 mset）。</p></blockquote><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/1ffba84802bd4732b4a390d0aade8020.png" alt="img"></p><h2 id="案例"><a class="anchor" href="#案例">#</a> 案例</h2><ol><li>将欲执行的命令全部写到一个 txt 文件中</li><li>将 txt 文件的内容传递给 Redis 的 pipe 参数</li></ol><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807140935362.png" alt="image-20230807140935362"></p><h2 id="总结"><a class="anchor" href="#总结">#</a> 总结</h2><h3 id="管道-vs-原生批量操作命令"><a class="anchor" href="#管道-vs-原生批量操作命令">#</a> 管道 vs 原生批量操作命令</h3><table><thead><tr><th>管道</th><th>原生批量命令</th></tr></thead><tbody><tr><td><font color="red">非原子性</font></td><td>原子性</td></tr><tr><td>支持批量执行不同命令</td><td>一次只能执行一种命令</td></tr><tr><td>服务端与客户端共同完成</td><td>服务端实现</td></tr></tbody></table><h3 id="管道-vs-redis-事务"><a class="anchor" href="#管道-vs-redis-事务">#</a> 管道 vs Redis 事务</h3><table><thead><tr><th>管道</th><th>Redis 事务</th></tr></thead><tbody><tr><td>非原子性，pipeline 之间可以<font color="red">交错执行</font></td><td><font color="red">可视为原子操作，但不满足原子性</font>，虽然两个不同的事务不会同时运行</td></tr><tr><td>一次性发送多条命令到服务端，请求次数更少</td><td>需要逐条发送命令到服务端</td></tr><tr><td><font color="red">非阻塞</font></td><td>会阻塞其他命令的执行</td></tr></tbody></table><h3 id="使用管道的注意事项"><a class="anchor" href="#使用管道的注意事项">#</a> 使用管道的注意事项</h3><ul><li><p>pipeline 缓冲的指令只是会依次执行，<font color="red">不保证原子性，如果执行中指令发生异常，将会继续执行后续的指令</font></p><blockquote><p>与 Redis 事务发生命令的运行时异常类似，冤头债主，不会连坐</p></blockquote></li><li><p>使用 pipeline 组装的<font color="red">命令个数不能太多</font>（例如 10k），不然数据量过大客户端阻塞的时间可能过久，同时<font color="red">服务端此时也被迫回复一个队列答复，占用很多内存</font></p></li></ul><h1 id="redis-性能优化"><a class="anchor" href="#redis-性能优化">#</a> <mark>🌟Redis 性能优化</mark></h1><p>除了下面介绍的内容之外，再推荐两篇不错的文章：</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3Mvbk5FdVl3ME5sWUdodUtLS0tvV2ZjUQ==">你的 Redis 真的变慢了吗？性能优化如何做 - 阿里开发者</span></li><li><span class="exturl" data-url="aHR0cHM6Ly9qYXZhZ3VpZGUuY24vZGF0YWJhc2UvcmVkaXMvcmVkaXMtY29tbW9uLWJsb2NraW5nLXByb2JsZW1zLXN1bW1hcnkuaHRtbA==">Redis 常见阻塞原因总结 - JavaGuide</span></li></ul><h2 id="使用批量操作减少网络传输"><a class="anchor" href="#使用批量操作减少网络传输">#</a> 使用批量操作减少网络传输</h2><p>一个 Redis 命令的执行可以简化为以下 4 步：</p><ol><li>发送命令</li><li>命令排队</li><li>命令执行</li><li>返回结果</li></ol><p>其中，第 1 步和第 4 步耗费时间之和称为 <strong>Round Trip Time (RTT, 往返时间)</strong> ，也就是数据在网络上传输的时间。</p><p><strong><font color="red">使用批量操作可以减少网络传输次数，进而有效减小网络开销，大幅减少 RTT</font></strong>。</p><p>另外，除了能减少 RTT 之外，发送一次命令的 socket I/O 成本也比较高（涉及上下文切换，存在 <code>read()</code> 和 <code>write()</code> 系统调用），<font color="red">批量操作还可以减少 socket I/O 成本</font>。这个在官方对 pipeline 的介绍中有提到：[<span class="exturl" data-url="aHR0cHM6Ly9yZWRpcy5pby9kb2NzL21hbnVhbC9waXBlbGluaW5nLw==">https://redis.io/docs/manual/pipelining/</span> 。</p><h3 id="原生批量操作命令"><a class="anchor" href="#原生批量操作命令">#</a> 原生批量操作命令</h3><p>Redis 中有一些原生支持批量操作的命令，比如：</p><ul><li><code>MGET</code> (获取一个或多个指定 key 的值)、 <code>MSET</code> (设置一个或多个指定 key 的值)</li><li><code>HMGET</code> (获取指定哈希表中一个或者多个指定字段的值)、 <code>HMSET</code> (同时将一个或多个 field-value 对设置到指定哈希表中)、</li><li><code>SADD</code> （向指定集合添加一个或多个元素）</li><li>……</li></ul><p>不过，在 Redis 官方提供的分片集群解决方案 <font color="red">Redis Cluster 下，使用这些原生批量操作命令可能会存在一些小问题需要解决</font>。就比如说 <code>MGET</code> 无法保证所有的 key 都在同一个 <strong>hash slot</strong>（哈希槽）上， <code>MGET</code> 可能还是需要多次网络传输，原子操作也无法保证了。不过，相较于非批量操作，还是可以节省不少网络传输次数。</p><p>整个步骤的简化版如下（通常由 Redis 客户端实现，无需我们自己再手动实现）：</p><ol><li>找到 key 对应的所有 hash slot；</li><li>分别向对应的 Redis 节点发起 <code>MGET</code> 请求获取数据；</li><li>等待所有请求执行结束，重新组装结果数据，保持跟入参 key 的顺序一致，然后返回结果。</li></ol><p>如果想要解决这个多次网络传输的问题，比较常用的办法是自己维护 key 与 slot 的关系。不过这样不太灵活，虽然带来了性能提升，但同样让系统复杂性提升。</p><h3 id="管道pipeline"><a class="anchor" href="#管道pipeline">#</a> 管道（pipeline）</h3><blockquote><p>参考前文 [Redis 管道](#Redis 管道（pipeline）)</p></blockquote><p>对于不支持批量操作的命令，我们<font color="red">可以利用 <strong>pipeline（流水线)</strong> 将一批 Redis 命令封装成一组，这些 Redis 命令会被一次性提交到 Redis 服务器，只需要一次网络传输</font>。不过，需要注意控制一次批量操作的 <strong>元素个数</strong> (例如 500 以内，实际也和元素字节数有关)，避免网络传输的数据量过大。</p><p>与 <code>MGET</code> 、 <code>MSET</code> 等原生批量操作命令一样，<font color="red">pipeline 同样在 Redis Cluster 上使用会存在一些小问题</font>。原因类似，无法保证所有的 key 都在同一个 <strong>hash slot</strong>（哈希槽）上。如果想要使用的话，客户端需要自己维护 key 与 slot 的关系。</p><p>[pipeline 与原生批量操作命令的区别](# 管道 vs 原生批量操作命令)</p><p>[pipeline 与 Redis 事务的区别](# 管道 vs Redis 事务)</p><p>另外，<font color="red">pipeline 不适用于执行顺序有依赖关系的一批命令</font>。就比如说，你需要将前一个命令的结果给后续的命令使用，pipeline 就没办法满足你的需求了。对于这种需求，我们可以使用 <strong>Lua 脚本</strong> 。</p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-pipeline-vs-transaction.png" alt="img" style="zoom:67%"><h3 id="lua-脚本"><a class="anchor" href="#lua-脚本">#</a> Lua 脚本</h3><p><font color="red">Lua 脚本同样支持批量操作多条命令，一段 Lua 脚本可以视作一条命令执行，可以看作是 <strong>原子操作</strong> </font>。也就是说，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰，这是 pipeline 所不具备的。</p><p>并且，<font color="red">Lua 脚本中支持一些简单的逻辑处理</font>，比如使用命令读取值并在 Lua 脚本中进行处理，这同样是 pipeline 所不具备的。</p><p>不过，Lua 脚本依然存在下面这些缺陷：</p><ul><li><font color="red">如果 Lua 脚本运行时出错并中途结束，之后的操作不会进行，但是之前已经发生的写操作不会撤销</font>，所以即使使用了 Lua 脚本，也不能实现类似数据库回滚的原子性。</li><li>Redis Cluster 下 Lua 脚本的原子操作也无法保证了，原因同样是无法保证所有的 key 都在同一个 <strong>hash slot</strong>（哈希槽）上。</li></ul><h2 id="大量-key-集中过期问题"><a class="anchor" href="#大量-key-集中过期问题">#</a> 大量 key 集中过期问题</h2><p>我在前面提到过：对于过期 key，Redis 采用的是 <font color="cornflowerblue">定期删除 + 惰性删除</font> 策略。</p><p>定期删除执行过程中，如果<font color="red">突然遇到大量过期 key </font>的话，客户端请求必须等待定期清理过期 key 任务线程执行完成，因为这个这个<font color="red">定期任务线程是在 Redis 主线程中执行的</font>。这就导致客户端请求没办法被及时处理，响应速度会比较慢。</p><p>下面是两种常见的解决方法：</p><ol><li>给 key 设置 **<font color="red">随机过期时间</font>**。</li><li><strong><font color="red">开启 lazy-free（惰性删除）</font></strong>。该特性是 Redis 4.0 开始引入的，指的是让 Redis <font color="red">采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程</font>。</li></ol><p>个人建议不管是否开启 lazy-free，我们都<font color="red">尽量给 key 设置随机过期时间</font>。</p><h2 id="bigkey大-key"><a class="anchor" href="#bigkey大-key">#</a> <mark>🌟bigkey（大 Key）</mark></h2><h3 id="bigkey-是什么"><a class="anchor" href="#bigkey-是什么">#</a> bigkey 是什么</h3><p>简单来说，如果 **<font color="red">一个 key 对应的 value 所占用的内存比较大</font>**，那这个 key 就可以看作是 bigkey。具体多大才算大呢？有一个不是特别精确的参考标准：</p><ul><li><font color="red">String 类型的 value 超过 1MB</font></li><li><font color="red">复合类型（List、Hash、Set、Sorted Set 等）的 value 包含的元素超过 5000 个</font>（不过，对于复合类型的 value 来说，不一定包含的元素越多，占用的内存就越多）。</li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/bigkey-criterion.png" alt="bigkey 判定标准"></p><center>bigkey 判定标准</center><h3 id="bigkey-怎么产生的"><a class="anchor" href="#bigkey-怎么产生的">#</a> bigkey 怎么产生的</h3><p>bigkey 通常是由于下面这些原因产生的：</p><ul><li>程序设计不当，比如直接使用 String 类型存储较大的文件对应的二进制数据。</li><li>对于业务的数据规模考虑不周到，比如使用集合类型的时候没有考虑到数据量的快速增长。</li><li><font color="red">未及时清理垃圾数据</font>，比如哈希中冗余了大量的无用键值对。</li></ul><h3 id="bigkey-的危害"><a class="anchor" href="#bigkey-的危害">#</a> bigkey 的危害</h3><p>bigkey 除了<font color="red">会消耗更多的内存空间和带宽，还会对性能造成比较大的影响</font>。</p><p>在<a href=""> Redis 常见阻塞原因总结</a>这篇文章中我们提到：大 key 还会造成阻塞问题。具体来说，主要体现在下面三个方面：</p><ol><li><font color="red">客户端超时阻塞</font>：由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li><li><font color="red">网络阻塞</font>：每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li><li><font color="red">工作线程阻塞</font>：如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li></ol><p>大 key 造成的阻塞问题还会<font color="red">进一步影响到主从同步和集群扩容</font>。</p><p>综上，大 key 带来的潜在问题是非常多的，我们应该尽量避免 Redis 中存在 bigkey。</p><h3 id="如何发现-bigkey"><a class="anchor" href="#如何发现-bigkey">#</a> 如何发现 bigkey</h3><p><strong><font color="#B32015">1、使用 Redis 自带的 --bigkeys 参数来查找</font></strong></p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># redis-cli -p 6379 --bigkeys</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># Scanning the entire keyspace to find biggest keys as well as</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># per 100 SCAN commands (not usually needed).</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token punctuation">[</span>00.00%<span class="token punctuation">]</span> Biggest string found so far <span class="token string">'"ballcat:oauth:refresh_auth:f6cdb384-9a9d-4f2f-af01-dc3f28057c20"'</span> with <span class="token number">4437</span> bytes</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token punctuation">[</span>00.00%<span class="token punctuation">]</span> Biggest list   found so far <span class="token string">'"my-list"'</span> with <span class="token number">17</span> items</pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>-------- summary -------</pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>Sampled <span class="token number">5</span> keys <span class="token keyword">in</span> the keyspace<span class="token operator">!</span></pre></td></tr><tr><td data-num="13"></td><td><pre>Total key length <span class="token keyword">in</span> bytes is <span class="token number">264</span> <span class="token punctuation">(</span>avg len <span class="token number">52.80</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>Biggest   list found <span class="token string">'"my-list"'</span> has <span class="token number">17</span> items</pre></td></tr><tr><td data-num="16"></td><td><pre>Biggest string found <span class="token string">'"ballcat:oauth:refresh_auth:f6cdb384-9a9d-4f2f-af01-dc3f28057c20"'</span> has <span class="token number">4437</span> bytes</pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token number">1</span> lists with <span class="token number">17</span> items <span class="token punctuation">(</span><span class="token number">20.00</span>% of keys, avg size <span class="token number">17.00</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token number">0</span> hashs with <span class="token number">0</span> fields <span class="token punctuation">(</span>00.00% of keys, avg size <span class="token number">0.00</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token number">4</span> strings with <span class="token number">4831</span> bytes <span class="token punctuation">(</span><span class="token number">80.00</span>% of keys, avg size <span class="token number">1207.75</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre><span class="token number">0</span> streams with <span class="token number">0</span> entries <span class="token punctuation">(</span>00.00% of keys, avg size <span class="token number">0.00</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre><span class="token number">0</span> sets with <span class="token number">0</span> members <span class="token punctuation">(</span>00.00% of keys, avg size <span class="token number">0.00</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre><span class="token number">0</span> zsets with <span class="token number">0</span> members <span class="token punctuation">(</span>00.00% of keys, avg size <span class="token number">0.00</span></pre></td></tr></table></figure><p>从这个命令的运行结果，我们可以看出：这个命令<font color="red">会扫描 (Scan) Redis 中的所有 key</font> ，会对 Redis 的性能有一点影响。并且，这种方式<font color="red">只能找出每种数据结构 top 1 bigkey</font>（占用内存最大的 String 数据类型，包含元素最多的复合数据类型）。然而，一个 key 的元素多并不代表占用内存也多，需要我们根据具体的业务情况来进一步判断。</p><p>在线上执行该命令时，为了降低对 Redis 的影响，<font color="red">需要指定 <code>-i</code> 参数控制扫描的频率</font>。 <code>redis-cli -p 6379 --bigkeys -i 3</code> 表示扫描过程中每次扫描后休息的时间间隔为 3 秒。</p><p><strong><font color="#B32015">2、使用 Redis 自带的 SCAN 命令</font></strong></p><p><code>SCAN</code> 命令可以按照一定的模式、数量返回匹配的 key。获取了 key 之后，可以利用 <code>STRLEN</code> 、 <code>HLEN</code> 、 <code>LLEN</code> 等命令返回其长度或成员数量。</p><table><thead><tr><th>数据结构</th><th>命令</th><th>复杂度</th><th>结果（对应 key）</th></tr></thead><tbody><tr><td>String</td><td>STRLEN</td><td>O(1)</td><td>字符串值的长度</td></tr><tr><td>Hash</td><td>HLEN</td><td>O(1)</td><td>哈希表中字段的数量</td></tr><tr><td>List</td><td>LLEN</td><td>O(1)</td><td>列表元素数量</td></tr><tr><td>Set</td><td>SCARD</td><td>O(1)</td><td>集合元素数量</td></tr><tr><td>Sorted Set</td><td>ZCARD</td><td>O(1)</td><td>有序集合的元素数量</td></tr></tbody></table><p>对于集合类型还可以使用 <code>MEMORY USAGE</code> 命令（Redis 4.0+），这个命令会返回键值对占用的内存空间。</p><p><strong><font color="#B32015">3、借助开源工具分析 RDB 文件</font></strong></p><p>通过分析 RDB 文件来找出 big key。这种方案的前提是你的 Redis 采用的是 RDB 持久化。</p><p>网上有现成的代码 / 工具可以直接拿来使用：</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NyaXBhdGhpa3Jpc2huYW4vcmVkaXMtcmRiLXRvb2xz">redis-rdb-tools</span>：Python 语言写的用来分析 Redis 的 RDB 快照文件用的工具</li><li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3dlaXlhbndlaTQxMi9yZGJfYmlna2V5cw==">rdb_bigkeys</span> : Go 语言写的用来分析 Redis 的 RDB 快照文件用的工具，性能更好。</li></ul><p><strong><font color="#B32015">4、借助公有云的 Redis 分析服务</font></strong></p><p>如果你用的是公有云的 Redis 服务的话，可以看看其是否提供了 key 分析功能（一般都提供了）。</p><p>这里以阿里云 Redis 为例说明，它<font color="red">支持 bigkey 实时分析、发现</font>，文档地址：<span class="exturl" data-url="aHR0cHM6Ly93d3cuYWxpYmFiYWNsb3VkLmNvbS9oZWxwL3poL2Fwc2FyYWRiLWZvci1yZWRpcy9sYXRlc3QvdXNlLXRoZS1yZWFsLXRpbWUta2V5LXN0YXRpc3RpY3MtZmVhdHVyZQ==">https://www.alibabacloud.com/help/zh/apsaradb-for-redis/latest/use-the-real-time-key-statistics-feature</span> 。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/aliyun-key-analysis.png" alt="阿里云Key分析"></p><center>阿里云Key分析</center><h3 id="如何处理-bigkey"><a class="anchor" href="#如何处理-bigkey">#</a> 如何处理 bigkey</h3><p>bigkey 的常见处理以及优化办法如下（这些方法可以配合起来使用）：</p><ul><li><strong><font color="#B32015">分割 bigkey</font></strong>：将一个 bigkey 分割为多个小 key。例如，将一个含有上万字段数量的 Hash 按照一定策略（比如二次哈希）拆分为多个 Hash。</li><li><strong><font color="#B32015">手动清理</font></strong>：Redis 4.0+ 可以使用 <code>UNLINK</code> 命令来异步删除一个或多个指定的 key。Redis 4.0 以下可以考虑使用 <code>SCAN</code> 命令结合 <code>DEL</code> 命令来分批次删除。</li><li><strong><font color="#B32015">采用合适的数据结构</font></strong>：例如，文件二进制数据不使用 String 保存、使用 HyperLogLog 统计页面 UV、Bitmap 保存状态信息（0/1）。</li><li><strong><font color="#B32015">开启 lazy-free（惰性删除 / 延迟释放）</font></strong>：lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。</li></ul><h2 id="hotkey热-key"><a class="anchor" href="#hotkey热-key">#</a> hotkey（热 Key）</h2><h3 id="hotkey-是什么"><a class="anchor" href="#hotkey-是什么">#</a> hotkey 是什么</h3><p>如果 **<font color="red">一个 key 的访问次数比较多且明显多于其他 key</font>** ，那这个 key 就可以看作是 hotkey（热 Key）。例如在 Redis 实例的每秒处理请求达到 5000 次，而其中某个 key 的每秒访问量就高达 2000 次，那这个 key 就可以看作是 hotkey。</p><p>hotkey 出现的原因主要是<font color="red">某个热点数据访问量暴增</font>，如重大的热搜事件、参与秒杀的商品。</p><h3 id="hotkey-的危害"><a class="anchor" href="#hotkey-的危害">#</a> hotkey 的危害</h3><p>处理 hotkey 会<font color="red">占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理</font>。此外，如果突然访问 hotkey 的请求超出了 Redis 的处理能力，<font color="red">Redis 就会直接宕机</font>。这种情况下，大量请求将落到后面的数据库上，<font color="red">可能会导致数据库崩溃</font>。</p><p>因此，hotkey 很可能成为系统性能的瓶颈点，需要单独对其进行优化，以确保系统的高可用性和稳定性。</p><h3 id="如何发现-hotkey"><a class="anchor" href="#如何发现-hotkey">#</a> 如何发现 hotkey</h3><p><strong><font color="#B32015">1、使用 Redis 自带的 --hotkeys 参数来查找</font></strong></p><p>Redis 4.0.3 版本中新增了 <code>hotkeys</code> 参数，该参数<font color="red">能够返回所有 key 的被访问次数</font>。</p><p>使用该方案的前提条件是 Redis Server 的 <code>maxmemory-policy</code> <font color="red">参数设置为 LFU 算法</font>，不然就会出现如下所示的错误。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># redis-cli -p 6379 --hotkeys</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># Scanning the entire keyspace to find hot keys as well as</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># per 100 SCAN commands (not usually needed).</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>Error: ERR An LFU maxmemory policy is not selected, access frequency not tracked. Please note that when switching between policies at runtime LRU and LFU data will take some <span class="token function">time</span> to adjust.</pre></td></tr></table></figure><p>Redis 中有两种 LFU 算法：</p><ol><li><strong>volatile-lfu（least frequently used）</strong>：从<u>已设置过期时间的数据集</u>（ <code>server.db[i].expires</code> ）中挑选<font color="red">最不经常使用的</font>数据淘汰。</li><li><strong>allkeys-lfu（least frequently used）</strong>：当内存不足以容纳新写入数据时，在<u>键空间中</u>，移除<font color="red">最不经常使用的</font> key。</li></ol><p>以下是配置文件 <code>redis.conf</code> 中的示例：</p><figure class="highlight properties"><figcaption data-lang=".properties"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 使用 volatile-lfu 策略</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token key attr-name">maxmemory-policy</span> <span class="token value attr-value">volatile-lfu</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># 或者使用 allkeys-lfu 策略</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token key attr-name">maxmemory-policy</span> <span class="token value attr-value">allkeys-lfu</span></pre></td></tr></table></figure><p>需要注意的是， <code>hotkeys</code> 参数命令也会增加 Redis 实例的 CPU 和内存消耗（全局扫描），因此需要谨慎使用。</p><p><strong><font color="#B32015">2、使用 MONITOR 命令</font></strong></p><p><code>MONITOR</code> 命令是 Redis 提供的一种实时查看 Redis 的所有操作的方式，可以用于<font color="red">实时监控 Redis 实例的操作情况，包括读写、删除等操作</font>。</p><p>由于该命令对 Redis 性能的影响比较大，<font color="red">因此禁止长时间开启</font> <code>MONITOR</code> （生产环境中建议谨慎使用该命令）。</p><figure class="highlight java"><figcaption data-lang="java"></figcaption><table><tr><td data-num="1"></td><td><pre># redis<span class="token operator">-</span>cli</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">></span> <span class="token constant">MONITOR</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token constant">OK</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">1683638260.637378</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61516</span><span class="token punctuation">]</span> <span class="token string">"ping"</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">1683638267.144236</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">"smembers"</span> <span class="token string">"mySet"</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token number">1683638268.941863</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">"smembers"</span> <span class="token string">"mySet"</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token number">1683638269.551671</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">"smembers"</span> <span class="token string">"mySet"</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token number">1683638270.646256</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61516</span><span class="token punctuation">]</span> <span class="token string">"ping"</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token number">1683638270.849551</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">"smembers"</span> <span class="token string">"mySet"</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token number">1683638271.926945</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">"smembers"</span> <span class="token string">"mySet"</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token number">1683638274.276599</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">"smembers"</span> <span class="token string">"mySet2"</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token number">1683638276.327234</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">"smembers"</span> <span class="token string">"mySet"</span></pre></td></tr></table></figure><p>在发生紧急情况时，我们可以选择在合适的时机短暂执行 <code>MONITOR</code> 命令并将输出重定向至文件，在关闭 <code>MONITOR</code> 命令后通过对文件中请求进行归类分析即可找出这段时间中的 hotkey。</p><p><strong><font color="#B32015">3、借助开源项目</font></strong></p><p>京东零售的 <span class="exturl" data-url="aHR0cHM6Ly9naXRlZS5jb20vamQtcGxhdGZvcm0tb3BlbnNvdXJjZS9ob3RrZXk=">hotkey</span> 这个项目不光支持 hotkey 的发现，还支持 hotkey 的处理。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/jd-hotkey.png" alt="京东零售开源的 hotkey"></p><center>京东零售开源的 hotkey</center><p><strong>4、根据业务情况提前预估</strong></p><p>可以根据业务情况来预估一些 hotkey，比如参与秒杀活动的商品数据等。不过，我们无法预估所有 hotkey 的出现，比如突发的热点新闻事件等。</p><p><strong>5、业务代码中记录分析</strong></p><p>在业务代码中添加相应的逻辑对 key 的访问情况进行记录分析。不过，这种方式会让业务代码的复杂性增加，一般也不会采用。</p><p><strong><font color="#B32015">6、借助公有云的 Redis 分析服务</font></strong></p><p>如果你用的是公有云的 Redis 服务的话，可以看看其是否提供了 key 分析功能（一般都提供了）。</p><p>这里以阿里云 Redis 为例说明，它<font color="red">支持 hotkey 实时分析、发现</font>，文档地址：<span class="exturl" data-url="aHR0cHM6Ly93d3cuYWxpYmFiYWNsb3VkLmNvbS9oZWxwL3poL2Fwc2FyYWRiLWZvci1yZWRpcy9sYXRlc3QvdXNlLXRoZS1yZWFsLXRpbWUta2V5LXN0YXRpc3RpY3MtZmVhdHVyZQ==">https://www.alibabacloud.com/help/zh/apsaradb-for-redis/latest/use-the-real-time-key-statistics-feature</span> 。</p><p><img data-src="https://oss.javaguide.cn/github/javaguide/database/redis/aliyun-key-analysis.png" alt="阿里云Key分析"></p><center>阿里云Key分析</center><h3 id="如何解决-hotkey"><a class="anchor" href="#如何解决-hotkey">#</a> 如何解决 hotkey</h3><p>hotkey 的常见处理以及优化办法如下（这些方法可以配合起来使用）：</p><ul><li><strong><font color="#B32015">读写分离</font></strong>：主节点处理写请求，从节点处理读请求。</li><li><strong><font color="#B32015">使用 Redis Cluster</font></strong>：将热点数据分散存储在多个 Redis 节点上。</li><li><strong><font color="#B32015">二级缓存</font></strong>：hotkey 采用二级缓存的方式进行处理，将 hotkey 存放一份到 JVM 本地内存中（可以用 Caffeine）。</li></ul><p>除了这些方法之外，如果你使用<font color="red">公有云的 Redis 服务</font>话，还可以留意其提供的开箱即用的解决方案。</p><p>这里以阿里云 Redis 为例说明，它<font color="red">支持通过代理查询缓存功能（Proxy Query Cache）优化热点 Key 问题</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/aliyun-hotkey-proxy-query-cache.png" alt="通过阿里云的Proxy Query Cache优化热点Key问题"></p><center>通过阿里云的Proxy Query Cache优化热点Key问题</center><h2 id="慢查询命令"><a class="anchor" href="#慢查询命令">#</a> 慢查询命令</h2><h3 id="慢查询命令的产生原因"><a class="anchor" href="#慢查询命令的产生原因">#</a> 慢查询命令的产生原因</h3><p>我们知道一个 Redis 命令的执行可以简化为以下 4 步：</p><ol><li>发送命令</li><li>命令排队</li><li><font color="red">命令执行</font></li><li>返回结果</li></ol><p>Redis 慢查询统计的是命令执行这一步骤的耗时，<strong><font color="red">慢查询命令也就是那些命令执行时间较长的命令</font></strong>。</p><p>Redis 为什么会有慢查询命令呢？[O (n) 命令](#O (n) 命令)</p><h3 id="如何发现慢查询命令"><a class="anchor" href="#如何发现慢查询命令">#</a> 如何发现慢查询命令</h3><p>在 <code>redis.conf</code> 文件中，我们可以使用 <code>slowlog-log-slower-than</code> 参数设置耗时命令的阈值，并使用 <code>slowlog-max-len</code> 参数设置耗时命令的最大记录条数。</p><p><font color="red">当 Redis 服务器检测到执行时间超过 <code>slowlog-log-slower-than</code> 阈值的命令时</font>，就会将该命令记录在 **<font color="#B32015">慢查询日志 (slow log)</font>** 中，这点和 MySQL 记录慢查询语句类似。<font color="red">当慢查询日志超过设定的最大记录条数 <code>slowlog-max-len</code> 之后，Redis 会把最早的执行命令依次舍弃</font>。</p><p>⚠️注意：由于慢查询日志会占用一定内存空间，如果设置最大记录条数过大，可能会导致内存占用过高的问题。</p><p><code>slowlog-log-slower-than</code> 和 <code>slowlog-max-len</code> 的默认配置如下 (可以自行修改)：</p><figure class="highlight nginx"><figcaption data-lang="nginx"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># The following time is expressed in microseconds, so 1000000 is equivalent</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># to one second. Note that a negative number disables the slow log, while</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># a value of zero forces the logging of every command.</span></pre></td></tr><tr><td data-num="4"></td><td><pre>slowlog-log-slower-than 10000</pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># There is no limit to this length. Just be aware that it will consume memory.</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment"># You can reclaim memory used by the slow log with SLOWLOG RESET.</span></pre></td></tr><tr><td data-num="8"></td><td><pre>slowlog-max-len 128</pre></td></tr></table></figure><p>除了修改配置文件之外，你也可以直接通过 <code>CONFIG</code> 命令直接设置：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 命令执行耗时超过 10000 微妙（即 10 毫秒）就会被记录</span></pre></td></tr><tr><td data-num="2"></td><td><pre>CONFIG SET slowlog-log-slower-than <span class="token number">10000</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 只保留最近 128 条耗时命令</span></pre></td></tr><tr><td data-num="4"></td><td><pre>CONFIG SET slowlog-max-len <span class="token number">128</span></pre></td></tr></table></figure><p>获取慢查询日志的内容很简单，直接使用 <code>SLOWLOG GET</code> 命令即可。</p><figure class="highlight java"><figcaption data-lang="java"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">></span> <span class="token constant">SLOWLOG</span> <span class="token constant">GET</span> #慢日志查询</pre></td></tr><tr><td data-num="2"></td><td><pre> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">5</span></pre></td></tr><tr><td data-num="3"></td><td><pre>   <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1684326682</span></pre></td></tr><tr><td data-num="4"></td><td><pre>   <span class="token number">3</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">12000</span></pre></td></tr><tr><td data-num="5"></td><td><pre>   <span class="token number">4</span><span class="token punctuation">)</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"KEYS"</span></pre></td></tr><tr><td data-num="6"></td><td><pre>      <span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"*"</span></pre></td></tr><tr><td data-num="7"></td><td><pre>   <span class="token number">5</span><span class="token punctuation">)</span> <span class="token string">"172.17.0.1:61152"</span></pre></td></tr><tr><td data-num="8"></td><td><pre>   <span class="token number">6</span><span class="token punctuation">)</span> <span class="token string">""</span></pre></td></tr><tr><td data-num="9"></td><td><pre>  <span class="token comment">// ...</span></pre></td></tr></table></figure><p>慢查询日志中的每个条目都由以下六个值组成：</p><ol><li>唯一渐进的<font color="gree">日志标识符</font>。</li><li>处理记录命令的<font color="gree"> Unix 时间戳</font>。</li><li><font color="gree">执行所需的时间量</font>，以微秒为单位。</li><li>组成<font color="gree">命令参数</font>的数组。</li><li>客户端<font color="gree"> IP 地址和端口</font>。</li><li>客户端<font color="gree">名称</font>。</li></ol><p><code>SLOWLOG GET</code> 命令默认返回最近 10 条的的慢查询命令，你也自己可以指定返回的慢查询命令的数量 <code>SLOWLOG GET N</code> 。</p><p>下面是其他比较常用的慢查询相关的命令：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 返回慢查询命令的数量</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> SLOWLOG LEN</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">128</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># 清空慢查询命令</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>></span> SLOWLOG RESET</pre></td></tr><tr><td data-num="6"></td><td><pre>OK</pre></td></tr></table></figure><h2 id="redis-内存碎片"><a class="anchor" href="#redis-内存碎片">#</a> Redis 内存碎片</h2><h3 id="内存碎片是什么"><a class="anchor" href="#内存碎片是什么">#</a> 内存碎片是什么</h3><p>可以将内存碎片简单地理解为那些<font color="red">不可用的空闲内存</font>。</p><p>举个例子：操作系统为你分配了 32 字节的连续内存空间，而你存储数据实际只需要使用 24 字节内存空间，那这多余出来的 8 字节内存空间如果后续没办法再被分配存储其他数据的话，就可以被称为内存碎片。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/memory-fragmentation.png" alt="内存碎片"></p><center>内存碎片</center><p>Redis 内存碎片<font color="red">虽然不会影响 Redis 性能，但是会增加内存消耗</font>。</p><h3 id="redis-内存碎片的产生原因"><a class="anchor" href="#redis-内存碎片的产生原因">#</a> Redis 内存碎片的产生原因</h3><p>Redis 内存碎片产生比较常见的 2 个原因：</p><p><strong><font color="#B32015">1、Redis 存储数据时，向操作系统申请的内存空间可能会大于数据实际需要的存储空间。</font></strong></p><p>Redis 使用 <code>zmalloc</code> 方法（Redis 自己实现的内存分配方法) 进行内存分配的时候，除了要分配 <code>size</code> 大小的内存之外，还会多分配 <code>PREFIX_SIZE</code> 大小的内存。</p><blockquote><p><code>zmalloc</code> 方法源码如下（源码地址：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FudGlyZXovcmVkaXMtdG9vbHMvYmxvYi9tYXN0ZXIvem1hbGxvYy5jJUVGJUJDJTg5">https://github.com/antirez/redis-tools/blob/master/zmalloc.c）</span></p></blockquote><figure class="highlight java"><figcaption data-lang="java"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">zmalloc</span><span class="token punctuation">(</span>size_t size<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="2"></td><td><pre>   <span class="token comment">// 分配指定大小的内存</span></pre></td></tr><tr><td data-num="3"></td><td><pre>   <span class="token keyword">void</span> <span class="token operator">*</span>ptr <span class="token operator">=</span> <span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token operator">+</span><span class="token constant">PREFIX_SIZE</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="4"></td><td><pre>   <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>ptr<span class="token punctuation">)</span> <span class="token function">zmalloc_oom_handler</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="5"></td><td><pre>#ifdef <span class="token class-name">HAVE_MALLOC_SIZE</span></pre></td></tr><tr><td data-num="6"></td><td><pre>   <span class="token function">update_zmalloc_stat_alloc</span><span class="token punctuation">(</span><span class="token function">zmalloc_size</span><span class="token punctuation">(</span>ptr<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="7"></td><td><pre>   <span class="token keyword">return</span> ptr<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="8"></td><td><pre>#<span class="token keyword">else</span></pre></td></tr><tr><td data-num="9"></td><td><pre>   <span class="token operator">*</span><span class="token punctuation">(</span><span class="token punctuation">(</span>size_t<span class="token operator">*</span><span class="token punctuation">)</span>ptr<span class="token punctuation">)</span> <span class="token operator">=</span> size<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="10"></td><td><pre>   <span class="token function">update_zmalloc_stat_alloc</span><span class="token punctuation">(</span>size<span class="token operator">+</span><span class="token constant">PREFIX_SIZE</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="11"></td><td><pre>   <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token keyword">char</span><span class="token operator">*</span><span class="token punctuation">)</span>ptr<span class="token operator">+</span><span class="token constant">PREFIX_SIZE</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="12"></td><td><pre>#endif</pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><p>另外，<font color="red">Redis 可以使用多种内存分配器（libc、jemalloc、tcmalloc）来分配内存</font>，默认使用<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2plbWFsbG9jL2plbWFsbG9j"> jemalloc</span>。而 jemalloc 按照一系列固定的大小（8 字节、16 字节、32 字节……）来分配内存的。jemalloc 划分的内存单元如下图所示：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/6803d3929e3e46c1b1c9d0bb9ee8e717.png" alt="jemalloc 内存单元示意图"></p><center>jemalloc 内存单元示意图</center><p><font color="red">当程序申请的内存最接近某个固定值时，jemalloc 会给它分配相应大小的空间</font>。就比如说程序需要申请 17 字节的内存，jemalloc 会直接给它分配 32 字节的内存，这样会导致有 15 字节内存的浪费。不过，<font color="red">jemalloc 专门针对内存碎片问题做了优化，一般不会存在过度碎片化的问题</font>。</p><p><strong><font color="#B32015">2、频繁修改 Redis 中的数据也会产生内存碎片。</font></strong></p><p><font color="red">当 Redis 中的某个数据删除时，Redis 通常不会轻易释放内存给操作系统</font>。</p><p>这个在 Redis 官方文档中也有对应的原话：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-docs-memory-optimization.png" alt="img"></p><p>文档地址：<span class="exturl" data-url="aHR0cHM6Ly9yZWRpcy5pby90b3BpY3MvbWVtb3J5LW9wdGltaXphdGlvbg==">https://redis.io/topics/memory-optimization</span> 。</p><h3 id="如何查看-redis-内存碎片的信息"><a class="anchor" href="#如何查看-redis-内存碎片的信息">#</a> 如何查看 Redis 内存碎片的信息</h3><p>使用 <code>info memory</code> 命令即可查看 Redis 内存相关的信息。下图中每个参数具体的含义，Redis 官方文档有详细的介绍：<span class="exturl" data-url="aHR0cHM6Ly9yZWRpcy5pby9jb21tYW5kcy9JTkZP">https://redis.io/commands/INFO</span> 。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-info-memory.png" alt="img"></p><p>Redis 内存碎片率的计算公式： <code>mem_fragmentation_ratio</code> （内存碎片率）= <code>used_memory_rss</code> (操作系统实际分配给 Redis 的物理内存空间大小)/ <code>used_memory</code> (Redis 内存分配器为了存储数据实际申请使用的内存空间大小)</p><p>也就是说， <code>mem_fragmentation_ratio</code> （内存碎片率）的值越大代表内存碎片率越严重。</p><p>一定不要误认为 <code>used_memory_rss</code> 减去 <code>used_memory</code> 值就是内存碎片的大小！！！这不仅包括内存碎片，还包括其他进程开销，以及共享库、堆栈等的开销。</p><p>很多小伙伴可能要问了：“多大的内存碎片率才是需要清理呢？”。</p><p>通常情况下，我们认为 <code>mem_fragmentation_ratio &gt; 1.5</code> 的话才需要清理内存碎片。 <code>mem_fragmentation_ratio &gt; 1.5</code> 意味着你使用 Redis 存储实际大小 2G 的数据需要使用大于 3G 的内存。</p><p>如果想要快速查看内存碎片率的话，你还可以通过下面这个命令：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">></span> redis-cli <span class="token parameter variable">-p</span> <span class="token number">6379</span> info <span class="token operator">|</span> <span class="token function">grep</span> mem_fragmentation_ratio</pre></td></tr></table></figure><p>另外，内存碎片率可能存在小于 1 的情况。这种情况我在日常使用中还没有遇到过，感兴趣的小伙伴可以看看这篇文章 <span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvZHJsRHZwN2JmcTVqdDJNNXBUcUpDdw==">故障分析 | Redis 内存碎片率太低该怎么办？- 爱可生开源社区</span> 。</p><h3 id="如何清理-redis-内存碎片"><a class="anchor" href="#如何清理-redis-内存碎片">#</a> 如何清理 Redis 内存碎片？</h3><p>Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题。</p><p><font color="red">直接通过 <code>config set</code> 命令将 <code>activedefrag</code> 配置项设置为 <code>yes</code> 即可</font>。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>config <span class="token builtin class-name">set</span> activedefrag <span class="token function">yes</span></pre></td></tr></table></figure><p>具体什么时候清理需要通过下面两个参数控制：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 内存碎片占用空间达到 500mb 的时候开始清理</span></pre></td></tr><tr><td data-num="2"></td><td><pre>config <span class="token builtin class-name">set</span> active-defrag-ignore-bytes 500mb</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 内存碎片率大于 1.5 的时候开始清理</span></pre></td></tr><tr><td data-num="4"></td><td><pre>config <span class="token builtin class-name">set</span> active-defrag-threshold-lower <span class="token number">50</span></pre></td></tr></table></figure><p>通过 Redis 自动内存碎片清理机制可能会对 Redis 的性能产生影响，我们可以通过下面两个参数来减少对 Redis 性能的影响：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 内存碎片清理所占用 CPU 时间的比例不低于 20%</span></pre></td></tr><tr><td data-num="2"></td><td><pre>config <span class="token builtin class-name">set</span> active-defrag-cycle-min <span class="token number">20</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 内存碎片清理所占用 CPU 时间的比例不高于 50%</span></pre></td></tr><tr><td data-num="4"></td><td><pre>config <span class="token builtin class-name">set</span> active-defrag-cycle-max <span class="token number">50</span></pre></td></tr></table></figure><p>另外，<font color="red">重启节点可以做到内存碎片重新整理</font>。如果你采用的是高可用架构的 Redis 集群的话，你<font color="red">可以将碎片率过高的主节点转换为从节点，以便进行安全重启</font>。</p><h1 id="redis-生产问题高并发问题"><a class="anchor" href="#redis-生产问题高并发问题">#</a> <mark>🌟Redis 生产问题（高并发问题）</mark></h1><h2 id="缓存穿透"><a class="anchor" href="#缓存穿透">#</a> 缓存穿透</h2><h3 id="是什么-5"><a class="anchor" href="#是什么-5">#</a> 是什么</h3><p>缓存穿透说简单点就是 **<font color="#B32015"><font color="orange">大量请求的 key 既不存在于缓存中，也不存在于数据库中</font>，进行了两次无用的查询，最终返回空数据</font>**。这就<font color="red">导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-cache-penetration.png" alt="缓存穿透"></p><center>缓存穿透</center><p>举个例子：某个黑客故意制造一些非法的 key 发起大量请求，导致大量请求落到数据库，结果数据库上也没有查到对应的数据。也就是说这些请求最终都落到了数据库上，对数据库造成了巨大的压力。</p><h3 id="如何解决"><a class="anchor" href="#如何解决">#</a> 如何解决</h3><p>最基本的就是<font color="red">首先做好参数校验</font>，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。</p><h4 id="1缓存无效-key"><a class="anchor" href="#1缓存无效-key">#</a> 1）缓存无效 key</h4><p><font color="red">将缓存和数据库都查不到某个 key 的数据写到 Redis 中，并设置过期时间</font>。具体命令如下： <code>SET key value EX 10086</code> 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，<strong><font color="red">这种方案并不能从根本上解决此问题</font></strong>。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。</p><p>另外，这里多说一嘴，一般情况下我们是这样设计 key 的： <code>表名:列名:主键名:主键值</code> 。</p><p>如果用 Java 代码展示的话，差不多是下面这样的：</p><figure class="highlight java"><figcaption data-lang="java"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">public</span> <span class="token class-name">Object</span> <span class="token function">getObjectInclNullById</span><span class="token punctuation">(</span><span class="token class-name">Integer</span> id<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token comment">// 从缓存中获取数据</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token class-name">Object</span> cacheValue <span class="token operator">=</span> cache<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token comment">// 缓存为空</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token keyword">if</span> <span class="token punctuation">(</span>cacheValue <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        <span class="token comment">// 从数据库中获取</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token class-name">Object</span> storageValue <span class="token operator">=</span> storage<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        <span class="token comment">// 缓存空对象</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        cache<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> storageValue<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        <span class="token comment">// 如果存储数据为空，需要设置一个过期时间 (300 秒)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        <span class="token keyword">if</span> <span class="token punctuation">(</span>storageValue <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="12"></td><td><pre>            <span class="token comment">// 必须设置过期时间，否则有被攻击的风险</span></pre></td></tr><tr><td data-num="13"></td><td><pre>            cache<span class="token punctuation">.</span><span class="token function">expire</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        <span class="token keyword">return</span> storageValue<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">return</span> cacheValue<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><h4 id="2布隆过滤器"><a class="anchor" href="#2布隆过滤器">#</a> 2）布隆过滤器</h4><blockquote><p>常用方法</p></blockquote><p>布隆过滤器是一个非常神奇的数据结构，它将所有可能存在的数据哈希到一个足够大的 <code>bitmap</code> 中，<strong><font color="red">一个一定不存在的数据会被拦截掉</font></strong>，从而避免了对底层存储系统的查询压力。通过它我们<font color="red">可以非常方便地判断一个给定数据是否存在于海量数据中</font>。我们需要的就是<font color="red">判断 key 是否合法</font>，有没有感觉布隆过滤器就是我们想要找的那个 “人”。</p><p>具体是这样做的：把所有可能存在的请求值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求值是否存在于布隆过滤器中。<font color="red">不存在的话，直接返回请求参数错误信息给客户端</font>，存在的话才会走下面的流程。</p><p>加入布隆过滤器之后的缓存处理流程图如下：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-cache-penetration-bloom-filter.png" alt="加入布隆过滤器之后的缓存处理流程图"></p><center>加入布隆过滤器之后的缓存处理流程图</center><p>但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是：<strong><font color="red">布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。</font></strong></p><hr><p><em>为什么会出现误判的情况呢？我们还要从布隆过滤器的原理来说！</em></p><p>我们先来看一下，<strong>当一个元素加入布隆过滤器中的时候，会进行哪些操作：</strong></p><ol><li>使用布隆过滤器中的<font color="red">哈希函数</font>对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。</li><li>根据得到的哈希值，在<font color="gree">位数组</font>中把对应下标的值置为 1。</li></ol><p>我们再来看一下，<strong>当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：</strong></p><ol><li>对给定元素再次进行相同的哈希计算；</li><li>得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。</li></ol><p>然后，一定会出现这样一种情况：<strong><font color="red">不同的字符串可能哈希出来的位置相同。</font></strong> （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）</p><p>更多关于布隆过滤器的内容可以看我的这篇原创：<span class="exturl" data-url="aHR0cHM6Ly9qYXZhZ3VpZGUuY24vY3MtYmFzaWNzL2RhdGEtc3RydWN0dXJlL2Jsb29tLWZpbHRlci8=">《不了解布隆过滤器？一文给你整的明明白白！》</span> ，强烈推荐，个人感觉网上应该找不到总结的这么明明白白的文章了。</p><h2 id="缓存击穿"><a class="anchor" href="#缓存击穿">#</a> 缓存击穿</h2><h3 id="是什么-6"><a class="anchor" href="#是什么-6">#</a> 是什么</h3><p>缓存击穿中，<strong><font color="orange">请求的 key 是<u>热点数据</u>，该数据存在于数据库中，但不存在于缓存中（通常因为缓存中的那份数据已经过期）</font></strong>。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-cache-breakdown.png" alt="缓存击穿"></p><center>缓存击穿</center><p>举个例子：秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力。</p><h3 id="如何解决-2"><a class="anchor" href="#如何解决-2">#</a> 如何解决</h3><ul><li><p>针对热点数据提前预热，<strong><font color="red">将热点数据存入缓存中并设置合理的过期时间（永不过期 / 过期时间较长）</font></strong>。比如秒杀场景下的数据在秒杀结束之前不过期。</p></li><li><p>请求数据库写数据到缓存之前，先<font color="red">获取互斥锁 mutex</font>，保证只有一个请求会落到数据库上，减少数据库的压力。</p></li></ul><h3 id="缓存穿透与缓存击穿的区别"><a class="anchor" href="#缓存穿透与缓存击穿的区别">#</a> 缓存穿透与缓存击穿的区别</h3><p>缓存穿透中，请求的 key 既不存在于缓存中，也不存在于数据库中。</p><p>缓存击穿中，请求的 key 对应的是 <strong>热点数据</strong> ，该数据 <strong>存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）</strong> 。</p><h2 id="缓存雪崩"><a class="anchor" href="#缓存雪崩">#</a> 缓存雪崩</h2><h3 id="是什么-7"><a class="anchor" href="#是什么-7">#</a> 是什么</h3><p>实际上，缓存雪崩描述的就是这样一个简单的场景：**<font color="#B32015"><font color="orange">缓存在同一时间大面积失效</font>，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。</font>** 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。</p><p>另外，<font color="red">缓存服务宕机也会导致缓存雪崩现象，导致所有的请求都落到了数据库上</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-cache-avalanche.png" alt="缓存雪崩"></p><center>缓存雪崩</center><p>举个例子：数据库中的大量数据在同一时间过期，这个时候突然有大量的请求需要访问这些过期的数据。这就导致大量的请求直接落到数据库上，对数据库造成了巨大的压力。</p><h3 id="如何解决-3"><a class="anchor" href="#如何解决-3">#</a> 如何解决</h3><p><strong>针对热点缓存失效的情况：</strong></p><ol><li>设置不同的失效时间，比如<font color="red">随机设置缓存的失效时间</font>。</li><li>缓存永不失效（不太推荐，实用性太差）。</li><li><font color="red">设置二级缓存</font>。</li></ol><p><strong>针对 Redis 服务不可用的情况：</strong></p><ol><li><font color="red">采用 Redis 集群</font>，避免单机出现问题整个缓存服务都没办法使用。</li><li><font color="red">限流</font>，避免同时处理大量的请求。</li></ol><h3 id="缓存雪崩与缓存击穿的区别"><a class="anchor" href="#缓存雪崩与缓存击穿的区别">#</a> 缓存雪崩与缓存击穿的区别</h3><p>缓存雪崩和缓存击穿比较像，但<font color="red">导致缓存雪崩的原因是缓存中的大量或者所有数据失效</font>，<font color="red">导致缓存击穿的原因主要是某个热点数据不存在于缓存中（通常是因为缓存中的那份数据已经过期）</font>。</p><h2 id="如何保证缓存和数据库数据的一致性"><a class="anchor" href="#如何保证缓存和数据库数据的一致性">#</a> 如何保证缓存和数据库数据的一致性？</h2><p>个人觉得引入缓存之后，如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要。</p><p>下面单独对 **<font color="#B32015">Cache Aside Pattern（旁路缓存模式）</font>** 来聊聊。</p><p>Cache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 。</p><p>如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：</p><ol><li><strong>缩短缓存失效时间（不推荐，治标不治本）</strong>：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。</li><li><strong><font color="#B32015">增加 cache 更新重试机制（常用）</font></strong>：如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。</li></ol><p>相关文章推荐：<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3M/X19iaXo9TXpJeU9UWXhOREk1T0E9PSZhbXA7bWlkPTIyNDc0ODczMTImYW1wO2lkeD0xJmFtcDtzbj1mYTE5NTY2ZjU3MjlkNjU5ODE1NWI1YzY3NmVlZTYyZCZhbXA7Y2hrc209ZThiZWI4ZTVkZmM5MzFmM2UzNTY1NWRhOWRhMGI2MWM3OWYyODQzMTAxYzEzMGNmMzg5OTY0NDY5NzUwMTRmOTU4YTY0ODFhYWNmMSZhbXA7c2NlbmU9MTc4JmFtcDtjdXJfYWxidW1faWQ9MTY5OTc2NjU4MDUzODAzMjEyOCNyZA==">缓存和数据库一致性问题，看这篇就够了 - 水滴与银弹</span>。</p><h2 id="redis-阻塞的常见原因"><a class="anchor" href="#redis-阻塞的常见原因">#</a> Redis 阻塞的常见原因</h2><h3 id="on-命令"><a class="anchor" href="#on-命令">#</a> O (n) 命令</h3><p>Redis 中的大部分命令都是 O (1) 时间复杂度，但也有少部分<font color="red"> O (n) 时间复杂度的命令</font>，例如：</p><ul><li><code>KEYS *</code> ：会返回所有符合规则的 key。</li><li><code>HGETALL</code> ：会返回一个 Hash 中所有的键值对。</li><li><code>LRANGE</code> ：会返回 List 中指定范围内的元素。</li><li><code>SMEMBERS</code> ：返回 Set 中的所有元素。</li><li><code>SINTER</code> / <code>SUNION</code> / <code>SDIFF</code> ：计算多个 Set 的交集 / 并集 / 差集。</li><li>……</li></ul><p>由于这些命令时间复杂度是 O (n)，有时候也会全表扫描，随着 n 的增大，执行耗时也会越长。不过，这些命令并不是一定不能使用，但是需要明确 N 的值。另外，<font color="red">有遍历的需求可以使用 <code>HSCAN</code> 、 <code>SSCAN</code> 、 <code>ZSCAN</code> 代替</font>。</p><p>除了这些 O (n) 时间复杂度的命令可能会导致慢查询之外， 还有一些<font color="red">时间复杂度可能在 O (N) 以上的命令</font>，例如：</p><ul><li><code>ZRANGE</code> / <code>ZREVRANGE</code> ：返回指定 Sorted Set 中指定排名范围内的所有元素。时间复杂度为 O (log (n)+m)，n 为所有元素的数量， m 为返回的元素数量，当 m 和 n 相当大时，O (n) 的时间复杂度更小。</li><li><code>ZREMRANGEBYRANK</code> / <code>ZREMRANGEBYSCORE</code> ：移除 Sorted Set 中指定排名范围 / 指定 score 范围内的所有元素。时间复杂度为 O (log (n)+m)，n 为所有元素的数量， m 被删除元素的数量，当 m 和 n 相当大时，O (n) 的时间复杂度更小。</li><li>……</li></ul><h3 id="save-创建-rdb-快照"><a class="anchor" href="#save-创建-rdb-快照">#</a> SAVE 创建 RDB 快照</h3><p>Redis 提供了两个命令来生成 RDB 快照文件：</p><ul><li><code>save</code> : 同步保存操作，<strong><font color="red">会阻塞 Redis 主线程</font></strong>；</li><li><code>bgsave</code> : fork 出一个子进程，子进程执行，<font color="red">不会阻塞 Redis 主线程</font>，默认选项。</li></ul><p>默认情况下，Redis 默认配置会使用 <code>bgsave</code> 命令。如果手动使用 <code>save</code> 命令生成 RDB 快照文件的话，就会阻塞主线程。</p><h3 id="aof"><a class="anchor" href="#aof">#</a> AOF</h3><h4 id="aof-日志记录阻塞"><a class="anchor" href="#aof-日志记录阻塞">#</a> AOF 日志记录阻塞</h4><p><strong><font color="red">AOF 持久化机制是在执行完命令之后再记录日志</font></strong>，这和关系型数据库（如 MySQL）通常都是执行命令之前记录日志（方便故障恢复）不同。</p><p><img data-src="https://oss.javaguide.cn/github/javaguide/database/redis/redis-aof-write-log-disc.png" alt="AOF 记录日志过程"></p><center>AOF 记录日志过程</center><p>为什么是在执行完命令之后记录日志呢？</p><ul><li><font color="red">避免额外的命令语法检查开销</font>，AOF 记录日志不会对命令进行语法检查；</li><li>在命令执行完之后再记录，<font color="red">不会阻塞当前的命令执行</font>。</li></ul><p>这样也带来了风险（我在前面介绍 AOF 持久化的时候也提到过）：</p><ul><li>如果刚执行完命令 Redis 就宕机，会导致对应的修改丢失；</li><li><strong><font color="red">由于 AOF 记录日志是在 Redis 主线程中进行的，因此可能会阻塞后续其他命令的执行</font></strong>。</li></ul><h4 id="aof-刷盘阻塞"><a class="anchor" href="#aof-刷盘阻塞">#</a> AOF 刷盘阻塞</h4><p>开启 AOF 持久化后，Redis 会将每条执行的写命令写入到 AOF 缓冲区 <code>server.aof_buf</code> 中，然后再根据 <code>appendfsync</code> 配置参数来决定何时将其同步到硬盘中的 AOF 文件（刷盘）。</p><p>在 Redis 的配置文件中存在三种不同的 AOF 持久化方式（ <code>fsync</code> 策略）：</p><ol><li><code>always</code> ：主线程调用 <code>write</code> 执行写操作后，后台线程（ <code>aof_fsync</code> 线程）立即会调用 <code>fsync</code> 函数同步 AOF 文件（刷盘）， <code>fsync</code> 完成后线程返回，这样会严重降低 Redis 的性能（ <code>write</code> + <code>fsync</code> ）。</li><li><code>everysec</code> ：主线程调用 <code>write</code> 执行写操作后立即返回，由后台线程（ <code>aof_fsync</code> 线程）每秒钟调用 <code>fsync</code> 函数（系统调用）同步一次 AOF 文件（ <code>write</code> + <code>fsync</code> ， <code>fsync</code> 间隔为 1 秒）</li><li><code>no</code> ：主线程调用 <code>write</code> 执行写操作后立即返回，让操作系统决定何时进行同步，Linux 下一般为 30 秒一次（ <code>write</code> 但不 <code>fsync</code> ， <code>fsync</code> 的时机由操作系统决定）。</li></ol><p><font color="red">当后台线程（ <code>aof_fsync</code> 线程）调用 <code>fsync</code> 函数同步 AOF 文件时，需要等待，直到写入完成</font>。当磁盘压力太大的时候，会导致 <code>fsync</code> 操作发生阻塞，主线程调用 <code>write</code> 函数时也会被阻塞。<font color="red"> <code>fsync</code> 完成后，主线程执行 <code>write</code> 才能成功返回</font>。</p><p>关于 AOF 工作流程的详细介绍可以查看：[AOF 持久化](#AOF 持久化)，有助于理解 AOF 刷盘阻塞。</p><h4 id="aof-重写阻塞"><a class="anchor" href="#aof-重写阻塞">#</a> AOF 重写阻塞</h4><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/2032648-20220207170749957-1755223036.png" alt="img"></p><ol><li>主线程 fork 出一条子线程来将文件重写，在执行 <code>BGREWRITEAOF</code> 命令时，Redis 服务器会维护一个<font color="gree"> AOF 重写缓冲区</font>，该缓冲区会在子线程创建新 AOF 文件期间，记录服务器执行的所有写命令。</li><li><font color="red">当子线程完成创建新 AOF 文件的工作之后，服务器会将 AOF 重写缓冲区中的所有内容追加到新 AOF 文件的末尾</font>，使得新的 AOF 文件保存的数据库状态与现有的数据库状态一致。</li><li>最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。</li></ol><p>阻塞就是出现在第 2 步的过程中，将 AOF 重写缓冲区中的新数据写到新 AOF 文件的过程中会产生<strong>阻塞</strong>。</p><p>相关阅读：<span class="exturl" data-url="aHR0cHM6Ly9jbG91ZC50ZW5jZW50LmNvbS9kZXZlbG9wZXIvYXJ0aWNsZS8xNjMzMDc3">Redis AOF 重写阻塞问题分析</span>。</p><h3 id="bigkey"><a class="anchor" href="#bigkey">#</a> bigkey</h3><p>[bigkey 是什么](#bigkey 是什么)</p><p>[bigkey 的危害](#bigkey 的危害)</p><h4 id="查找-bigkey"><a class="anchor" href="#查找-bigkey">#</a> 查找 bigkey</h4><blockquote><p>[如何发现 bigkey](# 如何发现 bigkey)</p></blockquote><p>当我们在使用 Redis 自带的 <code>--bigkeys</code> 参数查找大 key 时，<font color="red">最好选择在从节点上执行该命令</font>，因为主节点上执行时，会<strong>阻塞</strong>主节点。</p><ul><li>我们还可以使用 <code>SCAN</code> 命令来查找大 key；</li><li>通过分析 RDB 文件来找出 big key，这种方案的前提是 Redis 采用的是 RDB 持久化。网上有现成的工具：<ul><li>redis-rdb-tools：Python 语言写的用来分析 Redis 的 RDB 快照文件用的工具</li><li>rdb_bigkeys：Go 语言写的用来分析 Redis 的 RDB 快照文件用的工具，性能更好。</li></ul></li></ul><h4 id="删除-bigkey"><a class="anchor" href="#删除-bigkey">#</a> 删除 bigkey</h4><p>删除操作的本质是要释放键值对占用的内存空间。</p><p>释放内存只是第一步，为了更加高效地管理内存空间，<strong><font color="red">在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配</font></strong>。这个过程本身需要一定时间，而且会 **<font color="red">阻塞</font>** 当前释放内存的应用程序。</p><p>所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞，如果主线程发生了阻塞，其他所有请求可能都会超时，超时越来越多，会造成 Redis 连接耗尽，产生各种异常。</p><p>删除大 key 时建议采用<font color="cornflowerblue">分批次删除</font>和<font color="cornflowerblue">异步删除</font>的方式进行。</p><h3 id="清空数据库"><a class="anchor" href="#清空数据库">#</a> 清空数据库</h3><p>清空数据库和上面 bigkey 删除也是同样道理，<font color="red"> <code>flushdb</code> 、 <code>flushall</code> 也涉及到删除和释放所有的键值对，也是 Redis 的阻塞点</font>。</p><h3 id="集群扩容-缩容"><a class="anchor" href="#集群扩容-缩容">#</a> 集群扩容、缩容</h3><p>Redis 集群可以进行<font color="red">节点的动态扩容、缩容</font>，这一过程目前还处于半自动状态，需要人工介入。</p><p>在扩缩容的时候，需要进行<font color="red">数据迁移</font>。而 Redis 为了保证迁移的一致性，<font color="red">迁移所有操作都是同步操作</font>。</p><p>执行迁移时，两端的 Redis 均会进入时长不等的<font color="red">阻塞</font>状态，对于小 Key，该时间可以忽略不计，但如果一旦 Key 的内存使用过大，严重的时候会触发集群内的故障转移，造成不必要的切换。</p><h3 id="swap内存交换"><a class="anchor" href="#swap内存交换">#</a> Swap（内存交换）</h3><p>Linux 中的 Swap 常被称为内存交换。类似于 Windows 中的虚拟内存，就是<font color="red">当内存不足的时候，把一部分硬盘空间虚拟成内存使用，从而解决内存容量不足的情况</font>。因此，Swap 分区的作用就是<font color="red">牺牲硬盘，增加内存</font>，解决 VPS 内存不够用或者爆满的问题。</p><p><strong><font color="red">Swap 对于 Redis 来说是非常致命的，因为 Redis 保证高性能的一个重要前提是所有的数据在内存中</font></strong>。如果操作系统把 Redis 使用的部分内存换出硬盘，由于内存与硬盘的读写速度差几个数量级，会导致发生交换后的 Redis 性能急剧下降。</p><p>识别 Redis 发生 Swap 的检查方法如下：</p><p>1、查询 Redis 进程号</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>reids-cli <span class="token parameter variable">-p</span> <span class="token number">6383</span> info server <span class="token operator">|</span> <span class="token function">grep</span> process_id</pre></td></tr><tr><td data-num="2"></td><td><pre>process_id: <span class="token number">4476</span></pre></td></tr></table></figure><p>2、根据进程号查询内存交换信息</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">cat</span> /proc/4476/smaps <span class="token operator">|</span> <span class="token function">grep</span> Swap</pre></td></tr><tr><td data-num="2"></td><td><pre>Swap: 0kB</pre></td></tr><tr><td data-num="3"></td><td><pre>Swap: 0kB</pre></td></tr><tr><td data-num="4"></td><td><pre>Swap: 4kB</pre></td></tr><tr><td data-num="5"></td><td><pre>Swap: 0kB</pre></td></tr><tr><td data-num="6"></td><td><pre>Swap: 0kB</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token punctuation">..</span><span class="token punctuation">..</span>.</pre></td></tr></table></figure><p>如果交换量都是 0KB 或者个别的是 4KB，则正常。</p><p>预防内存交换的方法：</p><ul><li>保证机器充足的可用内存</li><li>确保所有 Redis 实例设置最大可用内存 (maxmemory)，防止极端情况 Redis 内存不可控的增长</li><li>降低系统使用 swap 优先级，如 <code>echo 10 &gt; /proc/sys/vm/swappiness</code></li></ul><h3 id="cpu-竞争"><a class="anchor" href="#cpu-竞争">#</a> CPU 竞争</h3><p><font color="red">Redis 是典型的 CPU 密集型应用，不建议和其他多核 CPU 密集型服务部署在一起</font>。当其他进程过度消耗 CPU 时，将严重影响 Redis 的吞吐量。</p><p>可以通过 <code>reids-cli --stat</code> 获取当前 Redis 使用情况。通过 <code>top</code> 命令获取进程对 CPU 的利用率等信息，通过 <code>info commandstats</code> 统计信息分析出命令不合理开销时间，查看是否是因为高算法复杂度或者过度的内存优化问题。</p><h3 id="网络问题"><a class="anchor" href="#网络问题">#</a> 网络问题</h3><p>连接拒绝、网络延迟，网卡软中断等网络问题也可能会导致 Redis 阻塞。</p><h1 id="redis-发布订阅pubsub"><a class="anchor" href="#redis-发布订阅pubsub">#</a> Redis 发布订阅（pub/sub）</h1><blockquote><p>这是 Redis 的第一代消息中间件，第二代是 Stream，然而<strong>一般使用的都是更加成熟的第三方消息中间件</strong>。</p><p><strong>了解即可</strong>，实际工作中用的很少，一般都是将 Redis 用作<strong>分布式缓存</strong>。</p></blockquote><h2 id="消息系统"><a class="anchor" href="#消息系统">#</a> 消息系统</h2><p>发布 / 订阅，即 pub/sub，是<font color="red">一种消息通信模式</font>：发布者也称为消息生产者，生产和发送消息到存储系统；订阅者也称为消息消费者，从存储系统接收和消费消息。这个存储系统可以是文件系统 FS、消息中间件 MQ、数据管理系统 DBMS，也可以是 Redis。<font color="red">整个消息发布者、订阅者、存储系统称为消息系统</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231207161229390.png" alt="image-20231207161229390"></p><p>消息系统中的订阅者订阅了某类消息后，只要存储系统中存在该类消息，其就可不断的接收并消费这些消息。当存储系统中没有该消息后，订阅者的接收、消费阻塞。而当发布者将消息写入到存储系统后，会立即唤醒订阅者。当存储系统放满时，不同的发布者具有不同的处理方式：有的会阻塞发布者的发布，等待可用的存储空间；有的则会将多余的消息丢失。</p><p>当然，不同的消息系统消息的发布 / 订阅方式也是不同的。例如 RocketMQ、 Kafka 等消息中间件构成的消息系统中，发布 / 订阅的消息都是以<font color="gree">主题 Topic </font>分类的。而 Redis 构成的消息系统中，发布 / 订阅的消息都是以<font color="gree">频道 Channel </font>分类的。</p><h2 id="pubsub-简介"><a class="anchor" href="#pubsub-简介">#</a> pub/sub 简介</h2><p>Redis 发布订阅（pub/sub）是一种消息通信模式：<font color="red">发送者 (PUBLISH) 发送消息，订阅者 (SUBSCRIBE) 接收消息</font>，可以实现进程间的消息传递。</p><p>一言蔽之：Redis 可以通过发布订阅实现消息的引导和分流，实现消息中间件 MQ 的功能。但是<font color="red">不推荐使用</font>该功能，专业的事情交给专业的中间件处理，redis 就做好分布式缓存功能。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807173639960.png" alt="image-20230807173639960"></p><center>Redis客户端可以订阅任意数量的频道，类似微信关注多个公众号</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807173711847.png" alt="image-20230807173711847"></p><center>当有新消息通过PUBLISH命令发送给频道时</center><p>小结：发布 / 订阅其实是<strong>一个轻量的队列</strong>，只不过<strong>数据不会被持久化</strong>，一般<strong>用来处理实时性较高的异步消息</strong>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807173943443.png" alt="image-20230807173943443"></p><h2 id="相关命令"><a class="anchor" href="#相关命令">#</a> 相关命令</h2><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td><code>PUBLISH</code> channel message</td><td>发布一个频道的消息。返回值为接收到该消息的订阅者数量。</td></tr><tr><td><code>SUBSCRIBE</code> channel [channel ...]</td><td>同时订阅任意数量的 channel。在输出了订阅了主题后，命令处于阻塞状态，等待相关 channel 的消息。</td></tr><tr><td><code>PSUBSCRIBE</code> pattern [pattern …]</td><td>订阅一个或多个符合给定模式 pattern 的频道 channel。这里的 pattern 只能使用通配符 *。例如，it* 可以匹配所有以 it 开头的频道，像 it.news、it.blog、 it.tweets 等；news.* 可以匹配所有以 news. 开头的频道，像 news.global.today、<span class="exturl" data-url="aHR0cDovL25ld3MuaXQ=">news.it</span> 等。</td></tr><tr><td><code>UNSUBSCRIBE</code> [channel [channel …]]</td><td>退订指定的频道。如果没有频道被指定，也就是一个无参数的 UNSUBSCRIBE 命令被执行，那么客户端使用 SUBSCRIBE 命令订阅的所有频道都会被退订。在这种情况下，命令会返回一个信息，告知客户端所有被退订的频道。</td></tr><tr><td><code>PUNSUBSCRIBE</code> [channel [channel …]]</td><td>退订一个或多个符合给定模式的频道。这里的 pattern 也只能使用通配符 *。</td></tr><tr><td><code>PUBSUB</code> &lt;subcommand&gt; [argument [argument …]]</td><td>PUBSUB 是一个<font color="red">查看订阅与发布系统状态</font>的<font color="red">内省命令集</font>，它由数个不同格式的子命令组成。</td></tr></tbody></table><h2 id="缺点-4"><a class="anchor" href="#缺点-4">#</a> 缺点</h2><ul><li><p>在 Redis 系统中 **<font color="red">发布的消息不能持久化</font>**。因此，<font color="red">必须先执行订阅，再等待消息发布</font>。如果先发布了消息，那么该消息由于没有订阅者，消息将被直接丢弃。</p></li><li><p>消息只管发送，对于发布者而言消息是即发即失的，不管接收，也 **<font color="red">没有 ACK 机制</font>**，无法保证消息的消费成功。</p></li><li><p>以上的缺点导致 **<font color="#B32015">Redis 的 Pub/Sub 模式就像个小玩具</font>**，在生产环境中几乎无用武之地。</p><blockquote><p>为此 Redis5.0 版本新增了 Stream 数据结构，不但支持多播，还支持数据持久化，相比 Pub/Sub 更加的强大，但是也不推荐使用。</p></blockquote></li></ul><h1 id="redis-集群高可用"><a class="anchor" href="#redis-集群高可用">#</a> <mark>🌟Redis 集群（高可用）</mark></h1><blockquote><p>Redis 为了支持高可用（HA），有 2 套机制：</p><ul><li>主从复制（replica）+ 哨兵（sentinel）</li><li>集群（cluster）</li></ul></blockquote><p>为了避免 Redis 的单点故障问题，我们可以搭建一个 Redis 集群，将数据备份到集群中的其它节点上。若一个 Redis 节点宕机，则由集群中的其它节点顶上。</p><h2 id="主从复制replica"><a class="anchor" href="#主从复制replica">#</a> 主从复制（replica）</h2><h3 id="是什么-8"><a class="anchor" href="#是什么-8">#</a> 是什么</h3><blockquote><p>承上启下的一节，前文都是在单机场景下，从此开始介绍多台 Redis 机器的场景，即<strong>通过主从复制支持多可用性、故障转移</strong>。</p></blockquote><p>Redis 的主从集群是一个<font color="red">“一主多从” 的读写分离集群</font>。集群中的 <strong><font color="red">Master 节点负责处理客户端的读写请求，而 Slave 节点仅能处理客户端的读请求</font></strong>。之所以要将集群搭建为读写分离模式，主要原因是，对于数据库集群，写操作压力一般都较小，压力大多数来自于读操作请求。所以，只有一个节点负责处理写操作请求即可。</p><p>当 Master 节点上的数据变化时，会自动将新数据<font color="red">异步复制</font>到其他 Slave 节点上。</p><h3 id="作用"><a class="anchor" href="#作用">#</a> 作用</h3><p>Redis 主从复制（replica）的功能如下：</p><ul><li><strong><font color="red">读写分离</font></strong></li><li><strong>容灾恢复</strong></li><li><strong>数据备份</strong></li><li><strong>水平扩容，支撑高并发</strong></li></ul><h3 id="基本命令"><a class="anchor" href="#基本命令">#</a> 基本命令</h3><ul><li><p><code>INFO replication</code> ：以一种易于理解和阅读的格式，<font color="red">返回关于当前 Redis 服务器的<strong>直接主 / 从</strong>复制信息</font></p></li><li><p><code>REPLICAOF masterIp masterPort</code> ：<font color="red">修改当前 Redis 服务器的主 / 从复制设置（自动配置）</font></p><blockquote><p>一般写入进 redis.conf 配置文件内</p></blockquote></li><li><p><code>SLAVEOF masterIp masterPort</code> ：将当前 Redis 服务器<font color="red">转变为指定服务器的从属服务器</font>（手动配置）</p><ul><li>每次与 master 断开之后，都需要<font color="red">重新连接</font>，除非你配置进 redis.conf 文件</li><li>在运行期间修改 slave 节点的信息，如果该数据库已经是某个主数据库的从数据库，那么会停止和原主数据库的同步关系，转而和新的主数据库同步，<font color="red">改换门庭</font></li></ul></li><li><p><code>SLAVEOF NO ONE</code> ：将使得这个从属服务器关闭复制功能，并从从属服务器<font color="red">转回主服务器，自立为王</font>，同时原来同步所得的数据集不会被丢弃。</p></li></ul><h3 id="常用的3招"><a class="anchor" href="#常用的3招">#</a> 常用的 3 招</h3><p>配置方法：<strong><font color="#B32015">配从不配主</font></strong></p><ol><li><p>master 如果配置了 <code>requirepass</code> 参数，需要密码登陆</p></li><li><p>那么 slave 就要配置 <code>masterauth</code> 来设置校验密码，否则 master 会拒绝 slave 的访问请求</p></li></ol><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807183910365.png" alt="image-20230807183910365"></p><h4 id="一主二从"><a class="anchor" href="#一主二从">#</a> 一主二从</h4><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807201752116.png" alt="image-20230807201752116"></p><h5 id="方案1配置文件固定写死"><a class="anchor" href="#方案1配置文件固定写死">#</a> 方案 1：配置文件固定写死</h5><ol><li><p>配从（6380 和 6381）不配主</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807193239828.png" alt="image-20230807193239828"></p></li><li><p>依次启动 master 和两台 slave</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807193418057.png" alt="image-20230807193418057"></p></li><li><p>查看主从关系</p><ol><li><p>通过日志文件：通过 <code>vim 6379.log</code> 查看 master 日志，通过 <code>vim 6380/6381.log</code> 查看 slave 日志</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807193701621.png" alt="image-20230807193701621"></p><center>master日志</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807193733743.png" alt="image-20230807193733743"></p><center>slave日志</center></li><li><p>通过命令： <code>info relication</code></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807193843707.png" alt="image-20230807193843707"></p><center>master的主从复制信息</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807193915854.png" alt="image-20230807193915854"></p><center>slave的主从复制信息</center></li></ol></li></ol><h5 id="主从复制问题演示"><a class="anchor" href="#主从复制问题演示">#</a> 主从复制问题演示</h5><ul><li><p>问题 1：<strong>slave 不能执行写命令！</strong></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807194936720.png" alt="image-20230807194936720"></p></li><li><p>问题 2：slave 切入点问题。当某台 slave shutdown 并重启后，<strong>slave 对 master 首次进行全量复制，然后进行增量复制</strong>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807194924560.png" alt="image-20230807194924560"></p></li><li><p>问题 3：master shutdown 后，slave 原地待命，数据仍可以正常使用，<strong>slave 等待 master 重启归来</strong>！</p></li><li><p>问题 4：shutdown 后的<strong> master 重启归来，主从关系还在！slave 还能顺利复制！</strong></p></li></ul><h5 id="方案2命令操作手动指定"><a class="anchor" href="#方案2命令操作手动指定">#</a> 方案 2：命令操作手动指定</h5><ol><li><p>slave 停机并去掉配置项，清空主从关系。此时 3 机都是 master，互不从属。</p></li><li><p>在预设的 2 个 slave 上执行命令 <code>SLAVEOF masterIp masterHost</code> 指定 master</p></li></ol><p>这种情况下，<strong><font color="red">若 slave shutdown 并重启，主从关系就不存在了（因为没有设置配置文件）！</font></strong></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807200155294.png" alt="image-20230807200155294"></p><h5 id="配置-vs-命令"><a class="anchor" href="#配置-vs-命令">#</a> 配置 vs 命令</h5><p><strong><font color="red">配置（即方案 1）持久稳定，命令（即方案 2）临时生效</font></strong>。</p><h4 id="薪火相传"><a class="anchor" href="#薪火相传">#</a> 薪火相传</h4><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807202217260.png" alt="image-20230807202217260"></p><p>要点：</p><ul><li>slave（6380）也可以作为其他 slave（6381）的 master，接收其连接和同步请求，可以<strong>有效减轻主 master（6379）的写压力</strong>。</li><li>改变 master 的命令： <code>SLAVEOF newMasterIp newMasterPort</code></li><li><strong><font color="red">slave（6380）仍然无法执行写命令！</font></strong></li><li>slave（6381）中途变更转向，master 从 6379 变为 6380，<strong><font color="red">会清除之前 master（6379）的数据，重新建立拷贝新的 master（6380）的数据</font></strong>。</li></ul><h4 id="自立为王"><a class="anchor" href="#自立为王">#</a> 自立为王</h4><blockquote><p>slave 转成 master</p></blockquote><p>命令 <code>SLAVEOF NO ONE</code> ：<strong><font color="red">停止与其他数据库的同步，清空数据，转成 Master 数据库</font></strong>。</p><h3 id="一主二从的案例演示"><a class="anchor" href="#一主二从的案例演示">#</a> 一主二从的案例演示</h3><h4 id="架构说明"><a class="anchor" href="#架构说明">#</a> 架构说明</h4><p>一主二从，一个 master，两个 slave，示意图如下：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807185141276.png" alt="image-20230807185141276"></p><p>拷贝多份配置文件，分别命名为：</p><ul><li>redis6379.conf</li><li>redis6380.conf</li><li>redis6381.conf</li></ul><h4 id="口诀"><a class="anchor" href="#口诀">#</a> <mark>口诀</mark></h4><p>前提：三边网络互相 ping 通，同时注意防火墙配置。</p><p>三大命令：</p><ul><li>主从复制： <code>REPLICAOF masterIp masterPort</code> ，配从不配主</li><li>改换门庭： <code>SLAVEOF masterIp masterPort</code></li><li>自立为王： <code>SLAVEOF NO ONE</code></li></ul><h4 id="修改配置文件的操作细节"><a class="anchor" href="#修改配置文件的操作细节">#</a> 修改配置文件的操作细节</h4><p>以 redis6379.conf 为例，步骤如下：</p><ol><li><p>要求 Redis 后台运行，不要弹出命令行窗口： <code>daemonize yes</code></p></li><li><p>取消 IP 的绑定，否则影响远程 IP 连接，注释掉 <code>bind 127.0.0.1</code></p></li><li><p>关闭保护模式，否则影响远程访问 / 连接： <code>protected-mode no</code></p></li><li><p>指定端口： <code>port 6379</code></p></li><li><p>指定当前工作目录， <code>dir /myredis</code></p></li><li><p>设置 pid（进程 id）文件的路径和名字： <code>pidfile /var/run/redis_6379.pid</code></p></li><li><p>设置 log 文件的路径和名字： <code>logfile &quot;/myredis/6379.log&quot;</code></p></li><li><p><font color="red">设置 Redis 服务器的密码</font>： <code>requirepass 111111</code></p><blockquote><p>master、slave 均配置</p></blockquote></li><li><p>设置 rdb 文件的名称： <code>dbfilename dump6379.rdb</code></p></li><li><p>若开启 AOF，还需设置 aof 文件的名字：appendfilename 。这里不开启了。</p></li><li><p><font color="red">slave 设置所访问的 master 的 IP 和端口： <code>replicaof masterIp 6379</code> ，并设置通行密码 <code>masterauth &quot;111111&quot;</code></font></p><blockquote><p>slave 需要配置</p></blockquote></li></ol><h3 id="原理工作流程"><a class="anchor" href="#原理工作流程">#</a> <mark>🌟原理（工作流程）</mark></h3><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/developer_1b16183.png" alt="developer_1b16183"></p><ol><li><p><strong><font color="#B32015">slave 首次连接，请求完全同步（sync）</font></strong>：slave <font color="red">首次连接</font> master 后会发送一个 <code>sync</code> 命令，<font color="red">请求完全同步（全量复制）</font></p><blockquote><p>执行一次完全同步（<font color="red">全量复制</font>），slave 自身原有数据会被<font color="red">覆盖清除</font></p></blockquote></li><li><p><strong><font color="#B32015">master 保存 RDB 快照，同时缓存写命令，响应给所有 slave 进行初始化（完全同步）</font></strong>：</p><ul><li>master 节点收到 <code>sync</code> 命令后会开始在后台<font color="red">保存快照</font>(即 RDB 持久化，主从复制时会触发 RDB)，同时<font color="red">缓存所有接收到的写命令</font>，master 节点执行 RDB 持久化完后，<font color="red">master 将 rdb 快照文件和所有缓存的写命令发送到所有 slave</font>，以完成一次完全同步</li><li>而 slave 服务在接收到数据库文件数据后，将其<font color="red">存盘并加载到内存中</font>，从而<font color="red">完成复制初始化</font></li></ul></li><li><p><strong><font color="#B32015">心跳持续，保持通信</font></strong>：master 向 slave 发出 PING 包，周期默认 10 秒。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807205137957.png" alt="image-20230807205137957"></p></li><li><p><strong><font color="#B32015">进入平稳，增量复制</font></strong>：master 继续将新的所有收集到的写命令自动依次传给 slave，完成同步</p></li><li><p><strong><font color="#B32015">slave 下线，重连续传</font></strong>：假设某台 slave 宕机并重启了，master 会检查 backlog 里面的 <code>offset</code> ，master 和 slave 都会保存一个复制的 <code>offset</code> 和一个 masterId， <code>offset</code> 是保存在 backlog 中的。<font color="red">master 只会把已经复制的  <code>offset</code> 后面的数据复制给 slave</font>，类似 **<font color="red">断点续传</font>**。</p></li></ol><h3 id="分级管理"><a class="anchor" href="#分级管理">#</a> 分级管理</h3><p>若 Redis 主从集群中的 Slave 较多时，它们的数据同步过程会对 Master 形成较大的性能压力。此时可以<font color="red">对这些 Slave 进行分级管理</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231210144213994.png" alt="image-20231210144213994"></p><p>设置方式很简单，只需要 **<font color="red">让低级别 Slave 指定其 slaveof 的主机为其上一级 Slave 即可</font>**。不过，上一级 Slave 的状态仍为 Slave，只不过，其是更上一级的 Slave。</p><p>例如，指定 6382 主机为 6381 主机的 Slave，而 6381 主机仍为真正的 Master 的 Slave。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231210144439772.png" alt="image-20231210144439772"></p><p>此时会发现， Master 的 Slave 只有 6381 一个主机。</p><h3 id="容灾冷处理"><a class="anchor" href="#容灾冷处理">#</a> 容灾冷处理</h3><p>在 Master/Slave 的 Redis 集群中，<font color="red">若 Master 出现宕机怎么办呢？</font>有两种处理方式：</p><ul><li><font color="red">冷处理</font>：手工角色调整，使 Slave 晋升为 Master</li><li><font color="red">热处理（哨兵模式）</font>：实现 Redis 集群的高可用 HA</li></ul><p>无论 Master 是否宕机，Slave 都可通过 slaveof no one 将自己由 Slave 晋升为 Master。如果其原本就有下一级的 Slave，那么，其就直接变为了这些 Slave 的真正的 Master 了。而原来的 Master 也会失去这个原来的 Slave。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231210144722685.png" alt="image-20231210144722685"></p><h3 id="缺点-5"><a class="anchor" href="#缺点-5">#</a> 缺点</h3><ul><li><p><strong><font color="red">复制（同步）延时</font></strong></p><blockquote><p>由于所有的写操作都是先在 Master 上操作，然后同步更新到 Slave 上，所以从 Master 同步到 Slave 机器有一定的延迟，当<font color="red">系统很繁忙</font>的时候，延迟问题会更加严重，<font color="red">Slave 机器数量的增加</font>也会使这个问题更加严重。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807210259342.png" alt="image-20230807210259342"></p></blockquote></li><li><p><strong><font color="red">Master 宕机后群龙无首</font></strong>！默认情况下，<font color="red">不会从 slave 中重选一个 master</font>，系统会陷入半瘫痪状态（<font color="red">只能读取，不能写入</font>）那客户端的写命令如何执行啊？</p><blockquote><p>期待有一种高可用的备份、恢复机制，能够从剩下的 slave 中选出一个 master！（<strong><font color="#B32015">无人值守安装：哨兵！</font></strong>）</p></blockquote></li></ul><h2 id="哨兵机制sentinel"><a class="anchor" href="#哨兵机制sentinel">#</a> 哨兵机制（sentinel）</h2><blockquote><p>目的：为了实现主从集群中的 **<font color="red">自动化的故障转移</font>**！</p></blockquote><p>普通的主从复制方案下，一旦 master 宕机，我们需要从 slave 中手动选择一个新的 master，同时需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。人工干预大大增加了问题的处理时间以及出错的可能性。</p><p>我们可以借助 Redis 官方的 Sentinel（哨兵）方案来帮助我们解决这个痛点，实现自动化的故障转移。</p><h3 id="是什么-9"><a class="anchor" href="#是什么-9">#</a> 是什么</h3><p>Redis Sentinel 实现 Redis 集群高可用，<font color="red">只是在主从复制实现集群的基础下，多了一个 Sentinel 角色来帮助我们监控 Redis 节点的运行状态，并自动实现故障转移</font>。</p><p><strong><font color="red">当 master 节点出现故障的时候，Sentinel 会自动根据一定的规则选出一个 slave 升级为 master，从而实现自动化的故障转移，确保整个 Redis 系统的高可用性（HA）</font></strong>。整个过程完全自动，不需要人工介入。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-master-slave-sentinel.png" alt="redis-master-slave-sentinel.png"></p><h3 id="作用-2"><a class="anchor" href="#作用-2">#</a> 作用</h3><p>Sentinel 节点的功能如下：</p><ul><li><strong><font color="red">监控</font></strong>：Sentinel 可以监控所有 Redis 节点（包括 Sentinel 节点自身）的<font color="red">状态是否正常</font>。</li><li><strong><font color="red">故障转移</font></strong>：如果一个 master 出现故障，Sentinel 会帮助我们实现故障转移，<font color="red">自动将某一台 slave 升级为 master</font>，确保整个 Redis 系统的可用性。</li><li><strong><font color="red">消息通知</font></strong>：<font color="red">通知 slave 新的 master 连接信息</font>，让它们执行 replicaof 成为新的 master 的 slave。</li><li><strong><font color="red">配置中心</font></strong>：<font color="red">客户端通过连接 sentinel 来获得 master 的地址</font>，如果发生故障转移，sentinel 会通知新的 master 链接信息给客户端。</li></ul><p>Sentinel 本身设计的就是一个分布式系统，<font color="red">建议多个 sentinel 节点协作运行</font>，好处是：</p><ul><li>多个 sentinel 节点通过<font color="red">投票</font>的方式来确定 master 节点是否真的不可用，<font color="red">避免误判</font>（比如网络问题可能会导致误判）。</li><li>Sentinel 自身就是<font color="red">高可用</font>。</li></ul><h3 id="sentinel-配置文件sentinelconf"><a class="anchor" href="#sentinel-配置文件sentinelconf">#</a> Sentinel 配置文件（sentinel.conf）</h3><blockquote><p>默认在 /opt/redis-7.0.0 目录下</p></blockquote><p>Sentinel（哨兵）只是 Redis 的一种运行模式，不提供读写服务，默认运行在 <font color="red">26379</font> 端口上，依赖于 Redis 工作。</p><p>Redis 在 Sentinel 这种特殊的运行模式下，使用专门的命令表，也就是说普通模式运行下的 Redis 命令将无法使用。</p><p>通过下面的命令就可以<font color="red">让 Redis 以 Sentinel 的方式运行</font>:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>redis-sentinel /path/to/sentinel.conf</pre></td></tr><tr><td data-num="2"></td><td><pre>或者</pre></td></tr><tr><td data-num="3"></td><td><pre>redis-server /path/to/sentinel.conf <span class="token parameter variable">--sentinel</span></pre></td></tr></table></figure><p>Redis 源码中的<font color="red"> <code>sentinel.conf</code> 文件是用来配置 Sentinel 的</font>，一个常见的最小配置如下所示：</p><figure class="highlight java"><figcaption data-lang="java"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">// 指定要监视的 master</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment">// 127.0.0.1 6379 为 master 地址</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">// 2 表示当有 2 个 sentinel 认为 master 失效时，master 才算真正失效</span></pre></td></tr><tr><td data-num="4"></td><td><pre>sentinel monitor mymaster <span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span> <span class="token number">6379</span> <span class="token number">2</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment">//master 节点宕机多长时间才会被 sentinel 认为是失效</span></pre></td></tr><tr><td data-num="6"></td><td><pre>sentinel down<span class="token operator">-</span>after<span class="token operator">-</span>milliseconds mymaster <span class="token number">60000</span></pre></td></tr><tr><td data-num="7"></td><td><pre>sentinel failover<span class="token operator">-</span>timeout mymaster <span class="token number">180000</span></pre></td></tr><tr><td data-num="8"></td><td><pre>sentinel parallel<span class="token operator">-</span>syncs mymaster <span class="token number">1</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>sentinel monitor resque <span class="token number">192.168</span><span class="token number">.1</span><span class="token number">.3</span> <span class="token number">6380</span> <span class="token number">4</span></pre></td></tr><tr><td data-num="11"></td><td><pre>sentinel down<span class="token operator">-</span>after<span class="token operator">-</span>milliseconds resque <span class="token number">10000</span></pre></td></tr><tr><td data-num="12"></td><td><pre>sentinel failover<span class="token operator">-</span>timeout resque <span class="token number">180000</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token comment">// 在发生主备切换时最多可以有 5 个 slave 同时对新的 master 进行同步</span></pre></td></tr><tr><td data-num="14"></td><td><pre>sentinel parallel<span class="token operator">-</span>syncs resque <span class="token number">5</span></pre></td></tr></table></figure><p>重点参数说明：</p><ul><li><p><code>bind</code> ：服务监听地址，用于客户端连接，默认为本机地址</p></li><li><p><code>daemonize</code> ：是否以后台 daemon（后台进程）方式运行，设为 yes</p></li><li><p><code>protected-mode</code> ：是否开启安全保护模式，设为 no，否则影响远程访问 / 连接</p></li><li><p><code>port</code> ：端口，默认是 26379</p></li><li><p><code>logfile</code> ：日志文件路径</p></li><li><p><code>pidfile</code> ：pid 文件路径</p></li><li><p><code>dir</code> ：工作目录</p></li><li><p><strong><code>sentinel monitor &lt;master-name&gt; &lt;master-ip&gt; &lt;master-port&gt; &lt;quorum&gt;</code> </strong>：<font color="red">设置 Sentinel 要监控的 master</font></p><ul><li><p><code>quorum</code> ：<strong><font color="red">判定 master 失效（<font color="cornflowerblue">客观下线</font>）最少需要的仲裁 Sentinel 节点数</font></strong>，即同意故障转移的法定<font color="red">投票数</font>。例如 quorum 为 2 表示当有 2 个 sentinel 认为 master 失效时，master 才算真正失效。</p><blockquote><p><strong>sentinel 定时向 master 发出 PING 包</strong>来确认 master 是否挂掉。</p><p>但网络是不可靠的，有时某个 sentinel 可能因为<strong>网络拥堵</strong>没收到 master 的响应，从而<strong>误以为 master 已挂掉</strong>。因此需要多个 sentinel 都一致认为 master 已挂，才可进行主从切换、故障转移，保证了公平性和高可用。</p></blockquote></li></ul></li><li><p><code>sentinel auth-pass &lt;master-name&gt; &lt;password&gt;</code> ：设置连接 master 服务器的密码</p></li><li><p><strong><code>sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;</code> </strong>：指定如果 master 在多少毫秒之后没有应答 sentinel，sentinel 则主观上认为 master 下线（<strong><font color="cornflowerblue">主观下线</font></strong>）</p></li><li><p><code>sentinel parallel-syncs &lt;master-name&gt; &lt;nums&gt;</code> ：表示允许并行同步的 slave 个数，当 master 挂了后，哨兵会选出新的 master，此时，剩余的 slave 会向新的 master 发起同步数据</p></li><li><p><code>sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt;</code> ：故障转移的超时时间。进行故障转移时，如果超过设置的毫秒，表示故障转移失败</p></li><li><p><code>sentinel notification-script &lt;master-name&gt; &lt;script-path&gt;</code> ：配置当某一事件发生时所需要执行的脚本</p></li><li><p><code>sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;</code> ：客户端重新配置 master 参数脚本</p></li></ul><h3 id="案例演示"><a class="anchor" href="#案例演示">#</a> 案例演示</h3><h4 id="架构说明-2"><a class="anchor" href="#架构说明-2">#</a> 架构说明</h4><p>**<font color="red">如果想要实现高可用，建议将哨兵 Sentinel 配置成单数，且大于等于 3 台。</font>** 好处有二：</p><ul><li>防止某台 sentinel 无法连接到 master，导致误切换</li><li>利于投票选举</li></ul><p>一个最简易的 Redis Sentinel 集群如下所示（官方文档中的一个例子），其中：</p><ul><li>3 个 Sentinel 节点</li><li>1 个 Master 节点，2 个 Slave 节点</li></ul><p>如果 Master 出现问题，只要 Sentinel 集群其中的两个投票赞同的话，就会开始故障转移工作，从 2 个 Slave 中重新选出一个作为 master。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808002037403.png" alt="image-20230808002037403"></p><h4 id="配置说明"><a class="anchor" href="#配置说明">#</a> 配置说明</h4><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808105627695.png" alt="image-20230808105627695"></p><p>由于机器硬件关系，我们的 3 个哨兵都同时配置进 192.168.111.169 同一台机器，即<font color="red">3 个哨兵和 master 在一台机器上</font>。</p><p>配置这 3 个哨兵的配置文件：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808104641977.png" alt="image-20230808104641977"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808104655030.png" alt="image-20230808104655030"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808104707250.png" alt="image-20230808104707250"></p><p>master 配置文件说明：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808104812771.png" alt="image-20230808104812771"></p><h4 id="先测试正常的主从复制"><a class="anchor" href="#先测试正常的主从复制">#</a> 先测试正常的主从复制</h4><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230807201752116.png" alt="image-20230807201752116"></p><ol><li>169 机器上新建 redis6379.conf 配置文件，由于 6379 后续可能会变成从机，需要设置访问新主机的密码，请设置 masterauth 项访问密码为 111111，不然后续可能报错 master_link_status:down</li><li>172 机器上新建 redis6380.conf 配置文件，设置好 <code>replicaof \&lt;masterip&gt; \&lt;masterport&gt;</code> ，以及 masterauth 项访问密码为 111111</li><li>173 机器上新建 redis6381.conf 配置文件，设置好 <code>replicaof \&lt;masterip&gt; \&lt;masterport&gt;</code> ，以及 masterauth 项访问密码为 111111</li><li>启动 3 台机器实例：<ol><li><code>redis-cli -a 111111 -p 6379</code></li><li><code>redis-cli -a 111111 -p 6380</code></li><li><code>redis-cli -a 111111 -p 6381</code></li></ol></li><li>测试</li></ol><h4 id="sentinel-来了"><a class="anchor" href="#sentinel-来了">#</a> Sentinel 来了！</h4><blockquote><p>sentinel 之间通过 master 来获取：</p><ul><li>slave 信息</li><li>其他 sentinel 信息</li></ul><p>从而实现通信。</p></blockquote><ol><li><p>在 master（6379）这台机器上<font color="red">启动 3 个 sentinel</font>（26379/26380/26381），完成监控</p><ol><li><code>redis-sentinel sentinel26379.conf --sentinel</code></li><li><code>redis-sentinel sentinel26380.conf --sentinel</code></li><li><code>redis-sentinel sentinel26381.conf --sentinel</code></li></ol><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808110202022.png" alt="image-20230808110202022"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808110255818.png" alt="image-20230808110255818"></p></li><li><p>查看哨兵的日志文件 <code>sentinel26379.log</code> ，可以看到<font color="red">当前 sentinel 的信息</font>、<font color="red">所监控 master 以及 slave 的信息</font>、<font color="red">其他 sentinel 的信息</font>：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808111127304.png" alt="image-20230808111127304"></p></li><li><p>再测试一次主从复制，木有问题</p></li></ol><h4 id="当-master-挂了"><a class="anchor" href="#当-master-挂了">#</a> 当 master 挂了！</h4><p>通过命令 <code>SHUTDOWN</code> 手动关闭 6379 服务器，模拟 master 挂掉。</p><p>思考以下问题：</p><ul><li><p>问题 1：<font color="red">两台 slave 上的数据还 OK！</font></p></li><li><p>问题 2：** 会从这两台 slave 上选出新的 master！** 具体信息可查看 sentinel 的 log 文件。</p><blockquote><p>在此过程中，哨兵配置文件 <code>sentinel.conf</code> 中会自动生成内容信息</p></blockquote></li><li><p>问题 3：<strong>down 机的旧 master 重启归来，也只能拜认新 master，作它的 slave！</strong></p></li></ul><p>在 master6379 宕机后，会出现两种错误：</p><ul><li><p>Error：Server closed the connection</p></li><li><p>Error：Broken pipe</p><blockquote><p><strong>broken pipe</strong>：pipe 是管道的意思，管道里面是数据流，通常是从文件或网络套接字读取的数据。<font color="red">当该管道从另一端突然关闭时，会发生数据突然中断</font>，即是 broken，对于 socket 来说，可能是网络被拔出或另一端的进程崩溃。</p><p><strong>如何解决</strong>：当该异常产生的时候，<font color="red">对于服务端来说，并没有多少影响</font>。因为可能是某个客户端突然中止了进程导致了该错误。</p><p><strong>总结</strong>：这个异常是<font color="red">客户端读取超时</font>关闭了连接，这时候服务器端再向客户端已经断开的连接写数据时就发生了 broken pipe 异常！</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808113740061.png" alt="image-20230808113740061"></p></blockquote></li></ul><p>针对本次案例，分析谁是 master：</p><ol><li>6381 被选为新 master，上位成功</li><li>以前的 6379 从 master 降级变成了 slave</li><li>6380 还是 slave，只不过换了个新老大 6381 (6379 变 6381)，6380 还是 slave</li></ol><h4 id="对比新老master的配置文件"><a class="anchor" href="#对比新老master的配置文件">#</a> 对比新老 master 的配置文件</h4><p>旧 master（6379）的配置文件 <code>redis6379.conf</code> 中会自动生成以下内容，让 其去做新 master（6381）的 slave：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808115231877.png" alt="image-20230808115231877"></p><p>新 master（6381）的配置文件 <code>redis6381.conf</code> 中：</p><ul><li>自动删掉 <code>replicaof</code> 参数的配置</li><li>自动生成以下内容：</li></ul><p>结论：</p><ul><li>conf 文件的内容会被 sentinel 动态更改</li><li>Master-Slave 切换后，master_redis.conf、slave_redis.conf 和 sentinel.conf 的内容都会发生改变，即<font color="red">master_redis.conf 中会多一行 slaveof 的配置</font>，<font color="red">sentinel.conf 的监控目标会随之调换</font></li></ul><h4 id="其他备注"><a class="anchor" href="#其他备注">#</a> 其他备注</h4><ul><li>生产都是不同机房不同服务器，<strong>很少出现 Sentinel 全挂掉的情况</strong></li><li><strong>可以同时监控多个 master</strong>，一行一个</li></ul><h3 id="sentinel-原理"><a class="anchor" href="#sentinel-原理">#</a> <mark>🌟Sentinel 原理</mark></h3><h4 id="三个定时任务"><a class="anchor" href="#三个定时任务">#</a> 三个定时任务</h4><p>Sentinel 维护着三个定时任务以监测 Redis 节点及其它 Sentinel 节点的状态：</p><ul><li><p><font color="cornflowerblue">info 任务</font>：每个 Sentinel 每隔 10 秒就会向 Redis 集群中的每个节点发送 <code>info</code> 命令，以<font color="red">获得最新的 Redis 拓扑结构</font>。</p></li><li><p><font color="cornflowerblue">ping 任务</font>：每个 Sentinel 每隔 1 秒就会向所有 Redis 节点及其它 Sentinel 节点发送一条 <code>ping</code> 命令，以<font color="red">检测这些节点的存活状态</font>。该任务<font color="red">是判断节点在线状态的重要依据</font>。</p></li><li><p><font color="cornflowerblue">pub/sub 任务</font>：</p><p>​	每个 Sentinel 节点在启动时都会<font color="red">向所有 Redis 节点订阅  <code>__sentinel__:hello</code> 主题的信息</font>，当 Redis 节点中该主题的信息发生了变化，就会立即通知到所有订阅者。</p><p>​	启动后，每个 Sentinel 节点每 2 秒就会向每个 Redis 节点发布一条 <code>__sentinel__:hello</code> 主题的信息，该信息是<font color="red">当前 Sentinel 对每个 Redis 节点在线状态的判断结果及当前 Sentinel 节点信息</font>。</p><p>​	当 Sentinel 节点接收到 <code>__sentinel__:hello</code> 主题信息后，就会读取并解析这些信息，然后主要完成以下三项工作：</p><ul><li>如果发现<font color="red">有新的 Sentinel 节点加入</font>，则记录下新加入 Sentinel 节点信息，并与其建立连接。</li><li>如果发现<font color="red">有 Sentinel Leader 选举的选票信息</font>，则执行 Leader 选举过程。</li><li><font color="red">汇总其它 Sentinel 节点对当前 Redis 节点在线状态的判断结果</font>，作为 Redis 节点客观下线的判断依据。</li></ul></li></ul><h4 id="redis-节点下线down判断"><a class="anchor" href="#redis-节点下线down判断">#</a> Redis 节点下线（DOWN）判断</h4><p>对于每个 Redis 节点在线状态的监控是由 Sentinel 完成的。</p><h5 id="主观下线subjectively-down"><a class="anchor" href="#主观下线subjectively-down">#</a> 主观下线（Subjectively DOWN）</h5><p>每个 Sentinel 节点每秒就会向每个 Redis 节点发送 <code>ping</code> 心跳检测，如果 Sentinel 在 [down-after-milliseconds] 时间内<font color="red">没有收到某 Redis 节点的回复</font>，则 Sentinel 节点就会对该 Redis 节点做出 “下线状态” 的判断。这个判断 **<font color="red">仅仅是当前 Sentinel 节点的 “一家之言”</font>**，所以称为主观下线。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-master-slave-sentinel-ping-sdown.png" alt="redis-master-slave-sentinel-ping-sdown.png"></p><h5 id="客观下线objectively-down"><a class="anchor" href="#客观下线objectively-down">#</a> 客观下线（Objectively DOWN）</h5><p>当 Sentinel 主观下线的节点是 master 时，该 Sentinel 节点会向每个其它 Sentinel 节点发送 <code>sentinel is-master-down-by-addr</code> 命令，以询问其对 master 在线状态的判断结果。这些 Sentinel 节点在收到命令后会向这个发问 Sentinel 节点响应 0（在线）或 1（下线）。<strong><font color="red">当 Sentinel 收到超过 quorum 个（通常为过半）下线判断后，就会对 master 做出客观下线判断</font></strong>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-master-slave-sentinel-ping-odown.png" alt="redis-master-slave-sentinel-ping-odown.png"></p><h4 id="sentinel-leader-选举raft-算法"><a class="anchor" href="#sentinel-leader-选举raft-算法">#</a> Sentinel Leader 选举（Raft 算法）</h4><p><font color="red">当 Sentinel 节点对 master 做出客观下线判断后，<strong>由 Sentinel Leader 来完成后续的故障转移</strong></font>。即 Sentinel 集群中的节点也并非是对等节点，是存在 Leader 与 Follower 的。</p><p>Sentinel Leader 的选举是通过 <strong><font color="orange">Raft 算法</font></strong> 实现的。Raft 算法比较复杂，后面会详细学习，这里仅简单介绍一下 **<font color="red">大致思路（先到先得）</font>**：</p><ol><li>每个 Sentinel 选举参与者都具有当选 Leader 的资格，当其完成了 “客观下线” 判断后，就会立即 <font color="red">“毛遂自荐”</font> 推选自己做 Leader，将自己的提案发送给所有 Sentinel 参与者。</li><li>其它参与者在收到提案后，<font color="red">只要自己手中的选票没有投出去，其就会立即通过该提案</font>，并将同意结果反馈给提案者。</li><li>后续再过来的提案会由于该参与者没有了选票而被拒绝。</li><li>当提案者收到了同意反馈数量大于等于 max (quorum， sentinelNum/2+1) 时，该提案者当选 Leader。</li></ol><p>说明：</p><ul><li>在网络没有问题的前提下，基本就是谁先做出了 “客观下线” 判断，谁就会首先发起 Sentinel Leader 的选举，谁就会得到大多数参与者的支持，谁就会当选 Leader。</li><li><font color="red">Sentinel Leader 选举在故障转移发生之前进行</font>。</li><li><font color="red">故障转移结束后 Sentinel 不再维护这种 Leader-Follower 关系</font>。</li></ul><h4 id="master-选举"><a class="anchor" href="#master-选举">#</a> Master 选举</h4><p>在进行故障转移时，Sentinel Leader 需要从所有 Redis 的 Slave 节点中选择出新的 Master。其选择算法为：</p><ol><li><p>过滤掉所有主观下线的，或心跳没有响应 Sentinel 的，或 replica-priority 值为 0 的 Redis 节点</p></li><li><p><strong>slave 优先级</strong>：在剩余 Redis 节点中选择出 <font color="red"><code>replica-priority</code> 最小</font>的的节点列表。如果只有一个节点，则直接返回，否则，继续</p></li><li><p><strong>复制进度</strong>：从优先级相同的节点列表中选择<font color="red">复制偏移量最大</font>的节点。如果只有一个节点，则直接返回，否则，继续</p></li><li><p><strong>runid（运行 id）</strong>：从复制偏移值量相同的节点列表中选择<font color="red">runid 最小</font>的节点返回</p></li></ol><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808165640759.png" alt="image-20230808165640759"></p><h4 id="故障转移failover流程"><a class="anchor" href="#故障转移failover流程">#</a> 故障转移（failover）流程</h4><ol><li><p><strong>集群正常运行</strong>：3 个 sentinel 监控一主二从集群，正常运行中</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808161905591.png" alt="image-20230808161905591"></p></li><li><p><strong><font color="cornflowerblue">SDown 主观下线（Subjectively Down）</font></strong>：指的是<font color="red">单个 Sentinel 实例</font>对 master 服务器做出的下线判断（有可能是接收不到订阅，之间的网络不通等等原因）。如果 master 服务器在 [ <code>sentinel down-after-milliseconds</code> ] 给定的毫秒数之内没有回应 PING 命令，或者返回一个错误消息，那么这个 Sentinel 会主观的 (<font color="red">单方面的</font>) 认为这个 master 不可以用了。</p><blockquote><p>sentinel 配置文件中的 <code>sentinel down-after-milliseconds &lt;masterName&gt; &lt;timeout&gt;</code> 设置了判断主观下线的时间长度，表示 master 被当前 sentinel 实例认定为失效的间隔时间。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808162539926.png" alt="image-20230808162539926"></p></blockquote></li><li><p><strong><font color="cornflowerblue">ODown 客观下线（Objectively Down）</font></strong>：需要一定数量的 sentinel，<font color="red">多个 sentinel 达成一致意见</font>才能认为一个 master 客观上已经宕掉。</p><blockquote><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808162827271.png" alt="image-20230808162827271"></p><ul><li><code>master-name</code> 是对某个 master+slave 组合的一个区分标识 (一套 sentinel 可以监听多组 master+slave 这样的组合)</li><li><strong><code>quorum</code> 这个参数是进行客观下线的一个依据</strong>，即法定人数 / 法定票数。意思是至少有 quorum 个 sentinel 认为这个 master 有故障才会对这个 master 进行下线以及故障转移。因为有的时候，某个 sentinel 节点可能因为自身网络原因导致无法连接 master，而此时 master 并没有出现故障，所以这就需要多个 sentinel 都一致认为该 master 有问题，才可以进行下一步操作，这就保证了公平性和高可用。</li></ul></blockquote></li><li><p><strong>Sentinel Leader 选举</strong>：从 sentinel 集群中选出 <strong><font color="#B32015">Sentinel Leader（兵王）</font></strong>：当 master 被判断 ODown 以后，各个 sentinel 节点会进行协商，先通过<font color="orange">Raft 算法</font>选举出一个 Sentinel Leader，<font color="red">由它进行 failover (故障迁移)</font>。</p><blockquote><p>监视该 Master 的所有 Sentinel 都有可能被选为 Leader，选举使用的算法是 Raft 算法，其基本思路是 **<font color="red">先到先得</font>**：即在一轮选举中，Sentinel A 向 Sentinel B 发送成为 Leader 的申请，如果 Sentinel B 没有同意过其他 Sentinel，则它会同意 Sentinel A 成为 Leader</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808164314705.png" alt="image-20230808164314705"></p></blockquote><p>从三个 sentinel 实例的 log 文件中可以看见兵王的诞生过程以及兵王执行故障迁移的过程：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808163922904.png" alt="image-20230808163922904"></p><center>sentinel26379.log</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808163958440.png" alt="image-20230808163958440"></p><center><font color="red">sentinel26380.log</font></center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808164037410.png" alt="image-20230808164037410"></p><center>sentinel26381.log</center></li><li><p><strong><font color="orange">故障转移，选举新的 master</font></strong>：</p><ol><li><p><strong>新主登基</strong>：**<font color="orange">新 master 选举算法</font>** 如下：</p><ol><li><p><font color="gree">优先级高</font>：所有 slave 中，根据 redis.conf 配置文件中的优先级 <code>slave-priority</code> 或者 <code>replica-priority</code> ，选择优先级最高的 slave 作为新 master。</p><blockquote><p>数字越小优先级越高</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808170206385.png" alt="image-20230808170206385"></p></blockquote></li><li><p><font color="gree">复制偏移大</font>：所有 slave 中，根据复制偏移位置 <code>offset</code> ，该值最大的 slave 作为新 master。</p></li><li><p><font color="gree">Run ID 小</font>：所有 slave 中，选择 Run ID 最小的 slave 作为新 master，是按照字典顺序，ASCII 码。</p></li></ol><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230808165640759.png" alt="image-20230808165640759"></p></li><li><p><strong>群臣俯首</strong>：一朝天子一朝臣，换个码头重新拜</p><ol><li>Sentinel leader 会对选举出的 slave 执行 <code>SLAVEOF NO ONE</code> 命令，将其提拔为新 master</li><li>Sentinel leader 向其余 slave 发送 <code>SLAVEOF</code> 命令，使它们成为新 master 的 slave</li></ol></li><li><p><strong>旧主拜服</strong>：老 master 回来也认怂</p><ol><li>老 master 成为新 master 的 slave</li><li>Sentinel leader 会让老 master 降级为 slave，并恢复正常工作</li></ol></li></ol><p>总结：上述 failover（故障迁移）均由 sentinel 独自完成，无需人工干预，因此称之为<strong>无人值守安装</strong>！</p></li></ol><h4 id="redis-节点上线"><a class="anchor" href="#redis-节点上线">#</a> Redis 节点上线</h4><p>不同的节点类型，其上线的方式也是不同的。</p><h5 id="原节点上线"><a class="anchor" href="#原节点上线">#</a> 原节点上线</h5><p>无论是原下线的 master 节点还是原下线的 slave 节点，只要是原 Redis 集群中的节点上线，<font color="red">只需启动 Redis 即可</font>。因为每个 Sentinel 中都保存有原来其监控的所有 Redis 节点列表，Sentinel 会定时查看这些 Redis 节点是否恢复。<font color="red">如果 Sentinel 查看到其已经恢复，则会命其从当前 master 进行数据同步</font>。</p><p>不过，<font color="red">如果是原 master 上线，在新 master 晋升后 Sentinel Leader 会立即先将原 master 节点更新为 slave，然后才会定时查看其是否恢复</font>。</p><h5 id="新节点上线"><a class="anchor" href="#新节点上线">#</a> 新节点上线</h5><p>如果需要在 Redis 集群中添加一个新的节点，其未曾出现在 Redis 集群中，则上线操作<font color="red">只能手工完成</font>。即添加者在添加之前必须知道当前 master 是谁，然后在新节点启动后<font color="red">运行 <code>slaveof</code> 命令加入集群</font>。</p><h5 id="sentinel-节点上线"><a class="anchor" href="#sentinel-节点上线">#</a> Sentinel 节点上线</h5><p>如果要添加的是 Sentinel 节点，无论其是否曾经出现在 Sentinel 集群中，都需要<font color="red">手工完成</font>。即添加者在添加之前必须知道当前 master 是谁，然后在配置文件中修改 sentinel monitor 属性，<font color="red">指定要监控的 master，然后启动 Sentinel 即可</font>。</p><h3 id="sentinel-使用建议"><a class="anchor" href="#sentinel-使用建议">#</a> Sentinel 使用建议</h3><ol><li><p><strong><font color="red">哨兵的数量应为多个，且奇数</font></strong>。哨兵本身应该集群，保证高可用。</p></li><li><p><strong><font color="red">各个哨兵的配置应一致</font></strong>。</p></li><li><p>如果哨兵部署在 Docker 等容器里面，尤其要<font color="red">注意端口的正确映射</font>。</p></li><li><p><code>主从复制 + 哨兵</code> 机制 **<font color="#B32015">并不能确保数据零丢失</font>**。因为从 master 挂掉到选举出新 master 的这段时间内，无法执行写命令！</p><blockquote><p>引出<strong>集群（cluster）</strong></p></blockquote></li></ol><h2 id="分布式系统切片集群cluster"><a class="anchor" href="#分布式系统切片集群cluster">#</a> 分布式系统 / 切片集群（cluster）</h2><blockquote><p>作为 Redis 实现高可用的一种方案，优于 <code>主从复制 + Sentinel</code> 方案！</p></blockquote><p>Redis 分布式系统，官方称为 Redis Cluster， Redis 集群，其是 Redis 3.0 开始推出的分布式解决方案。其可以<font color="red">很好地解决不同 Redis 节点存放不同数据，并将用户请求方便地路由到不同 Redis 的问题</font>。</p><h3 id="已经有主从复制-sentinel了为什么还需要-redis-cluster"><a class="anchor" href="#已经有主从复制-sentinel了为什么还需要-redis-cluster">#</a> 已经有主从复制、Sentinel 了，为什么还需要 Redis Cluster？</h3><p>主从复制和 Redis Sentinel 这两种方案本质都是通过增加主库（master）的副本（slave）数量的方式来提高 Redis 服务的整体可用性和读吞吐量，<font color="red">都不支持横向扩展来缓解写压力，以及解决缓存数据量过大的问题</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/f682fc80-930c-4e35-978b-496b856d790b.png" alt="img"></p><p>通常情况下，更建议使用 **<font color="#B32015">Redis 切片集群（cluster）</font>** 这种方案，更能满足高并发场景下分布式缓存的要求。</p><h3 id="是什么-10"><a class="anchor" href="#是什么-10">#</a> 是什么</h3><p>简单来说就是 **<font color="red">部署多台 master，它们之间平等，每个 master 只存储整个数据库的一部分数据，同时对外提供读 / 写服务，实现负载均衡</font>**。<font color="red">缓存的数据库相对均匀地分布在这些 Redis 实例上，客户端的请求通过 <code>路由规则</code> 转发到目标 master 上</font>。</p><p>为了保障集群整体的高可用，我们需要保证集群中每一个 master 的高可用，<font color="red">可以通过主从复制给每个 master 配置一个或者多个从节点（slave）</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/bd28bbbd-0ed4-46e6-ba94-aba9c730934d.png" alt="img"></p><p><font color="red">Redis 切片集群对于横向扩展非常友好，只需要增加 Redis 节点到集群中即可</font>。</p><h3 id="作用-3"><a class="anchor" href="#作用-3">#</a> 作用</h3><p>Redis Cluster 的功能总结如下：</p><ul><li><strong><font color="#B32015">支持多个 Master</font></strong>，每个 Master 又可以挂载多个 Slave。<ul><li>读写分离</li><li>支持数据的高可用</li><li>支持海量数据的读写存储操作</li></ul></li><li><strong><font color="#B32015">自带故障转移（failover）机制</font></strong>，内置了高可用的支持，<font color="red">无需再去使用哨兵功能</font>。</li><li><strong>客户端只需连接集群中的任意一个可用 Master 节点即可</strong>，不需要连接集群中的所有 Master 节点。</li><li><strong><font color="#B32015">槽位 slot</font><strong>负责分配到各个物理服务节点，由对应的集群来负责</strong>维护 Redis 节点、插槽、数据之间的关系</strong>。</li></ul><p>Redis Cluster 通过 <strong><font color="#B32015">分片（Sharding）</font></strong> 来进行数据管理，提供 <strong><font color="red">主从复制（Master-Slave Replication）</font></strong>、<strong><font color="red">故障转移（Failover）</font></strong> 等开箱即用的功能，可以非常方便地帮助我们解决 Redis 大数据量缓存以及 Redis 服务高可用的问题。</p><p>Redis Cluster 这种方案可以很方便地进行 <strong><font color="red">横向拓展（Scale Out）</font></strong>，内置了开箱即用的解决方案。当 Redis Cluster 的处理能力达到瓶颈无法满足系统要求的时候，<font color="red">直接动态添加 Redis 节点到集群中即可</font>。根据官方文档中的介绍，Redis Cluster 支持扩展到 1000 个节点。反之，当 Redis Cluster 的处理能力远远满足系统要求，<font color="red">同样可以动态删除集群中 Redis 节点，节省资源</font>。</p><p><img data-src="D:%5C%E5%90%84%E4%B8%AA%E7%A7%91%E7%9B%AE%5CJava%5CJavaGuide%5C%E9%9D%A2%E8%AF%95%E6%8C%87%E5%8C%97%5C%E9%9D%A2%E8%AF%95%E6%8C%87%E5%8C%97.assets%5Cbef6547a-7325-4cdc-8fa5-b3db66826be2.png" alt="img"></p><p>可以说，<strong><font color="red">Redis Cluster 的动态扩容和缩容是其最大的优势</font></strong>。</p><h3 id="最基本架构"><a class="anchor" href="#最基本架构">#</a> 最基本架构</h3><p>为了保证高可用，Redis Cluster <font color="red">至少需要 3 个 master 以及 3 个 slave</font>，也就是说每个 master 必须至少有 1 个 slave。master 和 slave 之间做<font color="red">主从复制</font>，slave 会实时同步 master 上的数据。</p><p>不同于普通的 Redis 主从架构，<strong><font color="red">这里的 slave 不对外提供读服务，主要用来保障 master 的高可用，当 master 出现故障的时候替代它</font></strong>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/7fefb5f3-1978-432b-9a6b-3e1608d033df.png" alt="img"></p><p>如果 master 只有一个 slave 的话，master 宕机之后就直接使用这个 slave 替代 master 继续提供服务，保证 Redis Cluster 的高可用。</p><p>如果 master 有多个 slave 的话，Redis Cluster 中的其他节点会从这个 master 的所有 slave 中选出一个替代 master 继续提供服务。Redis Cluster 总是希望<font color="red">数据最完整的</font> slave 被提升为新的 master。</p><p>Redis Cluster 是<font color="red">去中心化</font>的（各个节点基于 <code>Gossip</code> 进行通信），任何一个 master 出现故障，其它的 master 节点不受影响，因为 key 找的是 **<font color="red">哈希槽（hash slot）</font>** 而不是 Redis 节点。不过，Redis Cluster 至少要保证宕机的 master 有一个 slave 可用。</p><p><font color="red">如果宕机的 master 无 slave 的话，为了保障集群的完整性，保证所有的哈希槽都指派给了可用的 master，整个集群将不可用</font>。这种情况下，还是想让集群保持可用的话，可以将 <code>cluster-require-full-coverage</code> 这个参数设置成 no，该参数表示需要 16384 个 slot 都正常被分配时 Redis Cluster 才可以对外提供服务。</p><p><font color="red">如果想要添加新的 master 节点，只需要重新分配 hash slot 即可</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/d6eb12c9-d6a9-4f7b-b0b7-158b0d735042.png" alt="img"></p><p><font color="red">如果想要移除某个 master 节点，需要先将该节点的 hash slot 移动到其他节点上，这样才可以进行删除，不然会报错</font>。</p><h3 id="数据分片算法"><a class="anchor" href="#数据分片算法">#</a> <mark>🌟数据分片算法</mark></h3><blockquote><p>类似的问题：</p><ul><li><p>Redis Cluster 是如何分片的？</p></li><li><p>Redis Cluster 中的数据是如何分布的？</p></li><li><p>如何确定给定 key 应该分布到哪个哈希槽中？</p></li></ul></blockquote><p>常见的数据分区规则有两大类：</p><ul><li><p><font color="cornflowerblue">顺序分区</font>：将数据<font color="red">按照某种顺序平均分配</font>到不同的节点。不同的顺序方式，产生了不同的分区算法。</p><ul><li>轮询：每产生一个数据，就依次分配到不同的节点。其分配的结果是，在数据总量非常庞大的情况下，每个节点中数据是很平均的。但生产者与数据节点间的连接要长时间保持。</li><li>时间片轮转：在某固定长度的时间片内的数据都会分配到同一个节点。时间片结束，再产生的数据就会被分配到下一个节点。可能会出现节点数据不平均的情况（因为每个时间片内产生的数据量可能是不同的）。但生产者与节点间的连接只需占用当前正在使用的这个就可以，其它连接使用完毕后就立即释放。</li><li>数据块：在整体数据总量确定的情况下，根据各个节点的存储能力，可以将连接的某一整块数据分配到某一节点。</li><li>业务主题：数据可根据不同的业务主题，分配到不同的节点。</li></ul></li><li><p><font color="cornflowerblue">哈希分区</font>：充分<font color="red">利用数据的哈希值来完成分配</font>，对数据哈希值的不同使用方式产生了不同的哈希分区算法。</p><ul><li><p>哈希取余</p></li><li><p>一致性哈希</p></li><li><p><strong><font color="orange">哈希槽</font></strong></p><blockquote><p>Redis Cluster 采取的数据分片算法就是这种！</p></blockquote></li></ul></li></ul><p>这里仅展开介绍上述三种哈希分区算法！</p><h4 id="哈希取余-分区算法"><a class="anchor" href="#哈希取余-分区算法">#</a> 哈希取余 分区算法</h4><blockquote><p>小厂可用</p></blockquote><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230809004525207.png" alt="image-20230809004525207"></p><p>该算法的前提是，每个节点都已分配好了一个唯一序号，对于 N 个节点的集群，其序号范围为 [0, N-1]。<font color="red">选取数据本身或可以代表数据特征的数据的一部分作为 key，计算 hash (key) 与节点数量 N 的模，即 <code>hash(key) % N</code> ，计算结果决定了该数据的存储节点的序号</font>。</p><p><font color="gree">优点</font>：</p><ul><li>简单有效。只需要预估好数据规模，规划好节点，就能保证一段时间的数据支撑。</li><li>负载均衡。使用 Hash 算法让固定的一部分请求落到同一台服务器上，这样<font color="red">每台服务器固定处理一部分请求</font>（并维护这些请求的信息）。</li></ul><p><font color="gree">缺点</font>：</p><ul><li><strong><font color="red">Redis 节点的扩容 / 缩容麻烦</font></strong>。已经存储过的数据需要根据新的节点数量 N 进行<font color="red">数据迁移</font>，否则用户根据 key 是无法再找到原来的数据的。生产中扩容一般采用翻倍扩容方式，以减少扩容时数据迁移的比例。</li><li>某个 Redis 机器宕机了，由于台数数量变化，会导致 hash 取余全部数据重新洗牌。</li></ul><h4 id="一致性哈希-分区算法"><a class="anchor" href="#一致性哈希-分区算法">#</a> 一致性哈希 分区算法</h4><blockquote><p>在哈希取余算法的基础上，<strong><font color="red">固定了取余的分母为 2<sup>32</sup>-1（因此称之一致性）</font></strong>，而不再是 Master 节点数量。</p></blockquote><h5 id="设计思想"><a class="anchor" href="#设计思想">#</a> 设计思想</h5><p>为了解决<font color="red">哈希取余分区算法中的数据变动和映射问题</font>（某个机器宕机导致分母数量改变了，自然取余数不 OK 了）。目的是<font color="red">当 Redis 节点个数发生变动时，尽量减少客户端到服务器的映射关系的影响</font>。</p><p>一致性哈希算法通过一个叫作 **<font color="#B32015">一致性哈希环</font><strong>的数据结构实现。这个环的起点是 0，终点是 2<sup>32</sup> - 1，并且</strong><font color="red">起点与终点重合</font><strong>。环中间的整数按逆 / 顺时针分布，故这个环的整数分布范围是</strong><font color="red">[0, 2<sup>32</sup>-1]</font>**。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231210191026016.png" alt="image-20231210191026016"></p><p>上图中存在四个对象 o0、 o1、 o2、 o3，分别代表四个待分配的数据，红色方块是这四个数据的 hash (o) 在 Hash 环中的落点。同时，图上还存在三个节点 m0、 m1、 m2，绿色圆圈是这三节点的 hash (m) 在 Hash 环中的落点。</p><p>现在要为数据分配其要存储的节点。<strong><font color="red">该数据对象的 hash (o) 按照逆 / 顺时针方向距离哪个节点的 hash (m) 最近，就将该数据存储在哪个节点</font></strong>。这样就会形成上图所示的分配结果。</p><h5 id="3大步骤"><a class="anchor" href="#3大步骤">#</a> 3 大步骤</h5><ol><li><p><strong>构建一致性哈希环</strong>：</p><p>一致性哈希算法必然有个 hash 函数用于产生 hash 值，这个算法的所有可能哈希值会构成一个<font color="red">全量集</font>，这个集合可以成为一个 **<font color="red">hash 空间 [0,2<sup>32</sup>-1]</font><strong>，这个是一个线性空间，但是在算法中，我们通过适当的逻辑控制将它</strong><font color="red">首尾相连 (0 = 2<sup>32</sup>)</font>**，这样让它形成了一个<font color="red">逻辑上的环形空间</font>。</p><p>它也是按照使用取模的方法，<font color="red">前面介绍的是对 Redis 节点的数量进行取模</font>。而 **<font color="orange">一致性哈希算法是对 2<sup>32</sup> 取模</font>（因为取余的分母是固定的，所以称其一致性）**。</p><p>简单来说，一致性 Hash 算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数的值空间为 [0,2<sup>32</sup>-1]（即哈希值是一个 32 位无符号整形），整个哈希环如下图：整个空间按顺时针方向组织，圆环的正上方的点代表 0，0 点右侧的第一个点代表 1，以此类推，2、3、4、…… 直到 2<sup>32</sup>-1，也就是说<font color="red">0 点左侧的第一个点代表 2<sup>32</sup>-1</font>， 0 和 2<sup>32</sup>-1 在零点中方向重合，我们把这个 **<font color="red">由 2<sup>32</sup> 个点组成</font>** 的圆环称为 <code>Hash环</code> 。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230809010605612.png" alt="image-20230809010605612"></p></li><li><p><strong>Redis 服务器节点 IP 映射</strong>：</p><p>将集群中各个 Redis 节点的 IP 映射到环上的某一个位置。</p><p>将各个 Redis 服务器的 IP 或主机名作为关键字使用 Hash 进行哈希，这样每台机器就能确定其在哈希环上的位置。假如 4 个 Redis 节点 NodeA、NodeB、NodeC、NodeD，经过<font color="red">IP 地址的哈希函数计算 hash (ip)</font>，使用 IP 地址哈希后在环空间的位置如下：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230809114247849.png" alt="image-20230809114247849"></p></li><li><p><strong>落 key 规则</strong>：</p><p>当我们需要存储一个键值对时，<font color="red">首先计算 key 的 hash 值，hash (key)</font>，确定此数据在环上的位置，从此位置沿环 **<font color="red">顺时针</font>**“行走”，<font color="red">第一台遇到的 Redis 服务器</font>就是其应该定位到的服务器，并将该键值对存储在该节点上。</p><p>如我们有 Object A、Object B、Object C、Object D 四个数据对象，经过哈希计算后，在环空间上的位置如下：根据一致性 Hash 算法，Object A 会被定为到 Node A 上，Object B 被定为到 Node B 上，Object C 被定为到 Node C 上，Object D 被定为到 Node D 上。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230809114625589.png" alt="image-20230809114625589"></p></li></ol><h5 id="优缺点"><a class="anchor" href="#优缺点">#</a> 优缺点</h5><p><font color="gree">优点</font>：</p><ul><li><p><strong><font color="#B32015">容错性</font></strong></p><blockquote><p>假设 Node C 宕机，可以看到此时对象 A、B、D 不会受到影响。一般的，在一致性 Hash 算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。<font color="red">简单说，就是 C 挂了，受到影响的只是 B、C 之间的数据，且这些数据会转移到 D 进行存储</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230809115305990.png" alt="image-20230809115305990"></p></blockquote></li><li><p><strong><font color="#B32015">Redis 节点的扩容 / 缩容方便</font></strong></p><blockquote><p>随着数据量的增加，需要增加一台节点 NodeX，位置在 A 和 B 之间，<font color="red">那受到影响的也就是 A 到 X 之间的数据，重新把 A 到 X 的数据录入到 X 上即可，不会导致 hash 取余全部数据重新洗牌</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230809120153493.png" alt="image-20230809120153493"></p></blockquote></li></ul><p><font color="gree">缺点</font>：<strong>数据倾斜</strong>问题</p><blockquote><p><strong>当 Redis 服务节点太少时</strong>，容易因为<font color="red">节点分布不均匀</font>而造成<strong>数据倾斜</strong>（被缓存的数据对象大部分集中缓存在某一台服务器上）问题。</p><p>例如系统中只有两台服务器：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230809120432504.png" alt="image-20230809120432504"></p></blockquote><h4 id="哈希槽slot-分区算法"><a class="anchor" href="#哈希槽slot-分区算法">#</a> <mark>🌟哈希槽 (slot) 分区算法</mark></h4><blockquote><p>大厂都用它！而且 <strong>Redis Cluster 的数据分区采用的就是这种方式！</strong></p></blockquote><h5 id="设计思想javaguide"><a class="anchor" href="#设计思想javaguide">#</a> 设计思想（JavaGuide）</h5><p>Redis Cluster 并没有使用一致性哈希，采用的是 **<font color="#B32015">哈希槽分区</font>** ，每一个键值对都属于一个 hash slot（哈希槽）。</p><p>Redis Cluster 通常有 16384 个哈希槽 ，要计算给定 key 应该分布到哪个哈希槽中，我们只需要先对每个 key 计算 CRC-16（XMODEM） 校验码，然后再对这个校验码对 16384 (哈希槽的总数) 取模，得到的值即是 key 对应的哈希槽。</p><p>哈希槽的计算公式如下：</p><pre><code class="language-C">HASH_SLOT = CRC16(key) mod 16384
</code></pre><p>创建并初始化 Redis Cluster 的时候，Redis 会自动平均分配这 16384 个哈希槽到各个节点，不需要我们手动分配。如果你想自己手动调整的话，Redis Cluster 也内置了相关的命令比如 <code>ADDSLOTS、ADDSLOTSRANGE</code> （后面会详细介绍到重新分配哈希槽相关的命令）。</p><p>客户端连接 Redis Cluster 中任意一个 master 节点即可访问 Redis Cluster 的数据。<font color="red">当客户端发送命令请求的时候，需要先根据 key 通过上面的计算公示找到的对应的哈希槽，然后再查询哈希槽和节点的映射关系，即可找到目标节点。</font></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/06f32493-52dc-4c53-8522-fb98e72da782.png" alt="img"></p><p>如果哈希槽确实是当前节点负责，那就直接响应客户端的请求返回结果，<font color="red">如果不由当前节点负责，就会返回 <code>-MOVED</code> 重定向错误，告知客户端当前哈希槽是由哪个节点负责，客户端向目标节点发送请求并更新缓存的哈希槽分配信息</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231216122451496.png" alt="image-20231216122451496"></p><p>这个时候你可能就会疑问：<strong>为什么还会存在找错节点的情况呢？根据公式计算难道还会出错？</strong></p><p>这是因为 Redis Cluster <font color="red">内部可能会重新分配哈希槽，比如扩容缩容的时候</font>（后文中有详细介绍到 Redis Cluster 的扩容和缩容问题），这就可能会导致客户端缓存的哈希槽分配信息会有误。</p><p>从上面的介绍中，我们可以简单总结出 Redis Cluster 哈希槽分区机制的优点：<strong><font color="#B32015">解耦了数据和节点之间的关系，提升了集群的横向扩展性和容错性。</font></strong></p><h5 id="设计思想-2"><a class="anchor" href="#设计思想-2">#</a> 设计思想</h5><p>为了解决<font color="red">数据分配不均匀</font>的问题（数据倾斜），哈希槽分区算法<font color="red">在数据和 Redis 节点之间加了一层哈希槽（slot）</font>，用于管理数据和 Redis 节点之间的关系，相当于是<font color="red">把数据放入槽中，再把槽映射到 Redis 节点上</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231210194354635.png" alt="image-20231210194354635"></p><p>该算法 **<font color="red">首先虚拟出一个固定数量为 2<sup>14</sup>=16384 的整数集合，其中每个整数称为一个槽（slot）</font><strong>。这个槽的数量一般是远远大于节点数量的。然后</strong><font color="red">再将所有槽平均映射到各个 Redis 节点之上</font>**。</p><p>例如，Redis 分布式系统中共虚拟了 16384（即 2<sup>14</sup>） 个 slot 槽，其范围为 [0, 16383]。假设共有 3 个节点，那么 slot 槽与节点间的映射关系如下图所示：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231210192907595.png" alt="image-20231210192907595"></p><p><font color="red">数据只与 slot 槽有关系，与 Redis 节点没有直接关系</font>。数据根据计算公式 <code>slot = hash(key) % slotNums</code> 映射到 slot 槽。这也是该算法的一个优点，<font color="red">解耦了数据与节点，客户端无需维护节点，只需维护与 slot 槽的关系即可</font>。</p><p>Redis Cluster 的数据分区采用的就是该算法。其计算槽点的公式为： <code>slot = CRC16(key) % 16384</code> 。 <strong><font color="red">CRC16 () 是一种带有校验功能的、具有良好分散功能的、特殊的 hash 算法函数</font></strong>。 其实 Redis 中计算槽点的公式不是上面的那个，而是： <code>slot = CRC16(key) &amp; 16383</code> 。</p><blockquote><p>若要计算 a % b，如果 b 是 2 的整数次幂，那么 a % b = a &amp; (b-1)。</p></blockquote><h5 id="为什么哈希槽的数量是16384个"><a class="anchor" href="#为什么哈希槽的数量是16384个">#</a> 为什么哈希槽的数量是 16384 个？</h5><blockquote><p><font color="red"><strong>CRC16 () 算法产生的哈希值有 16bit</strong>，即 2<sup>16</sup>=65536 个值，为什么 Redis 集群的算法只采用 2<sup>14</sup>=16384 个哈希槽？</font>在进行 mode 运算时，为什么是 <code>HASH_SLOT = CRC16(key) mod 16384</code> 而不是 <code>HASH_SLOT = CRC16(key) mod 65536</code> ？</p></blockquote><p><font color="gree">作者的回复</font>：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230809132510614.png" alt="image-20230809132510614"></p><p><font color="gree">消息头 clusterMsg 的结构</font>：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20230809132604570.png" alt="image-20230809132604570"></p><p><strong><font color="gree">标准回答</font></strong>：</p><ul><li><p>正常的心跳包会携带一个节点的完整配置，它会以幂等的方式更新旧的配置，这意味着<font color="red">心跳包会附带当前节点的负责的哈希槽的信息</font>。假设哈希槽采用 16384，则占空间 2k（16384/8）。假设哈希槽采用 65536，则占空间 8k (65536/8)，这是令人难以接受的内存占用。因此，<font color="red">如果槽位为 65536，那么发送心跳信息的消息头大小达到 8k，<strong>发送的心跳包过于庞大，浪费带宽</strong>。</font></p><blockquote><p>在消息头中最占空间的是 <code>myslots[CLUSTER_SLOTS/8]</code> :</p><ul><li>当槽位为 65536 时，这块的大小是: 65536÷8÷1024=<font color="red">8kb</font></li><li>当槽位为 16384 时，这块的大小是: 16384÷8÷1024=<font color="red">2kb</font></li></ul><p>因为每秒钟 redis 节点需要发送一定数量的 ping 消息作为心跳包，如果槽位为 65536，这个 <font color="red">ping 消息的消息头太大了，浪费带宽</font>。</p></blockquote></li><li><p><font color="red">对于基本不可能超过 1000 个 master 节点数量的 redi 集群而言，<strong>16384 个槽位就已经够用了</strong>。</font></p><blockquote><p>集群的节点越多，心跳包的消息体内携带的数据越多。如果节点过 1000 个，也会导致网络拥堵。因此 redis 作者不建议 redis cluster 节点数量超过 1000 个。那么，<font color="red">对于节点数在 1000 以内的 redis cluster 集群，16384 个槽位够用了</font>。没有必要拓展到 65536 个。</p></blockquote></li><li><p><font color="red">槽位越小，节点少的情况下，<strong>压缩比高，容易传输</strong></font></p><blockquote><p>Redis 的 master 节点的配置信息中它所负责的哈希槽是通过一张 bitmap 的形式来保存的，在传输过程中会对 bitmap 进行压缩，但是<font color="red">如果 bitmap 的填充率 slots / N 很高的话 (N 表示节点数)，bitmap 的压缩率就很低</font>。如果节点数很少，而哈希槽数量很多的话，bitmap 的压缩率就很低。</p></blockquote></li></ul><h3 id="集群操作案例演示"><a class="anchor" href="#集群操作案例演示">#</a> 集群操作（案例演示）</h3><h4 id="集群架构说明"><a class="anchor" href="#集群架构说明">#</a> 集群架构说明</h4><p>集群的架构是最简单的三主三从。即在 3 台虚拟机上新建 6 个独立的 Redis 实例服务，每台机器上一主一从，<font color="gree">设计图</font>如下：</p><blockquote><p>注意：<strong><font color="red">master 与 slave 的角色以及配对关系，实际上是在系统搭建成功后自动随机分配的</font></strong>。</p></blockquote><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/IMG_8445(20230809-135635).JPEG" alt="IMG_8445(20230809-135635)"></p><h4 id="集群搭建"><a class="anchor" href="#集群搭建">#</a> 集群搭建</h4><blockquote><p>接下来的操作中，Redis 节点从 6381~6386 变成了 6380~6385。</p></blockquote><h5 id="集群架构"><a class="anchor" href="#集群架构">#</a> 集群架构</h5><p>下面要搭建的 Redis 分布式系统由 6 个节点构成，这 6 个节点的地址及角色分别如下表所示。一个 master 配备一个 slave，不过 master 与 slave 的角色以及配对关系，实际上是在系统搭建成功后自动随机分配的。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213190023854.png" alt="image-20231213190023854"></p><h5 id="删除持久化文件"><a class="anchor" href="#删除持久化文件">#</a> 删除持久化文件</h5><p>先将之前 “Redis 主从集群” 中在 Redis 安装目录下生成的<font color="red"> RDB 持久化文件</font> dump638*.conf 与<font color="red"> AOF 持久化文件</font>删除。因为<font color="red"> Redis 分布式系统要求创建在一个空的数据库之上</font>。注意， AOF 持久化文件全部在 appendonlydir 目录中。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213190413135.png" alt="image-20231213190413135"></p><h5 id="创建目录"><a class="anchor" href="#创建目录">#</a> 创建目录</h5><p>在 Redis 安装目录中 mkdir 一个新的目录 cluster-dis，用作分布式系统的工作目录。</p><h5 id="复制2个配置文件"><a class="anchor" href="#复制2个配置文件">#</a> 复制 2 个配置文件</h5><p>将 cluster 目录中的 redis.conf 与 redis6380.conf 文件复制到 cluster-dis 目录。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213190509762.png" alt="image-20231213190509762"></p><h5 id="修改-redisconf"><a class="anchor" href="#修改-redisconf">#</a> 修改 redis.conf</h5><p>对于 redis.conf 配置文件，主要涉及到以下三个四个属性：</p><ul><li><p><code>dir</code> ：指定<font color="red">工作目录</font>为前面创建的 cluster-dis 目录。持久化文件、节点配置文件将来都会在工作目录中自动生成。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213190633688.png" alt="image-20231213190633688"></p></li><li><p><code>cluster-enabled</code> ：开启 Redis 的<font color="red">集群模式</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213190642530.png" alt="image-20231213190642530"></p></li><li><p><code>cluster-config-file</code> ：指定 “集群节点” 的<font color="red">配置文件</font>。该文件会在第一次节点启动时自动生成，其生成的路径是在 dir 属性指定的工作目录中。在集群节点信息发生变化后（如节点下线、故障转移等），节点会自动将集群状态信息保存到该配置文件中。不过，该属性在这里仍保持注释状态。<font color="red">在后面的每个节点单独的配置文件中配置它</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213190827903.png" alt="image-20231213190827903"></p></li><li><p><code>cluster-node-timeout</code> ：指定 “集群节点” 间<font color="red">通信的超时时间阈值</font>，单位毫秒。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213190925419.png" alt="image-20231213190925419"></p></li></ul><h5 id="修改-redis6380conf"><a class="anchor" href="#修改-redis6380conf">#</a> 修改 redis6380.conf</h5><p>仅添加一个 cluster-config-file 属性即可。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213191005505.png" alt="image-20231213191005505"></p><h5 id="复制5个配置文件"><a class="anchor" href="#复制5个配置文件">#</a> 复制 5 个配置文件</h5><p>使用 redis6380.conf 复制出 5 个配置文件 redis6381.conf、redis6382.conf、redis6383.conf、redis6384.conf、 redis6385.conf。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213191314724.png" alt="image-20231213191314724"></p><p>cluster-dis 中出现了 7 个配置文件。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213191414191.png" alt="image-20231213191414191"></p><h5 id="修改5个配置文件"><a class="anchor" href="#修改5个配置文件">#</a> 修改 5 个配置文件</h5><p>修改 5 个配置文件 redis6381.conf、 redis6382.conf、 redis6383.conf、 redis6384.conf、redis6385.conf 的内容，将其中所有涉及的<font color="red">端口号</font>全部替换为当前文件名称中的端口号。例如，下面的是 redis6381.conf 的配置文件内容。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213191459568.png" alt="image-20231213191459568"></p><h4 id="集群启动与关闭"><a class="anchor" href="#集群启动与关闭">#</a> 集群启动与关闭</h4><h5 id="启动节点"><a class="anchor" href="#启动节点">#</a> 启动节点</h5><p>启动所有 Redis 节点。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213193441641.png" alt="image-20231213193441641"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213193459669.png" alt="image-20231213193459669"></p><p>此时查看 cluster-dis 目录，可以看到生成了 6 个 nodes 的配置文件。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213193536609.png" alt="image-20231213193536609"></p><h5 id="创建集群"><a class="anchor" href="#创建集群">#</a> 创建集群</h5><p>6 个节点启动后，它们仍是 6 个独立的 Redis，通过 <code>redis-cli --cluster create</code> 命令可将 6 个节点创建了一个分布式系统。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213193647388.png" alt="image-20231213193647388"></p><p>该命令用于将指定的 6 个节点连接为一个分布式系统。 <code>--cluster replicas 1</code> <font color="red">指定每个 master 会带有一个 slave 作为副本</font>。</p><p>回车后会立即看到如下日志：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213193728569.png" alt="image-20231213193728569"></p><p>输入 yes 后回车，系统就会将以上显示的动态配置信息真正的应用到节点上，然后就可看到如下日志：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213193902008.png" alt="image-20231213193902008"></p><h5 id="测试集群"><a class="anchor" href="#测试集群">#</a> 测试集群</h5><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213194244750.png" alt="image-20231213194244750"></p><p>通过 <code>cluster nodes</code> 命令可以<font color="red">查看系统中各节点的关系及连接情况</font>。只要能看到每个节点给出 connected，就说明分布式系统已经成功搭建。不过，对于客户端连接命令 redis-cli，需要注意两点：</p><ul><li>参数 - c：表示这是要连接一个 “集群”，而非是一个节点。</li><li>端口号：可以使用 6 个中的任意一个。</li></ul><h5 id="关闭集群"><a class="anchor" href="#关闭集群">#</a> 关闭集群</h5><p>对于分布式系统的关闭，只需将各个节点 shutdown 即可。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213194413240.png" alt="image-20231213194413240"></p><h4 id="连接集群"><a class="anchor" href="#连接集群">#</a> 连接集群</h4><p>无论要怎样操作分布式系统，都需要首先连接上。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213194657202.png" alt="image-20231213194657202"></p><p>与之前单机连接相比的唯一区别就是增加了参数 - c。</p><h4 id="写入数据"><a class="anchor" href="#写入数据">#</a> 写入数据</h4><h5 id="key-单个写入"><a class="anchor" href="#key-单个写入">#</a> key 单个写入</h5><p>无论 value 类型为 String 还是 List、Set 等集合类型，只要写入时操作的是一个 key，那么在分布式系统中就没有问题。例如：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213194800157.png" alt="image-20231213194800157"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213195107814.png" alt="image-20231213195107814"></p><h5 id="key-批量操作"><a class="anchor" href="#key-批量操作">#</a> key 批量操作</h5><p>对一次写入多个 key 的操作，<font color="red">由于多个 key 会计算出多个 slot，多个 slot 可能会对应多个节点。而由于<strong>一次只能写入一个节点，所以该操作会报错</strong></font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213195136514.png" alt="image-20231213195136514"></p><p>不过，系统也提供了一种对批量 key 的操作方案，<strong><font color="red">为这些 key 指定一个统一的 group，让这个 group 作为计算 slot 的唯一值</font></strong>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231213195151905.png" alt="image-20231213195151905"></p><h4 id="集群查询"><a class="anchor" href="#集群查询">#</a> 集群查询</h4><h5 id="查询-key-的-slot"><a class="anchor" href="#查询-key-的-slot">#</a> 查询 key 的 slot</h5><p>通过 <code>cluster keyslot</code> 可以<font color="red">查询指定 key 的 slot</font>。例如，下面是查询 emp 的 slot。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231214003835665.png" alt="image-20231214003835665"></p><h5 id="查询-slot-中-key-的数量"><a class="anchor" href="#查询-slot-中-key-的数量">#</a> 查询 slot 中 key 的数量</h5><p>通过 <code>cluster countkeysinslot</code> 命令可以查看到指定 slot 所包含的 key 的个数。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231214003913529.png" alt="image-20231214003913529"></p><h5 id="查询-slot-中的-key"><a class="anchor" href="#查询-slot-中的-key">#</a> 查询 slot 中的 key</h5><p>通过 <code>cluster getkeysinslot</code> 命令可以查看到指定 slot 所包含的 key。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231214003941285.png" alt="image-20231214003941285"></p><h4 id="故障转移failover"><a class="anchor" href="#故障转移failover">#</a> 故障转移（failover）</h4><h5 id="模拟故障"><a class="anchor" href="#模拟故障">#</a> 模拟故障</h5><p>通过 <code>cluster nodes</code> 命令可以查看<font color="red">集群的整体架构及连接情况</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231214150028063.png" alt="image-20231214150028063"></p><p>当然，也可以通过 <code>info replication</code> 查看<font color="red">当前客户端连接的节点的角色</font>。可以看到，6381 节点是 master，其 slave 为 6383 节点。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231214150155289.png" alt="image-20231214150155289"></p><p>为了模拟 6381 宕机，直接将其 shutdown。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231214150205563.png" alt="image-20231214150205563"></p><p>通过客户端连接上 6383 节点后可以查看到，<font color="red">6383 节点已经自动晋升为了 master</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231214150223922.png" alt="image-20231214150223922"></p><p>重启 6381 节点后查看其角色，发现<font color="red"> 6381 节点自动成为了 6383 节点的 slave</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231214150239399.png" alt="image-20231214150239399"></p><h5 id="全覆盖需求"><a class="anchor" href="#全覆盖需求">#</a> 全覆盖需求</h5><p><font color="red">如果某 slot 范围对应节点的 master 与 slave 全部宕机，那么整个分布式系统是否还可以对外提供读服务</font>，就取决于属性 <code>cluster-require-full-coverage</code> 的设置。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231214150545505.png" alt="image-20231214150545505"></p><p>该属性有两种取值：</p><ul><li><font color="gree">yes</font>：默认值。要求所有 slot 节点必须全覆盖的情况下系统才能运行。</li><li><font color="gree">no</font>：<strong><font color="red">slot 节点不全的情况下系统也可以提供查询服务</font></strong>。</li></ul><h4 id="集群扩容"><a class="anchor" href="#集群扩容">#</a> 集群扩容</h4><p>下面要在正在运行的分布式系统中添加两个新的节点：端口号为 6386 的节点为 master 节点，其下会有一个端口号为 6387 的 slave 节点。</p><h5 id="复制并修改-2-个配置文件"><a class="anchor" href="#复制并修改-2-个配置文件">#</a> 复制并修改 2 个配置文件</h5><p>使用 redis6380.conf 复制出 2 个配置文件 redis6386.conf 与 redis6387.conf，并修改其中的各处端口号为相应端口号，为集群扩容做前期准备。</p><h5 id="启动系统与-2-个节点"><a class="anchor" href="#启动系统与-2-个节点">#</a> 启动系统与 2 个节点</h5><p>由于要演示的是在分布式系统运行期间的动态扩容，所以这里先启动分布式系统。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215172635503.png" alt="image-20231215172635503"></p><p>要添加的两个节点是两个 Redis，所以需要先将它们启动。只不过，在没有添加到分布式系统之前，它们两个是孤立节点，每个节点与其它任何节点都没有关系。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215172655817.png" alt="image-20231215172655817"></p><h5 id="添加-master-节点"><a class="anchor" href="#添加-master-节点">#</a> 添加 master 节点</h5><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215172700376.png" alt="image-20231215172700376"></p><p>通过命令 <code>redis-cli --cluster add-node &#123;newHost&#125;:&#123;newPort&#125; &#123;existHost&#125;:&#123;existPort&#125;</code> 可以将新的节点添加到系统中。其中 {newHost}:{newPort} 是新添加节点的地址，{existHost}:{existPort} 是<font color="red">原系统中的任意节点地址</font>。</p><p>添加成功后可看到如下日志。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215172848431.png" alt="image-20231215172848431"></p><p>添加成功后，通过 <code>redis-cli -c -p 6386 cluster nodes</code> 命令可以看到其它 master 节点都分配有 slot，只有新添加的 master 还没有相应的 slot。当然，通过该命令也可以看到该新节点的动态 ID。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215172946229.png" alt="image-20231215172946229"></p><h5 id="分配-slot"><a class="anchor" href="#分配-slot">#</a> 分配 slot</h5><p>为新的 master 分配的 slot 来自于其它节点，总 slot 数量并不会改变。所以 slot 分配过程<font color="red">本质是一个 slot 的移动过程</font>。</p><p>通过 <code>redis-cli –c --cluster reshard &#123;existIP&#125;:&#123;existPort&#125;</code> 命令可 **<font color="red">开启 slot 分配流程</font>**。其中地址 {existIP}:{existPort} 为分布式系统中的任意节点地址。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215173057570.png" alt="image-20231215173057570"></p><p>该流程中会<font color="red">首先查询出当前节点的 slot 分配情况</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215173132186.png" alt="image-20231215173132186"></p><p>然后<font color="red">开始 Q&amp;A 交互</font>。一共询问了四个问题，这里有三个：</p><ul><li>准备移动多少 slot？</li><li>准备由谁来接收移动的 slot？</li><li>选择要移动 slot 的源节点，有两种方案。<ul><li>如果选择键入 <font color="gree">all</font>，则所有已存在 slot 的节点都将作为 slot 源节点，即该方案将进行一次 slot 全局大分配。</li><li>也可以选择<font color="gree">其它部分节点</font>作为 slot 源节点。此时将源节点的动态 ID 复制到这里，每个 ID 键入完毕后回车，然后再复制下一个 slot 源节点动态 ID，直至最后一个键入完毕回车后再键入 done。</li></ul></li></ul><p>这里键入的是 all，进行全局大分配。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215175514516.png" alt="image-20231215175514516"></p><p>其首先会检测指定的 slot 源节点的数据，然后制定出 reshard 的方案。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215180639548.png" alt="image-20231215180639548"></p><p>这里会再进行一次 Q&amp;A 交互，询问是否想继续处理推荐的方案。键入 yes，然后开始真正的全局分配，直至完成。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215180704120.png" alt="image-20231215180704120"></p><p>此时再通过 redis-cli -c -p 6386 cluster nodes 命令查看节点信息，可以看到 6386 节点中已经分配了 slot，只不过分配的 slot 编号并不连续。 master 节点新增完成。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215180725935.png" alt="image-20231215180725935"></p><h5 id="添加-slave-节点"><a class="anchor" href="#添加-slave-节点">#</a> 添加 slave 节点</h5><p>现要将 6387 节点添加为 6386 节点的 slave。 当然，首先要确保 6387 节点的 Redis 是启动状态。</p><p>通过 <code>redis-cli --cluster add-node &#123;newHost&#125;:&#123;newPort&#125; &#123;existHost&#125;:&#123;existPort&#125; --cluster-slave --cluster-master-id masterID</code> 命令可将新添加的节点直接添加为指定 master 的 slave。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215180849727.png" alt="image-20231215180849727"></p><p>回车后可看到如下的日志，说明添加成功。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215180904899.png" alt="image-20231215180904899"></p><p>此时再通过 redis-cli -c -p 6386 cluster nodes 命令可以看到其已经添加成功，且为指定 master 的 slave。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231215180939876.png" alt="image-20231215180939876"></p><h4 id="集群缩容"><a class="anchor" href="#集群缩容">#</a> 集群缩容</h4><p>下面要将 slave 节点 6387 与 master 节点 6386 从分布式系统中删除。</p><h5 id="删除-slave-节点"><a class="anchor" href="#删除-slave-节点">#</a> 删除 slave 节点</h5><p>对于 slave 节点，可以直接通过 <code>redis-cli --cluster del-node &lt;delHost&gt;:&lt;delPort&gt; delNodeID</code> 命令删除。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231216113753611.png" alt="image-20231216113753611"></p><p>此时再查看集群，发现已经没有了 6387 节点。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231216113855438.png" alt="image-20231216113855438"></p><h5 id="移出-master-的-slot"><a class="anchor" href="#移出-master-的-slot">#</a> 移出 master 的 slot</h5><p><strong><font color="red">在删除一个 master 之前，必须要保证该 master 上没有分配有 slot，否则无法删除</font></strong>。所以，在删除一个 master 之前，需要先将其上分配的 slot 移出。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231216114101043.png" alt="image-20231216114101043"></p><p>以上交互指定的是将 6386 节点中的 1999 个 slot 移动到 6380 节点。</p><p>注意：</p><ul><li>要删除的节点所包含的 slot 数量在前面检测结果中都是可以看到的，例如， 6386 中的并不是 2000 个，而是 1999 个</li><li>What is the receiving node ID？仅能指定一个接收节点</li></ul><p>回车后继续。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231216114332934.png" alt="image-20231216114332934"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231216114400814.png" alt="image-20231216114400814"></p><p>此时再查看发现，6386 节点中已经没有 slot 了。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231216121516825.png" alt="image-20231216121516825"></p><h5 id="删除-master-节点"><a class="anchor" href="#删除-master-节点">#</a> 删除 master 节点</h5><p>此时就可以删除 6386 节点了。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231216121543342.png" alt="image-20231216121543342"></p><p>此时再查看集群，发现已经没有了 6386 节点。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231216121555920.png" alt="image-20231216121555920"></p><h3 id="局限性"><a class="anchor" href="#局限性">#</a> 局限性</h3><p>Redis Cluster 存在一些使用限制：</p><ul><li>仅支持 0 号数据库</li><li>批量 key 操作支持有限</li><li>分区仅限于 key</li><li>事务支持有限</li><li>不支持分级管理</li></ul><h3 id="redis-cluster-在扩容缩容期间可以提供服务吗"><a class="anchor" href="#redis-cluster-在扩容缩容期间可以提供服务吗">#</a> Redis Cluster 在扩容 / 缩容期间可以提供服务吗？</h3><p><strong><font color="#B32015">Redis Cluster 扩容和缩容本质是进行重新分片，动态迁移哈希槽。</font></strong></p><p>为了保证 Redis Cluster 在扩容和缩容期间依然能够对外正常提供服务，Redis Cluster 提供了重定向机制，两种不同的类型：</p><ul><li><font color="gree">ASK 重定向</font></li><li><font color="gree">MOVED 重定向</font></li></ul><p>从客户端的角度来看，ASK 重定向是下面这样的：</p><ol><li>客户端发送请求命令，如果请求的 key 对应的哈希槽还在当前节点的话，就直接响应客户端的请求。</li><li><font color="red">如果客户端请求的 key 对应的哈希槽当前正在迁移至新的节点，就会返回 <code>-ASK</code> 重定向错误，告知客户端要将请求发送到哈希槽被迁移到的目标节点</font>。</li><li>客户端收到 -ASK 重定向错误后，将会临时（一次性）重定向，自动向目标节点发送一条 <span class="exturl" data-url="aHR0cHM6Ly9yZWRpcy5pby9jb21tYW5kcy9hc2tpbmcv">ASKING</span> 命令。也就是说，接收到 ASKING 命令的节点会强制执行一次请求，下次再来需要重新提前发送 ASKING 命令。</li><li>客户端发送真正的请求命令。</li><li><font color="red">ASK 重定向并不会同步更新客户端缓存的哈希槽分配信息</font>，也就是说，客户端对正在迁移的相同哈希槽的请求依然会发送到原节点而不是目标节点。</li></ol><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/ca358827-2d14-40cd-ab6a-64ec1ea21428.png" alt="img"></p><p><font color="red">如果客户端请求的 key 对应的哈希槽已经迁移完成的话，就会返回 <code>-MOVED</code> 重定向错误，告知客户端当前哈希槽是由哪个节点负责，客户端向目标节点发送请求并更新缓存的哈希槽分配信息</font>。</p><h3 id="cap-定理"><a class="anchor" href="#cap-定理">#</a> CAP 定理</h3><h4 id="概念"><a class="anchor" href="#概念">#</a> 概念</h4><p>CAP 定理指的是 **<font color="#B32015">在一个分布式系统中，一致性（C）、可用性（A）、分区容错性（P）三者不可兼得</font>**。</p><ul><li><font color="cornflowerblue">一致性（Consistency）</font>：分布式系统中多个主机之间是否能够保持数据一致的特性。即，<font color="red">当系统数据发生更新操作后，各个主机中的数据仍然处于一致的状态</font>。</li><li><font color="cornflowerblue">可用性（Availability）</font>：<font color="red">系统提供的服务必须一直处于可用的状态</font>，即对于用户的每一个请求，系统总是可以在有限的时间内对用户做出响应。</li><li><font color="cornflowerblue">分区容错性（Partition tolerance）</font>：<font color="red">分布式系统在遇到任何<strong>网络分区故障</strong>时，仍能够保证对外提供满足一致性和可用性的服务</font>。</li></ul><h4 id="定理"><a class="anchor" href="#定理">#</a> 定理</h4><p>CAP 定理的内容是：<font color="red">对于分布式系统，网络环境相对是不可控的，出现网络分区是不可避免的，因此系统必须具备分区容错性</font>。但 **<font color="red">系统不能同时保证一致性（C）与可用性（A）。即要么 CP，要么 AP</font>**。</p><h4 id="base-理论"><a class="anchor" href="#base-理论">#</a> BASE 理论</h4><p><font color="red">BASE 是对 CAP 中一致性和可用性权衡的结果</font>，其来源于对大规模互联网系统分布式实践的结论，是基于 CAP 定理逐步演化而来的，由以下三个短语的简写组成：</p><ul><li><font color="cornflowerblue"><code>B</code> asically <code>A</code> vailable（基本可用）</font>：分布式系统在出现不可预知故障的时候，<font color="red">允许损失部分可用性</font></li><li><font color="cornflowerblue"><code>S</code> oft state（软状态）</font>：允许系统数据存在的中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即<font color="red">允许系统主机间进行数据同步的过程存在一定延时</font>。软状态，其实就是一种灰度状态，过渡状态。</li><li><font color="cornflowerblue"><code>E</code> ventually consistent（最终一致性）</font>：强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是<font color="red">需要系统保证最终数据能够达到一致，而不需要保证系统数据的实时一致性</font>。</li></ul><p>BASE 理论的核心思想是：<strong><font color="red">即使无法做到强一致性，但每个系统都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性</font></strong>。</p><h4 id="cap-应用"><a class="anchor" href="#cap-应用">#</a> CAP 应用</h4><h5 id="zookeepercp-模式"><a class="anchor" href="#zookeepercp-模式">#</a> Zookeeper：CP 模式</h5><p>Zookeeper 遵循的是 CP 模式，即保证了一致性（C），但牺牲了可用性（A）。<font color="red">当 Leader 节点中的数据发生了变化后，在 Follower 还没有同步完成之前，整个 Zookeeper 集群是不对外提供服务的</font>。如果此时有客户端来访问数据，则客户端会因访问超时而发生重试。不过，由于 Leader 的选举非常快，所以这种重试对于用户来说几乎是感知不到的。所以说，Zookeeper 保证了一致性，但牺牲了可用性。</p><h5 id="consulcp-模式"><a class="anchor" href="#consulcp-模式">#</a> Consul：CP 模式</h5><h5 id="redisap-模式"><a class="anchor" href="#redisap-模式">#</a> Redis：AP 模式</h5><p>Redis 遵循的是 AP 模式，即保证了可用性（A），但牺牲了一致性（C）。</p><h5 id="eurekaap-模式"><a class="anchor" href="#eurekaap-模式">#</a> Eureka：AP 模式</h5><h5 id="nacosap-模式"><a class="anchor" href="#nacosap-模式">#</a> Nacos：AP 模式</h5><p>Nacos 在做注册中心时，默认是 AP 的。但其也支持 CP 模式，但需要用户提交请求进行转换。</p><h1 id="使用规范"><a class="anchor" href="#使用规范">#</a> 使用规范</h1><p>实际使用 Redis 的过程中，我们尽量要准守一些常见的规范，比如：</p><ol><li><font color="red">使用连接池</font>：避免频繁创建关闭客户端连接。</li><li><font color="red">尽量不使用 O (n) 指令</font>，使用 O (n) 命令时要关注 n 的数量：像 <code>KEYS *</code> 、 <code>HGETALL</code> 、 <code>LRANGE</code> 、 <code>SMEMBERS</code> 、 <code>SINTER</code> / <code>SUNION</code> / <code>SDIFF</code> 等 O (n) 命令并非不能使用，但是需要明确 n 的值。另外，有遍历的需求可以使用 <code>HSCAN</code> 、 <code>SSCAN</code> 、 <code>ZSCAN</code> 代替。</li><li><font color="red">使用批量操作，减少网络传输</font>：原生批量操作命令（比如 <code>MGET</code> 、 <code>MSET</code> 等等）、pipeline、Lua 脚本。</li><li><font color="red">尽量不用 Redis 事务，用 Lua 脚本代替</font>：Redis 事务实现的功能比较鸡肋，可以使用 Lua 脚本代替。</li><li><font color="red">禁止长时间开启 monitor</font>：对性能影响比较大。</li><li><font color="red">控制 key 的生命周期</font>：避免 Redis 中存放了太多不经常被访问的数据。</li><li>……</li></ol><p>相关文章推荐：<span class="exturl" data-url="aHR0cHM6Ly9kZXZlbG9wZXIuYWxpeXVuLmNvbS9hcnRpY2xlLzUzMTA2Nw==">阿里云 Redis 开发规范</span>。</p><h1 id="lua-脚本-2"><a class="anchor" href="#lua-脚本-2">#</a> Lua 脚本</h1><h1 id="分布式锁"><a class="anchor" href="#分布式锁">#</a> 分布式锁</h1><h1 id="️重要知识点"><a class="anchor" href="#️重要知识点">#</a> ⭐️重要知识点</h1></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2024-01-10 23:05:19" itemprop="dateModified" datetime="2024-01-10T23:05:19+08:00">2024-01-10</time> </span><span id="database/redis/Redis-JavaGuide/" class="item leancloud_visitors" data-flag-title="Redis-JavaGuide" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>范特东东东 <i class="ic i-at"><em>@</em></i>水文 & 摄影</li><li class="link"><strong>本文链接：</strong> <a href="http://example.com/database/redis/Redis-JavaGuide/" title="Redis-JavaGuide">http://example.com/database/redis/Redis-JavaGuide/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/database/mysql/MySQL-JavaGuide/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;oss.javaguide.cn&#x2F;github&#x2F;javaguide&#x2F;csdn&#x2F;20210327143351823.png" title="MySQL-JavaGuide"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> MySQL</span><h3>MySQL-JavaGuide</h3></a></div><div class="item right"><a href="/database/elasticsearch/Elasticsearch-JavaGuide/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;hjx159&#x2F;picture-bed&#x2F;main&#x2F;img&#x2F;sql-nosql-tushi.png" title="Elasticsearch-JavaGuide"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> Elasticsearch</span><h3>Elasticsearch-JavaGuide</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">缓存基础常见面试题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98"><span class="toc-number">1.1.</span> <span class="toc-text">为什么要用分布式缓存？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3"><span class="toc-number">1.1.1.</span> <span class="toc-text">缓存的基本思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-number">1.1.2.</span> <span class="toc-text">缓存的分类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">本地缓存</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.1.2.1.1.</span> <span class="toc-text">是什么</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88"><span class="toc-number">1.1.2.1.2.</span> <span class="toc-text">实现方案</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">1.1.2.1.3.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">分布式缓存</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88-2"><span class="toc-number">1.1.2.2.1.</span> <span class="toc-text">是什么</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88redis"><span class="toc-number">1.1.2.2.2.</span> <span class="toc-text">实现方案：Redis</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98"><span class="toc-number">1.1.2.3.</span> <span class="toc-text">多级缓存</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5%E6%9C%89%E5%93%AA%E5%87%A0%E7%A7%8D"><span class="toc-number">1.2.</span> <span class="toc-text">常见的缓存更新策略有哪几种？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cache-aside-pattern%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.2.1.</span> <span class="toc-text">Cache Aside Pattern（旁路缓存模式）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88-3"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">是什么</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E8%AF%BB%E5%86%99%E6%AD%A5%E9%AA%A4"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">缓存读写步骤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.1.3.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9-2"><span class="toc-number">1.2.1.4.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#readwrite-through-pattern%E8%AF%BB%E5%86%99%E7%A9%BF%E9%80%8F%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.2.2.</span> <span class="toc-text">Read&#x2F;Write Through Pattern（读 &#x2F; 写穿透模式）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88-4"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">是什么</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E8%AF%BB%E5%86%99%E6%AD%A5%E9%AA%A4-2"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">缓存读写步骤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E7%90%86-2"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9-3"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#write-behind-pattern%E5%BC%82%E6%AD%A5%E7%BC%93%E5%AD%98%E5%86%99%E5%85%A5%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.2.3.</span> <span class="toc-text">Write Behind Pattern（异步缓存写入模式）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E5%9F%BA%E7%A1%80"><span class="toc-number">2.</span> <span class="toc-text">Redis 基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">2.1.</span> <span class="toc-text">Redis 是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E6%80%8E%E4%B9%88%E7%94%A8"><span class="toc-number">2.2.</span> <span class="toc-text">Redis 怎么用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E5%8A%9F%E8%83%BD"><span class="toc-number">2.3.</span> <span class="toc-text">Redis 功能</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E4%BC%98%E5%8A%BF"><span class="toc-number">2.4.</span> <span class="toc-text">Redis 优势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E8%BF%AD%E4%BB%A3%E5%8E%86%E5%8F%B2"><span class="toc-number">2.5.</span> <span class="toc-text">Redis 迭代历史</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis7-%E6%96%B0%E7%89%B9%E6%80%A7"><span class="toc-number">2.6.</span> <span class="toc-text">Redis7 新特性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB"><span class="toc-number">2.7.</span> <span class="toc-text">Redis 为什么这么快？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%E5%B8%B8%E8%A7%81%E7%9A%84%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E6%96%B9%E6%A1%88"><span class="toc-number">2.8.</span> <span class="toc-text">分布式缓存常见的技术选型方案</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E5%92%8C-memcached-%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E5%85%B1%E5%90%8C%E7%82%B9"><span class="toc-number">2.9.</span> <span class="toc-text">Redis 和 Memcached 的区别和共同点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8-redis%E6%88%96%E8%80%85%E7%BC%93%E5%AD%98"><span class="toc-number">2.10.</span> <span class="toc-text">为什么要用 Redis（或者缓存）？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E7%BC%93%E5%AD%98%E8%AF%BB%E5%86%99%E7%AD%96%E7%95%A5"><span class="toc-number">2.11.</span> <span class="toc-text">常见的缓存读写策略</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E5%BA%94%E7%94%A8"><span class="toc-number">3.</span> <span class="toc-text">Redis 应用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E9%99%A4%E4%BA%86%E5%81%9A%E7%BC%93%E5%AD%98%E8%BF%98%E8%83%BD%E5%81%9A%E4%BB%80%E4%B9%88"><span class="toc-number">3.1.</span> <span class="toc-text">Redis 除了做缓存，还能做什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-number">3.2.</span> <span class="toc-text">Redis 如何实现分布式锁？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E5%8F%AF%E4%BB%A5%E5%81%9A%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B9%88"><span class="toc-number">3.3.</span> <span class="toc-text">Redis 可以做消息队列么？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#list-%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F"><span class="toc-number">3.3.1.</span> <span class="toc-text">List 实现方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85pubsub%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F"><span class="toc-number">3.3.2.</span> <span class="toc-text">发布订阅（pub&#x2F;sub）实现方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#stream-%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F"><span class="toc-number">3.3.3.</span> <span class="toc-text">Stream 实现方式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E5%91%BD%E4%BB%A4"><span class="toc-number">4.</span> <span class="toc-text">Redis 命令</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4"><span class="toc-number">4.1.</span> <span class="toc-text">基础命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#key-%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4"><span class="toc-number">4.2.</span> <span class="toc-text">key 相关命令</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">5.</span> <span class="toc-text">🌟Redis 数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">5.1.</span> <span class="toc-text">🌟常用数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%A7%8D%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">5.1.1.</span> <span class="toc-text">5 种基础数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#string%E5%AD%97%E7%AC%A6%E4%B8%B2"><span class="toc-number">5.1.1.1.</span> <span class="toc-text">String（字符串）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">5.1.1.1.1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4"><span class="toc-number">5.1.1.1.2.</span> <span class="toc-text">命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#string-%E5%BA%94%E7%94%A8"><span class="toc-number">5.1.1.1.3.</span> <span class="toc-text">String 应用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#list%E5%88%97%E8%A1%A8"><span class="toc-number">5.1.1.2.</span> <span class="toc-text">List（列表）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D-2"><span class="toc-number">5.1.1.2.1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4-2"><span class="toc-number">5.1.1.2.2.</span> <span class="toc-text">命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BA%94%E7%94%A8"><span class="toc-number">5.1.1.2.3.</span> <span class="toc-text">应用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#hash%E5%93%88%E5%B8%8C"><span class="toc-number">5.1.1.3.</span> <span class="toc-text">Hash（哈希）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D-3"><span class="toc-number">5.1.1.3.1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4-3"><span class="toc-number">5.1.1.3.2.</span> <span class="toc-text">命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BA%94%E7%94%A8-2"><span class="toc-number">5.1.1.3.3.</span> <span class="toc-text">应用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#set%E9%9B%86%E5%90%88"><span class="toc-number">5.1.1.4.</span> <span class="toc-text">Set（集合）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D-4"><span class="toc-number">5.1.1.4.1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4-4"><span class="toc-number">5.1.1.4.2.</span> <span class="toc-text">命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#set-%E5%BA%94%E7%94%A8"><span class="toc-number">5.1.1.4.3.</span> <span class="toc-text">Set 应用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sorted-setzset%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88"><span class="toc-number">5.1.1.5.</span> <span class="toc-text">Sorted Set&#x2F;Zset（有序集合）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D-5"><span class="toc-number">5.1.1.5.1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4-5"><span class="toc-number">5.1.1.5.2.</span> <span class="toc-text">命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#zset-%E5%BA%94%E7%94%A8"><span class="toc-number">5.1.1.5.3.</span> <span class="toc-text">Zset 应用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">5.1.1.6.</span> <span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%A7%8D%E7%89%B9%E6%AE%8A%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">5.1.2.</span> <span class="toc-text">3 种特殊数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#bitmap%E4%BD%8D%E5%9B%BE"><span class="toc-number">5.1.2.1.</span> <span class="toc-text">Bitmap（位图）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D-6"><span class="toc-number">5.1.2.1.1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4-6"><span class="toc-number">5.1.2.1.2.</span> <span class="toc-text">命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#bitmap-%E5%BA%94%E7%94%A8"><span class="toc-number">5.1.2.1.3.</span> <span class="toc-text">Bitmap 应用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#hyperloglog%E5%9F%BA%E6%95%B0%E7%BB%9F%E8%AE%A1"><span class="toc-number">5.1.2.2.</span> <span class="toc-text">HyperLogLog（基数统计）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D-7"><span class="toc-number">5.1.2.2.1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4-7"><span class="toc-number">5.1.2.2.2.</span> <span class="toc-text">命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BA%94%E7%94%A8-3"><span class="toc-number">5.1.2.2.3.</span> <span class="toc-text">应用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#geospatial%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE"><span class="toc-number">5.1.2.3.</span> <span class="toc-text">Geospatial（地理位置）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D-8"><span class="toc-number">5.1.2.3.1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4-8"><span class="toc-number">5.1.2.3.2.</span> <span class="toc-text">命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BA%94%E7%94%A8-4"><span class="toc-number">5.1.2.3.3.</span> <span class="toc-text">应用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-2"><span class="toc-number">5.1.2.4.</span> <span class="toc-text">小结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#string-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">5.2.</span> <span class="toc-text">String 应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AD%98%E5%82%A8%E5%BB%BA%E8%AE%AE%E4%BD%BF%E7%94%A8-string"><span class="toc-number">5.3.</span> <span class="toc-text">对象数据的存储建议使用 String</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#string-%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0sds"><span class="toc-number">5.4.</span> <span class="toc-text">🌟String 的底层实现：SDS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sds-%E4%BB%8B%E7%BB%8D"><span class="toc-number">5.4.1.</span> <span class="toc-text">SDS 介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sds-%E7%BB%93%E6%9E%84"><span class="toc-number">5.4.2.</span> <span class="toc-text">SDS 结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sds-%E7%9B%B8%E6%AF%94-c-%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="toc-number">5.4.3.</span> <span class="toc-text">SDS 相比 C 字符串的优势</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sds-%E6%97%A7%E7%89%88%E6%9C%AC%E7%BB%93%E6%9E%84"><span class="toc-number">5.4.4.</span> <span class="toc-text">SDS 旧版本结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B4%AD%E7%89%A9%E8%BD%A6%E4%BF%A1%E6%81%AF%E7%9A%84%E5%AD%98%E5%82%A8%E5%BB%BA%E8%AE%AE%E4%BD%BF%E7%94%A8-hash"><span class="toc-number">5.5.</span> <span class="toc-text">购物车信息的存储建议使用 Hash</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-sorted-set-%E5%AE%9E%E7%8E%B0%E6%8E%92%E8%A1%8C%E6%A6%9C"><span class="toc-number">5.6.</span> <span class="toc-text">使用 Sorted Set 实现排行榜</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#set-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">5.7.</span> <span class="toc-text">Set 应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-set-%E5%AE%9E%E7%8E%B0%E6%8A%BD%E5%A5%96%E7%B3%BB%E7%BB%9F"><span class="toc-number">5.8.</span> <span class="toc-text">使用 Set 实现抽奖系统</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E5%90%88%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0"><span class="toc-number">5.9.</span> <span class="toc-text">🌟集合的底层实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ziplist%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8"><span class="toc-number">5.9.1.</span> <span class="toc-text">zipList（压缩列表）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#listpack%E7%B4%A7%E5%87%91%E5%88%97%E8%A1%A8"><span class="toc-number">5.9.2.</span> <span class="toc-text">listPack（紧凑列表）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#skiplist%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8%E8%B7%B3%E8%A1%A8"><span class="toc-number">5.9.3.</span> <span class="toc-text">🌟skipList（跳跃列表 &#x2F; 跳表）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E7%90%86-3"><span class="toc-number">5.9.3.1.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98"><span class="toc-number">5.9.3.2.</span> <span class="toc-text">存在问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96"><span class="toc-number">5.9.3.3.</span> <span class="toc-text">算法优化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#quicklist%E5%BF%AB%E9%80%9F%E5%88%97%E8%A1%A8%E5%BF%AB%E8%A1%A8"><span class="toc-number">5.9.4.</span> <span class="toc-text">quickList（快速列表 &#x2F; 快表）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E7%90%86-4"><span class="toc-number">5.9.4.1.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A3%80%E7%B4%A2%E6%93%8D%E4%BD%9C"><span class="toc-number">5.9.4.2.</span> <span class="toc-text">检索操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8F%92%E5%85%A5%E6%93%8D%E4%BD%9C"><span class="toc-number">5.9.4.3.</span> <span class="toc-text">插入操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C"><span class="toc-number">5.9.4.4.</span> <span class="toc-text">删除操作</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-bitmap-%E7%BB%9F%E8%AE%A1%E6%B4%BB%E8%B7%83%E7%94%A8%E6%88%B7"><span class="toc-number">5.10.</span> <span class="toc-text">使用 Bitmap 统计活跃用户</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-hyperloglog-%E7%BB%9F%E8%AE%A1%E9%A1%B5%E9%9D%A2-uv%E7%8B%AC%E7%AB%8B%E8%AE%BF%E5%AE%A2"><span class="toc-number">5.11.</span> <span class="toc-text">使用 HyperLogLog 统计页面 UV（独立访客）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6"><span class="toc-number">6.</span> <span class="toc-text">🌟Redis 持久化机制</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">6.1.</span> <span class="toc-text">持久化基本原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rdb-%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">6.2.</span> <span class="toc-text">RDB 持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rdb-%E7%AE%80%E4%BB%8B"><span class="toc-number">6.2.1.</span> <span class="toc-text">RDB 简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rdb-%E5%BF%AB%E7%85%A7%E7%9A%84%E8%A7%A6%E5%8F%91%E6%96%B9%E5%BC%8F"><span class="toc-number">6.2.2.</span> <span class="toc-text">RDB 快照的触发方式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8-save-%E5%91%BD%E4%BB%A4"><span class="toc-number">6.2.2.1.</span> <span class="toc-text">手动 save 命令</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8-bgsave-%E5%91%BD%E4%BB%A4"><span class="toc-number">6.2.2.2.</span> <span class="toc-text">手动 bgsave 命令</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E6%9D%A1%E4%BB%B6%E8%A7%A6%E5%8F%91"><span class="toc-number">6.2.2.3.</span> <span class="toc-text">自动条件触发</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rdb-%E6%8C%81%E4%B9%85%E5%8C%96%E8%BF%87%E7%A8%8B%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">6.2.3.</span> <span class="toc-text">RDB 持久化过程（工作机制）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rdb-%E9%85%8D%E7%BD%AE%E9%A1%B9"><span class="toc-number">6.2.4.</span> <span class="toc-text">RDB 配置项</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rdb-%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84"><span class="toc-number">6.2.5.</span> <span class="toc-text">RDB 文件结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rdb-%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">6.2.6.</span> <span class="toc-text">RDB 优缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E7%A6%81%E7%94%A8-rdb"><span class="toc-number">6.2.7.</span> <span class="toc-text">如何禁用 RDB</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D-rdb-%E6%96%87%E4%BB%B6"><span class="toc-number">6.2.8.</span> <span class="toc-text">如何恢复 RDB 文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rdb-%E5%B0%8F%E7%BB%93"><span class="toc-number">6.2.9.</span> <span class="toc-text">RDB 小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#aof-%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">6.3.</span> <span class="toc-text">AOF 持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#aof-%E7%AE%80%E4%BB%8B"><span class="toc-number">6.3.1.</span> <span class="toc-text">AOF 简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aof-%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F"><span class="toc-number">6.3.2.</span> <span class="toc-text">AOF 文件格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aof-%E9%85%8D%E7%BD%AE%E9%A1%B9"><span class="toc-number">6.3.3.</span> <span class="toc-text">AOF 配置项</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aof-%E6%8C%81%E4%B9%85%E5%8C%96%E8%BF%87%E7%A8%8B%E5%B7%A5%E4%BD%9C%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><span class="toc-number">6.3.4.</span> <span class="toc-text">AOF 持久化过程（工作基本流程）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aof-%E7%BC%93%E5%86%B2%E5%8C%BA%E7%9A%84%E4%B8%89%E7%A7%8D%E5%86%99%E5%9B%9E%E5%88%B7%E7%9B%98%E7%AD%96%E7%95%A5fsync-%E7%AD%96%E7%95%A5"><span class="toc-number">6.3.5.</span> <span class="toc-text">AOF 缓冲区的三种写回 &#x2F; 刷盘策略（ fsync 策略）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aof-%E9%87%8D%E5%86%99%E6%9C%BA%E5%88%B6rewrite"><span class="toc-number">6.3.6.</span> <span class="toc-text">🌟AOF 重写机制（Rewrite）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%95%E4%B8%BA-rewrite"><span class="toc-number">6.3.6.1.</span> <span class="toc-text">何为 rewrite</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#rewrite-%E8%A7%A6%E5%8F%91%E6%96%B9%E5%BC%8F"><span class="toc-number">6.3.6.2.</span> <span class="toc-text">rewrite 触发方式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#rewrite-%E5%8E%9F%E7%90%86"><span class="toc-number">6.3.6.3.</span> <span class="toc-text">rewrite 原理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aof-%E6%A0%A1%E9%AA%8C%E6%9C%BA%E5%88%B6"><span class="toc-number">6.3.7.</span> <span class="toc-text">AOF 校验机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aof-%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97%E8%BF%87%E7%A8%8B"><span class="toc-number">6.3.8.</span> <span class="toc-text">AOF 记录日志过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aof-%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">6.3.9.</span> <span class="toc-text">AOF 优缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aof-%E5%B0%8F%E7%BB%93"><span class="toc-number">6.3.10.</span> <span class="toc-text">AOF 小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rdb-aof-%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">6.4.</span> <span class="toc-text">RDB-AOF 混合持久化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rdb-%E4%B8%8E-aof-%E5%AF%B9%E6%AF%94%E6%8C%81%E4%B9%85%E5%8C%96%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B"><span class="toc-number">6.5.</span> <span class="toc-text">🌟RDB 与 AOF 对比（持久化技术选型）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%AF%E7%BC%93%E5%AD%98%E6%A8%A1%E5%BC%8F"><span class="toc-number">6.6.</span> <span class="toc-text">纯缓存模式</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E7%BA%BF%E7%A8%8Bio%E6%A8%A1%E5%9E%8B"><span class="toc-number">7.</span> <span class="toc-text">Redis 线程（IO）模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">7.1.</span> <span class="toc-text">单线程模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">7.2.</span> <span class="toc-text">混合线程模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">7.3.</span> <span class="toc-text">多线程模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93"><span class="toc-number">7.4.</span> <span class="toc-text">优缺点总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-60-%E4%B9%8B%E5%89%8D%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E4%BD%BF%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-number">7.5.</span> <span class="toc-text">Redis 6.0 之前为什么不使用多线程？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis60-%E4%B9%8B%E5%90%8E%E4%B8%BA%E4%BD%95%E5%BC%95%E5%85%A5%E4%BA%86%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-number">7.6.</span> <span class="toc-text">Redis6.0 之后为何引入了多线程？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B%E4%BA%86%E8%A7%A3%E5%90%97"><span class="toc-number">7.7.</span> <span class="toc-text">Redis 后台线程了解吗？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86"><span class="toc-number">8.</span> <span class="toc-text">Redis 内存管理（缓存数据管理）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E7%BB%99%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E8%AE%BE%E7%BD%AE%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%E7%9A%84%E6%84%8F%E4%B9%89"><span class="toc-number">8.1.</span> <span class="toc-text">Redis 给缓存数据设置过期时间的意义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%87%E6%9C%9F%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%A4%E6%96%AD"><span class="toc-number">8.2.</span> <span class="toc-text">过期数据的判断</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%87%E6%9C%9F%E7%9A%84%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5"><span class="toc-number">8.3.</span> <span class="toc-text">过期的数据的删除策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6"><span class="toc-number">8.4.</span> <span class="toc-text">🌟Redis 内存淘汰机制</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E4%BA%8B%E5%8A%A1"><span class="toc-number">9.</span> <span class="toc-text">Redis 事务</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">9.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="toc-number">9.2.</span> <span class="toc-text">常用命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E6%80%A7"><span class="toc-number">9.3.</span> <span class="toc-text">特性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E5%85%B7%E5%A4%87%E5%8E%9F%E5%AD%90%E6%80%A7a"><span class="toc-number">9.3.1.</span> <span class="toc-text">不具备原子性（A）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E4%BA%86%E7%AE%80%E5%8D%95%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7i"><span class="toc-number">9.3.2.</span> <span class="toc-text">实现了简单的隔离性（I）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E6%B3%95%E4%BF%9D%E8%AF%81%E6%8C%81%E4%B9%85%E6%80%A7d"><span class="toc-number">9.3.3.</span> <span class="toc-text">无法保证持久性（D）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86"><span class="toc-number">9.4.</span> <span class="toc-text">异常处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%AD%E6%B3%95%E9%94%99%E8%AF%AF"><span class="toc-number">9.4.1.</span> <span class="toc-text">语法错误</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E5%BC%82%E5%B8%B8"><span class="toc-number">9.4.2.</span> <span class="toc-text">执行异常</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%94%E7%A6%BB%E6%9C%BA%E5%88%B6"><span class="toc-number">9.5.</span> <span class="toc-text">隔离机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E9%9A%94%E7%A6%BB%E6%9C%BA%E5%88%B6"><span class="toc-number">9.5.1.</span> <span class="toc-text">为什么需要隔离机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%94%E7%A6%BB%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">9.5.2.</span> <span class="toc-text">隔离的实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">9.5.3.</span> <span class="toc-text">🌟实现原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis%E4%BA%8B%E5%8A%A1-vs-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1"><span class="toc-number">9.6.</span> <span class="toc-text">Redis 事务 v.s 数据库事务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3-redis-%E4%BA%8B%E5%8A%A1%E7%9A%84%E7%BC%BA%E9%99%B7"><span class="toc-number">9.7.</span> <span class="toc-text">如何解决 Redis 事务的缺陷</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E7%AE%A1%E9%81%93pipeline"><span class="toc-number">10.</span> <span class="toc-text">Redis 管道（pipeline）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-number">10.1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B-2"><span class="toc-number">10.2.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B"><span class="toc-number">10.3.</span> <span class="toc-text">案例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">10.4.</span> <span class="toc-text">总结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%A1%E9%81%93-vs-%E5%8E%9F%E7%94%9F%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4"><span class="toc-number">10.4.1.</span> <span class="toc-text">管道 vs 原生批量操作命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%A1%E9%81%93-vs-redis-%E4%BA%8B%E5%8A%A1"><span class="toc-number">10.4.2.</span> <span class="toc-text">管道 vs Redis 事务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%AE%A1%E9%81%93%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">10.4.3.</span> <span class="toc-text">使用管道的注意事项</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96"><span class="toc-number">11.</span> <span class="toc-text">🌟Redis 性能优化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C%E5%87%8F%E5%B0%91%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93"><span class="toc-number">11.1.</span> <span class="toc-text">使用批量操作减少网络传输</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%9F%E7%94%9F%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4"><span class="toc-number">11.1.1.</span> <span class="toc-text">原生批量操作命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%A1%E9%81%93pipeline"><span class="toc-number">11.1.2.</span> <span class="toc-text">管道（pipeline）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lua-%E8%84%9A%E6%9C%AC"><span class="toc-number">11.1.3.</span> <span class="toc-text">Lua 脚本</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E9%87%8F-key-%E9%9B%86%E4%B8%AD%E8%BF%87%E6%9C%9F%E9%97%AE%E9%A2%98"><span class="toc-number">11.2.</span> <span class="toc-text">大量 key 集中过期问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#bigkey%E5%A4%A7-key"><span class="toc-number">11.3.</span> <span class="toc-text">🌟bigkey（大 Key）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#bigkey-%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">11.3.1.</span> <span class="toc-text">bigkey 是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bigkey-%E6%80%8E%E4%B9%88%E4%BA%A7%E7%94%9F%E7%9A%84"><span class="toc-number">11.3.2.</span> <span class="toc-text">bigkey 怎么产生的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bigkey-%E7%9A%84%E5%8D%B1%E5%AE%B3"><span class="toc-number">11.3.3.</span> <span class="toc-text">bigkey 的危害</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%8F%91%E7%8E%B0-bigkey"><span class="toc-number">11.3.4.</span> <span class="toc-text">如何发现 bigkey</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86-bigkey"><span class="toc-number">11.3.5.</span> <span class="toc-text">如何处理 bigkey</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hotkey%E7%83%AD-key"><span class="toc-number">11.4.</span> <span class="toc-text">hotkey（热 Key）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#hotkey-%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">11.4.1.</span> <span class="toc-text">hotkey 是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hotkey-%E7%9A%84%E5%8D%B1%E5%AE%B3"><span class="toc-number">11.4.2.</span> <span class="toc-text">hotkey 的危害</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%8F%91%E7%8E%B0-hotkey"><span class="toc-number">11.4.3.</span> <span class="toc-text">如何发现 hotkey</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3-hotkey"><span class="toc-number">11.4.4.</span> <span class="toc-text">如何解决 hotkey</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%85%A2%E6%9F%A5%E8%AF%A2%E5%91%BD%E4%BB%A4"><span class="toc-number">11.5.</span> <span class="toc-text">慢查询命令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%85%A2%E6%9F%A5%E8%AF%A2%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0"><span class="toc-number">11.5.1.</span> <span class="toc-text">慢查询命令的产生原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%8F%91%E7%8E%B0%E6%85%A2%E6%9F%A5%E8%AF%A2%E5%91%BD%E4%BB%A4"><span class="toc-number">11.5.2.</span> <span class="toc-text">如何发现慢查询命令</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87"><span class="toc-number">11.6.</span> <span class="toc-text">Redis 内存碎片</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">11.6.1.</span> <span class="toc-text">内存碎片是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redis-%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%E7%9A%84%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0"><span class="toc-number">11.6.2.</span> <span class="toc-text">Redis 内存碎片的产生原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B-redis-%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%E7%9A%84%E4%BF%A1%E6%81%AF"><span class="toc-number">11.6.3.</span> <span class="toc-text">如何查看 Redis 内存碎片的信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%B8%85%E7%90%86-redis-%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87"><span class="toc-number">11.6.4.</span> <span class="toc-text">如何清理 Redis 内存碎片？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E9%AB%98%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98"><span class="toc-number">12.</span> <span class="toc-text">🌟Redis 生产问题（高并发问题）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F"><span class="toc-number">12.1.</span> <span class="toc-text">缓存穿透</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88-5"><span class="toc-number">12.1.1.</span> <span class="toc-text">是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3"><span class="toc-number">12.1.2.</span> <span class="toc-text">如何解决</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E7%BC%93%E5%AD%98%E6%97%A0%E6%95%88-key"><span class="toc-number">12.1.2.1.</span> <span class="toc-text">1）缓存无效 key</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8"><span class="toc-number">12.1.2.2.</span> <span class="toc-text">2）布隆过滤器</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF"><span class="toc-number">12.2.</span> <span class="toc-text">缓存击穿</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88-6"><span class="toc-number">12.2.1.</span> <span class="toc-text">是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3-2"><span class="toc-number">12.2.2.</span> <span class="toc-text">如何解决</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E4%B8%8E%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">12.2.3.</span> <span class="toc-text">缓存穿透与缓存击穿的区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9"><span class="toc-number">12.3.</span> <span class="toc-text">缓存雪崩</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88-7"><span class="toc-number">12.3.1.</span> <span class="toc-text">是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3-3"><span class="toc-number">12.3.2.</span> <span class="toc-text">如何解决</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E4%B8%8E%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">12.3.3.</span> <span class="toc-text">缓存雪崩与缓存击穿的区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7"><span class="toc-number">12.4.</span> <span class="toc-text">如何保证缓存和数据库数据的一致性？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E9%98%BB%E5%A1%9E%E7%9A%84%E5%B8%B8%E8%A7%81%E5%8E%9F%E5%9B%A0"><span class="toc-number">12.5.</span> <span class="toc-text">Redis 阻塞的常见原因</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#on-%E5%91%BD%E4%BB%A4"><span class="toc-number">12.5.1.</span> <span class="toc-text">O (n) 命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#save-%E5%88%9B%E5%BB%BA-rdb-%E5%BF%AB%E7%85%A7"><span class="toc-number">12.5.2.</span> <span class="toc-text">SAVE 创建 RDB 快照</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aof"><span class="toc-number">12.5.3.</span> <span class="toc-text">AOF</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#aof-%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E9%98%BB%E5%A1%9E"><span class="toc-number">12.5.3.1.</span> <span class="toc-text">AOF 日志记录阻塞</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#aof-%E5%88%B7%E7%9B%98%E9%98%BB%E5%A1%9E"><span class="toc-number">12.5.3.2.</span> <span class="toc-text">AOF 刷盘阻塞</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#aof-%E9%87%8D%E5%86%99%E9%98%BB%E5%A1%9E"><span class="toc-number">12.5.3.3.</span> <span class="toc-text">AOF 重写阻塞</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bigkey"><span class="toc-number">12.5.4.</span> <span class="toc-text">bigkey</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E6%89%BE-bigkey"><span class="toc-number">12.5.4.1.</span> <span class="toc-text">查找 bigkey</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A0%E9%99%A4-bigkey"><span class="toc-number">12.5.4.2.</span> <span class="toc-text">删除 bigkey</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B8%85%E7%A9%BA%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">12.5.5.</span> <span class="toc-text">清空数据库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%89%A9%E5%AE%B9-%E7%BC%A9%E5%AE%B9"><span class="toc-number">12.5.6.</span> <span class="toc-text">集群扩容、缩容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#swap%E5%86%85%E5%AD%98%E4%BA%A4%E6%8D%A2"><span class="toc-number">12.5.7.</span> <span class="toc-text">Swap（内存交换）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cpu-%E7%AB%9E%E4%BA%89"><span class="toc-number">12.5.8.</span> <span class="toc-text">CPU 竞争</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98"><span class="toc-number">12.5.9.</span> <span class="toc-text">网络问题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85pubsub"><span class="toc-number">13.</span> <span class="toc-text">Redis 发布订阅（pub&#x2F;sub）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F"><span class="toc-number">13.1.</span> <span class="toc-text">消息系统</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pubsub-%E7%AE%80%E4%BB%8B"><span class="toc-number">13.2.</span> <span class="toc-text">pub&#x2F;sub 简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4"><span class="toc-number">13.3.</span> <span class="toc-text">相关命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9-4"><span class="toc-number">13.4.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#redis-%E9%9B%86%E7%BE%A4%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="toc-number">14.</span> <span class="toc-text">🌟Redis 集群（高可用）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6replica"><span class="toc-number">14.1.</span> <span class="toc-text">主从复制（replica）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88-8"><span class="toc-number">14.1.1.</span> <span class="toc-text">是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8"><span class="toc-number">14.1.2.</span> <span class="toc-text">作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4"><span class="toc-number">14.1.3.</span> <span class="toc-text">基本命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%843%E6%8B%9B"><span class="toc-number">14.1.4.</span> <span class="toc-text">常用的 3 招</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E4%B8%BB%E4%BA%8C%E4%BB%8E"><span class="toc-number">14.1.4.1.</span> <span class="toc-text">一主二从</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B9%E6%A1%881%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%9B%BA%E5%AE%9A%E5%86%99%E6%AD%BB"><span class="toc-number">14.1.4.1.1.</span> <span class="toc-text">方案 1：配置文件固定写死</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E9%97%AE%E9%A2%98%E6%BC%94%E7%A4%BA"><span class="toc-number">14.1.4.1.2.</span> <span class="toc-text">主从复制问题演示</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B9%E6%A1%882%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C%E6%89%8B%E5%8A%A8%E6%8C%87%E5%AE%9A"><span class="toc-number">14.1.4.1.3.</span> <span class="toc-text">方案 2：命令操作手动指定</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-vs-%E5%91%BD%E4%BB%A4"><span class="toc-number">14.1.4.1.4.</span> <span class="toc-text">配置 vs 命令</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%96%AA%E7%81%AB%E7%9B%B8%E4%BC%A0"><span class="toc-number">14.1.4.2.</span> <span class="toc-text">薪火相传</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E7%AB%8B%E4%B8%BA%E7%8E%8B"><span class="toc-number">14.1.4.3.</span> <span class="toc-text">自立为王</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%B8%BB%E4%BA%8C%E4%BB%8E%E7%9A%84%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="toc-number">14.1.5.</span> <span class="toc-text">一主二从的案例演示</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84%E8%AF%B4%E6%98%8E"><span class="toc-number">14.1.5.1.</span> <span class="toc-text">架构说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%A3%E8%AF%80"><span class="toc-number">14.1.5.2.</span> <span class="toc-text">口诀</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E6%93%8D%E4%BD%9C%E7%BB%86%E8%8A%82"><span class="toc-number">14.1.5.3.</span> <span class="toc-text">修改配置文件的操作细节</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%9F%E7%90%86%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">14.1.6.</span> <span class="toc-text">🌟原理（工作流程）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%BA%A7%E7%AE%A1%E7%90%86"><span class="toc-number">14.1.7.</span> <span class="toc-text">分级管理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%B9%E7%81%BE%E5%86%B7%E5%A4%84%E7%90%86"><span class="toc-number">14.1.8.</span> <span class="toc-text">容灾冷处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9-5"><span class="toc-number">14.1.9.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6sentinel"><span class="toc-number">14.2.</span> <span class="toc-text">哨兵机制（sentinel）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88-9"><span class="toc-number">14.2.1.</span> <span class="toc-text">是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8-2"><span class="toc-number">14.2.2.</span> <span class="toc-text">作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sentinel-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6sentinelconf"><span class="toc-number">14.2.3.</span> <span class="toc-text">Sentinel 配置文件（sentinel.conf）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="toc-number">14.2.4.</span> <span class="toc-text">案例演示</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84%E8%AF%B4%E6%98%8E-2"><span class="toc-number">14.2.4.1.</span> <span class="toc-text">架构说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E"><span class="toc-number">14.2.4.2.</span> <span class="toc-text">配置说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%88%E6%B5%8B%E8%AF%95%E6%AD%A3%E5%B8%B8%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6"><span class="toc-number">14.2.4.3.</span> <span class="toc-text">先测试正常的主从复制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sentinel-%E6%9D%A5%E4%BA%86"><span class="toc-number">14.2.4.4.</span> <span class="toc-text">Sentinel 来了！</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BD%93-master-%E6%8C%82%E4%BA%86"><span class="toc-number">14.2.4.5.</span> <span class="toc-text">当 master 挂了！</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E6%96%B0%E8%80%81master%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">14.2.4.6.</span> <span class="toc-text">对比新老 master 的配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E5%A4%87%E6%B3%A8"><span class="toc-number">14.2.4.7.</span> <span class="toc-text">其他备注</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sentinel-%E5%8E%9F%E7%90%86"><span class="toc-number">14.2.5.</span> <span class="toc-text">🌟Sentinel 原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E4%B8%AA%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1"><span class="toc-number">14.2.5.1.</span> <span class="toc-text">三个定时任务</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#redis-%E8%8A%82%E7%82%B9%E4%B8%8B%E7%BA%BFdown%E5%88%A4%E6%96%AD"><span class="toc-number">14.2.5.2.</span> <span class="toc-text">Redis 节点下线（DOWN）判断</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BB%E8%A7%82%E4%B8%8B%E7%BA%BFsubjectively-down"><span class="toc-number">14.2.5.2.1.</span> <span class="toc-text">主观下线（Subjectively DOWN）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%A2%E8%A7%82%E4%B8%8B%E7%BA%BFobjectively-down"><span class="toc-number">14.2.5.2.2.</span> <span class="toc-text">客观下线（Objectively DOWN）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sentinel-leader-%E9%80%89%E4%B8%BEraft-%E7%AE%97%E6%B3%95"><span class="toc-number">14.2.5.3.</span> <span class="toc-text">Sentinel Leader 选举（Raft 算法）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#master-%E9%80%89%E4%B8%BE"><span class="toc-number">14.2.5.4.</span> <span class="toc-text">Master 选举</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BBfailover%E6%B5%81%E7%A8%8B"><span class="toc-number">14.2.5.5.</span> <span class="toc-text">故障转移（failover）流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#redis-%E8%8A%82%E7%82%B9%E4%B8%8A%E7%BA%BF"><span class="toc-number">14.2.5.6.</span> <span class="toc-text">Redis 节点上线</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8E%9F%E8%8A%82%E7%82%B9%E4%B8%8A%E7%BA%BF"><span class="toc-number">14.2.5.6.1.</span> <span class="toc-text">原节点上线</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B0%E8%8A%82%E7%82%B9%E4%B8%8A%E7%BA%BF"><span class="toc-number">14.2.5.6.2.</span> <span class="toc-text">新节点上线</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#sentinel-%E8%8A%82%E7%82%B9%E4%B8%8A%E7%BA%BF"><span class="toc-number">14.2.5.6.3.</span> <span class="toc-text">Sentinel 节点上线</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sentinel-%E4%BD%BF%E7%94%A8%E5%BB%BA%E8%AE%AE"><span class="toc-number">14.2.6.</span> <span class="toc-text">Sentinel 使用建议</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4cluster"><span class="toc-number">14.3.</span> <span class="toc-text">分布式系统 &#x2F; 切片集群（cluster）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%B2%E7%BB%8F%E6%9C%89%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-sentinel%E4%BA%86%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E9%9C%80%E8%A6%81-redis-cluster"><span class="toc-number">14.3.1.</span> <span class="toc-text">已经有主从复制、Sentinel 了，为什么还需要 Redis Cluster？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88-10"><span class="toc-number">14.3.2.</span> <span class="toc-text">是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8-3"><span class="toc-number">14.3.3.</span> <span class="toc-text">作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84"><span class="toc-number">14.3.4.</span> <span class="toc-text">最基本架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87%E7%AE%97%E6%B3%95"><span class="toc-number">14.3.5.</span> <span class="toc-text">🌟数据分片算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%93%88%E5%B8%8C%E5%8F%96%E4%BD%99-%E5%88%86%E5%8C%BA%E7%AE%97%E6%B3%95"><span class="toc-number">14.3.5.1.</span> <span class="toc-text">哈希取余 分区算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C-%E5%88%86%E5%8C%BA%E7%AE%97%E6%B3%95"><span class="toc-number">14.3.5.2.</span> <span class="toc-text">一致性哈希 分区算法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3"><span class="toc-number">14.3.5.2.1.</span> <span class="toc-text">设计思想</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3%E5%A4%A7%E6%AD%A5%E9%AA%A4"><span class="toc-number">14.3.5.2.2.</span> <span class="toc-text">3 大步骤</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">14.3.5.2.3.</span> <span class="toc-text">优缺点</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%93%88%E5%B8%8C%E6%A7%BDslot-%E5%88%86%E5%8C%BA%E7%AE%97%E6%B3%95"><span class="toc-number">14.3.5.3.</span> <span class="toc-text">🌟哈希槽 (slot) 分区算法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3javaguide"><span class="toc-number">14.3.5.3.1.</span> <span class="toc-text">设计思想（JavaGuide）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3-2"><span class="toc-number">14.3.5.3.2.</span> <span class="toc-text">设计思想</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%93%88%E5%B8%8C%E6%A7%BD%E7%9A%84%E6%95%B0%E9%87%8F%E6%98%AF16384%E4%B8%AA"><span class="toc-number">14.3.5.3.3.</span> <span class="toc-text">为什么哈希槽的数量是 16384 个？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%93%8D%E4%BD%9C%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="toc-number">14.3.6.</span> <span class="toc-text">集群操作（案例演示）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84%E8%AF%B4%E6%98%8E"><span class="toc-number">14.3.6.1.</span> <span class="toc-text">集群架构说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA"><span class="toc-number">14.3.6.2.</span> <span class="toc-text">集群搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84"><span class="toc-number">14.3.6.2.1.</span> <span class="toc-text">集群架构</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%87%E4%BB%B6"><span class="toc-number">14.3.6.2.2.</span> <span class="toc-text">删除持久化文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95"><span class="toc-number">14.3.6.2.3.</span> <span class="toc-text">创建目录</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A4%8D%E5%88%B62%E4%B8%AA%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">14.3.6.2.4.</span> <span class="toc-text">复制 2 个配置文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9-redisconf"><span class="toc-number">14.3.6.2.5.</span> <span class="toc-text">修改 redis.conf</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9-redis6380conf"><span class="toc-number">14.3.6.2.6.</span> <span class="toc-text">修改 redis6380.conf</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A4%8D%E5%88%B65%E4%B8%AA%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">14.3.6.2.7.</span> <span class="toc-text">复制 5 个配置文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BF%AE%E6%94%B95%E4%B8%AA%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">14.3.6.2.8.</span> <span class="toc-text">修改 5 个配置文件</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E4%B8%8E%E5%85%B3%E9%97%AD"><span class="toc-number">14.3.6.3.</span> <span class="toc-text">集群启动与关闭</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E8%8A%82%E7%82%B9"><span class="toc-number">14.3.6.3.1.</span> <span class="toc-text">启动节点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%9B%86%E7%BE%A4"><span class="toc-number">14.3.6.3.2.</span> <span class="toc-text">创建集群</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E9%9B%86%E7%BE%A4"><span class="toc-number">14.3.6.3.3.</span> <span class="toc-text">测试集群</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%B3%E9%97%AD%E9%9B%86%E7%BE%A4"><span class="toc-number">14.3.6.3.4.</span> <span class="toc-text">关闭集群</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9E%E6%8E%A5%E9%9B%86%E7%BE%A4"><span class="toc-number">14.3.6.4.</span> <span class="toc-text">连接集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">14.3.6.5.</span> <span class="toc-text">写入数据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#key-%E5%8D%95%E4%B8%AA%E5%86%99%E5%85%A5"><span class="toc-number">14.3.6.5.1.</span> <span class="toc-text">key 单个写入</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#key-%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C"><span class="toc-number">14.3.6.5.2.</span> <span class="toc-text">key 批量操作</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%9F%A5%E8%AF%A2"><span class="toc-number">14.3.6.6.</span> <span class="toc-text">集群查询</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2-key-%E7%9A%84-slot"><span class="toc-number">14.3.6.6.1.</span> <span class="toc-text">查询 key 的 slot</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2-slot-%E4%B8%AD-key-%E7%9A%84%E6%95%B0%E9%87%8F"><span class="toc-number">14.3.6.6.2.</span> <span class="toc-text">查询 slot 中 key 的数量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2-slot-%E4%B8%AD%E7%9A%84-key"><span class="toc-number">14.3.6.6.3.</span> <span class="toc-text">查询 slot 中的 key</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BBfailover"><span class="toc-number">14.3.6.7.</span> <span class="toc-text">故障转移（failover）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A8%A1%E6%8B%9F%E6%95%85%E9%9A%9C"><span class="toc-number">14.3.6.7.1.</span> <span class="toc-text">模拟故障</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%A8%E8%A6%86%E7%9B%96%E9%9C%80%E6%B1%82"><span class="toc-number">14.3.6.7.2.</span> <span class="toc-text">全覆盖需求</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%89%A9%E5%AE%B9"><span class="toc-number">14.3.6.8.</span> <span class="toc-text">集群扩容</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6%E5%B9%B6%E4%BF%AE%E6%94%B9-2-%E4%B8%AA%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">14.3.6.8.1.</span> <span class="toc-text">复制并修改 2 个配置文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E7%B3%BB%E7%BB%9F%E4%B8%8E-2-%E4%B8%AA%E8%8A%82%E7%82%B9"><span class="toc-number">14.3.6.8.2.</span> <span class="toc-text">启动系统与 2 个节点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0-master-%E8%8A%82%E7%82%B9"><span class="toc-number">14.3.6.8.3.</span> <span class="toc-text">添加 master 节点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%86%E9%85%8D-slot"><span class="toc-number">14.3.6.8.4.</span> <span class="toc-text">分配 slot</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0-slave-%E8%8A%82%E7%82%B9"><span class="toc-number">14.3.6.8.5.</span> <span class="toc-text">添加 slave 节点</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E7%BC%A9%E5%AE%B9"><span class="toc-number">14.3.6.9.</span> <span class="toc-text">集群缩容</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%A0%E9%99%A4-slave-%E8%8A%82%E7%82%B9"><span class="toc-number">14.3.6.9.1.</span> <span class="toc-text">删除 slave 节点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%A7%BB%E5%87%BA-master-%E7%9A%84-slot"><span class="toc-number">14.3.6.9.2.</span> <span class="toc-text">移出 master 的 slot</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%A0%E9%99%A4-master-%E8%8A%82%E7%82%B9"><span class="toc-number">14.3.6.9.3.</span> <span class="toc-text">删除 master 节点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">14.3.7.</span> <span class="toc-text">局限性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redis-cluster-%E5%9C%A8%E6%89%A9%E5%AE%B9%E7%BC%A9%E5%AE%B9%E6%9C%9F%E9%97%B4%E5%8F%AF%E4%BB%A5%E6%8F%90%E4%BE%9B%E6%9C%8D%E5%8A%A1%E5%90%97"><span class="toc-number">14.3.8.</span> <span class="toc-text">Redis Cluster 在扩容 &#x2F; 缩容期间可以提供服务吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cap-%E5%AE%9A%E7%90%86"><span class="toc-number">14.3.9.</span> <span class="toc-text">CAP 定理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5"><span class="toc-number">14.3.9.1.</span> <span class="toc-text">概念</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E7%90%86"><span class="toc-number">14.3.9.2.</span> <span class="toc-text">定理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#base-%E7%90%86%E8%AE%BA"><span class="toc-number">14.3.9.3.</span> <span class="toc-text">BASE 理论</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#cap-%E5%BA%94%E7%94%A8"><span class="toc-number">14.3.9.4.</span> <span class="toc-text">CAP 应用</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#zookeepercp-%E6%A8%A1%E5%BC%8F"><span class="toc-number">14.3.9.4.1.</span> <span class="toc-text">Zookeeper：CP 模式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#consulcp-%E6%A8%A1%E5%BC%8F"><span class="toc-number">14.3.9.4.2.</span> <span class="toc-text">Consul：CP 模式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#redisap-%E6%A8%A1%E5%BC%8F"><span class="toc-number">14.3.9.4.3.</span> <span class="toc-text">Redis：AP 模式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#eurekaap-%E6%A8%A1%E5%BC%8F"><span class="toc-number">14.3.9.4.4.</span> <span class="toc-text">Eureka：AP 模式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#nacosap-%E6%A8%A1%E5%BC%8F"><span class="toc-number">14.3.9.4.5.</span> <span class="toc-text">Nacos：AP 模式</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83"><span class="toc-number">15.</span> <span class="toc-text">使用规范</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lua-%E8%84%9A%E6%9C%AC-2"><span class="toc-number">16.</span> <span class="toc-text">Lua 脚本</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-number">17.</span> <span class="toc-text">分布式锁</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%EF%B8%8F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="toc-number">18.</span> <span class="toc-text">⭐️重要知识点</span></a></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li class="active"><a href="/database/redis/Redis-JavaGuide/" rel="bookmark" title="Redis-JavaGuide">Redis-JavaGuide</a></li><li><a href="/database/redis/%E5%B0%9A%E7%A1%85%E8%B0%B7-%E5%91%A8%E9%98%B3-Redis7/" rel="bookmark" title="Redis7-尚硅谷-周阳">Redis7-尚硅谷-周阳</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="范特东东东" data-src="/images/avatar.jpg"><p class="name" itemprop="name">范特东东东</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">61</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">19</span> <span class="name">分类</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hqeDE1OQ==" title="https:&#x2F;&#x2F;github.com&#x2F;hjx159"><i class="ic i-github"></i></span> <span class="exturl item xiaohongshu" data-url="aHR0cHM6Ly93d3cueGlhb2hvbmdzaHUuY29tL3VzZXIvcHJvZmlsZS81ZTAyYzhhZDAwMDAwMDAwMDEwMDFmM2U=" title="https:&#x2F;&#x2F;www.xiaohongshu.com&#x2F;user&#x2F;profile&#x2F;5e02c8ad0000000001001f3e"><i class="ic i-xiaohongshu2"></i></span> <span class="exturl item email" data-url="bWFpbHRvOjgxMjE0MzI4MEBxcS5jb20=" title="mailto:812143280@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/categories/photography/" rel="section"><i class="ic i-photography"></i>摄影</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于我</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/database/mysql/MySQL-JavaGuide/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/database/elasticsearch/Elasticsearch-JavaGuide/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-excise/" title="分类于 Java基础-真题">Java基础-真题</a></div><span><a href="/java/java-se/java-excise/%E7%AC%AC13%E7%AB%A0%EF%BC%9A%E9%9A%8F%E5%A0%82%E5%A4%8D%E4%B9%A0%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%9C%9F%E9%A2%98%EF%BC%88%E6%B3%9B%E5%9E%8B%EF%BC%89/" title="宋红康_第13章：泛型">宋红康_第13章：泛型</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-knowledge/" title="分类于 Java基础-知识点">Java基础-知识点</a></div><span><a href="/java/java-se/java-knowledge/%E5%B0%9A%E7%A1%85%E8%B0%B7_%E5%AE%8B%E7%BA%A2%E5%BA%B7_%E7%AC%AC10%E7%AB%A0_%E5%A4%9A%E7%BA%BF%E7%A8%8B/" title="宋红康_第10章_多线程">宋红康_第10章_多线程</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-knowledge/" title="分类于 Java基础-知识点">Java基础-知识点</a></div><span><a href="/java/java-se/java-knowledge/%E5%B0%9A%E7%A1%85%E8%B0%B7_%E5%AE%8B%E7%BA%A2%E5%BA%B7_%E7%AC%AC08%E7%AB%A0_%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%EF%BC%88%E9%AB%98%E7%BA%A7%EF%BC%89/" title="宋红康_第08章_面向对象编程(高级)">宋红康_第08章_面向对象编程(高级)</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/database/" title="分类于 数据库">数据库</a> <i class="ic i-angle-right"></i> <a href="/categories/database/redis/" title="分类于 Redis">Redis</a></div><span><a href="/database/redis/Redis-JavaGuide/" title="Redis-JavaGuide">Redis-JavaGuide</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-knowledge/" title="分类于 Java基础-知识点">Java基础-知识点</a></div><span><a href="/java/java-se/java-knowledge/%E5%B0%9A%E7%A1%85%E8%B0%B7_%E5%AE%8B%E7%BA%A2%E5%BA%B7_%E7%AC%AC16%E7%AB%A0_%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" title="宋红康_第16章_网络编程">宋红康_第16章_网络编程</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-excise/" title="分类于 Java基础-真题">Java基础-真题</a></div><span><a href="/java/java-se/java-excise/%E7%AC%AC01%E7%AB%A0%EF%BC%9A%E9%9A%8F%E5%A0%82%E5%A4%8D%E4%B9%A0%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%9C%9F%E9%A2%98%EF%BC%88Java%E8%AF%AD%E8%A8%80%E6%A6%82%E8%BF%B0%EF%BC%89/" title="宋红康_第01章：Java语言概述">宋红康_第01章：Java语言概述</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/photography/" title="分类于 摄影">摄影</a></div><span><a href="/photography/%E8%93%9D%E4%B8%8E%E9%BB%84/" title="蓝与黄">蓝与黄</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/juc/" title="分类于 JUC">JUC</a></div><span><a href="/java/juc/JUC%E7%AC%94%E8%AE%B0/" title="JUC 笔记">JUC 笔记</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-excise/" title="分类于 Java基础-真题">Java基础-真题</a></div><span><a href="/java/java-se/java-excise/%E7%AC%AC08%E7%AB%A0%EF%BC%9A%E9%9A%8F%E5%A0%82%E5%A4%8D%E4%B9%A0%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%9C%9F%E9%A2%98%EF%BC%88%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1-%E9%AB%98%E7%BA%A7%EF%BC%89/" title="宋红康_第08章：面向对象-高级">宋红康_第08章：面向对象-高级</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-knowledge/" title="分类于 Java基础-知识点">Java基础-知识点</a></div><span><a href="/java/java-se/java-knowledge/%E5%B0%9A%E7%A1%85%E8%B0%B7_%E5%AE%8B%E7%BA%A2%E5%BA%B7_%E7%AC%AC03%E7%AB%A0_%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%E8%AF%AD%E5%8F%A5/" title="宋红康_第03章_流程控制语句">宋红康_第03章_流程控制语句</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">范特东东东 @ fantedong</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">1.9m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">28:35</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"database/redis/Redis-JavaGuide/",favicon:{show:"(●´3｀●)欢迎回来",hide:"(〃＞皿＜)你快回来"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->