<!-- build time:Thu Jan 25 2024 04:07:03 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="水文 & 摄影" href="http://example.com/rss.xml"><link rel="alternate" type="application/atom+xml" title="水文 & 摄影" href="http://example.com/atom.xml"><link rel="alternate" type="application/json" title="水文 & 摄影" href="http://example.com/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="http://example.com/distributed-microservices/%E5%88%86%E5%B8%83%E5%BC%8FID&%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81&%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1&%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"><title>分布式理论&算法&协议 - 分布式微服务 | fantedong = 水文 & 摄影 = 为了能更好地访问图片，你需要一点魔法</title><meta name="generator" content="Hexo 6.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">分布式理论&算法&协议</h1><div class="meta"><span class="item" title="创建时间：2024-01-06 12:02:34"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2024-01-06T12:02:34+08:00">2024-01-06</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>16k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>15 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">fantedong</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><img src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231217154635468.png"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/distributed-microservices/" itemprop="item" rel="index" title="分类于 分布式微服务"><span itemprop="name">分布式微服务</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://example.com/distributed-microservices/%E5%88%86%E5%B8%83%E5%BC%8FID&%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81&%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1&%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="范特东东东"><meta itemprop="description" content="为了能更好地访问图片，你需要一点魔法, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="水文 & 摄影"></span><div class="body md" itemprop="articleBody"><h1 id="cap-base-理论详解"><a class="anchor" href="#cap-base-理论详解">#</a> CAP &amp; BASE 理论详解</h1><h2 id="cap-理论"><a class="anchor" href="#cap-理论">#</a> CAP 理论</h2><h3 id="简介"><a class="anchor" href="#简介">#</a> 简介</h3><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231217154635468.png" alt="CAP理论"></p><p>CAP 理论指的是 **<font color="#B32015">在一个分布式系统中，在设计读写操作时，只能同时满足以下三点中的两个：一致性（C）、可用性（A）、分区容错性（P）</font>**。</p><ul><li><p><font color="cornflowerblue">一致性（ <code>C</code> onsistency）</font>：分布式系统中多个主机之间是否能够保持数据一致的特性。即，<font color="red">当系统数据发生更新操作后，各个主机中的数据仍然处于一致的状态</font>。所有节点访问同一份最新的数据副本。</p></li><li><p><font color="cornflowerblue">可用性（ <code>A</code> vailability）</font>：<font color="red">系统提供的服务必须一直处于可用的状态</font>。即，对于用户的每一个请求，系统（非故障节点）总是可以在有限的时间内对用户做出合理响应（不是错误 / 超时的响应）。</p></li><li><p><font color="cornflowerblue">分区容错性（ <code>P</code> artition tolerance）</font>：<font color="red">分布式系统在遇到任何<strong>网络分区故障</strong>时，仍能够保证对外提供（满足一致性和可用性的）服务</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/partition-tolerance.png" alt="partition-tolerance"></p><center>partition-tolerance</center><blockquote><p><strong>网络分区</strong>：分布式系统中，多个节点之间的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）<font color="red">某些节点之间不连通了，整个网络就分成了几块区域</font>，这就叫网络分区。</p></blockquote></li></ul><h3 id="不是所谓的3选2"><a class="anchor" href="#不是所谓的3选2">#</a> 不是所谓的 “3 选 2”</h3><p>大部分人解释这一定律时，常常简单的表述为：“一致性、可用性、分区容忍性三者你只能同时达到其中两个，不可能同时达到”。实际上这是一个非常具有误导性质的说法，而且在 CAP 理论诞生 12 年之后，CAP 之父也在 2012 年重写了之前的论文。</p><blockquote><p>当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。</p><p>简而言之就是：<strong><font color="#B32015">CAP 理论中分区容错性 P 是一定要满足的，在此基础上，只能满足可用性 A 或者强一致性 C</font></strong>。</p></blockquote><p>因此，<font color="red">分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构</font>。比如 ZooKeeper、HBase 就是 CP 架构，Cassandra、Eureka 就是 AP 架构，Nacos 不仅支持 CP 架构也支持 AP 架构。</p><p>为啥不可能选择 CA 架构呢？举个例子：若系统出现 “分区”，系统中的某个节点在进行写操作。为了保证 C，必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。</p><p><font color="red">选择 CP 还是 AP 的关键在于当前的业务场景，没有定论，比如对于需要确保强一致性的场景如银行一般会选择保证 CP 。</font></p><p>另外，需要补充说明的一点是：<font color="red">如果网络分区正常的话（系统在绝大部分时候所处的状态），也就说不需要保证 P 的时候，C 和 A 能够同时保证。</font></p><h3 id="cap-实际应用案例注册中心"><a class="anchor" href="#cap-实际应用案例注册中心">#</a> CAP 实际应用案例：注册中心</h3><p>我这里以注册中心来探讨一下 CAP 的实际应用。考虑到很多小伙伴不知道注册中心是干嘛的，这里简单以 Dubbo 为例说一说。</p><p>下图是 Dubbo 的架构图。注册中心 Registry 在其中扮演了什么角色呢？提供了什么服务呢？</p><p><font color="red">注册中心负责服务地址的注册与查找，相当于服务的目录，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231217154850034.png" alt="image-20231217154850034"></p><p>常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos...。</p><ol><li>**ZooKeeper 保证的是 CP。** 任何时刻对 ZooKeeper 的读请求都能得到一致性的结果，但是，<font color="red">ZooKeeper 不保证每次请求的可用性，比如在 Leader 选举过程中，或者半数以上的机器不可用的时候，或者当 Leader 节点中的数据发生了变化但 Follower 还没有同步完成之前，整个 ZooKeeper 集群是不对外提供服务的</font>。</li><li><strong>Eureka 保证的则是 AP。</strong> Eureka 在设计的时候就是优先保证 A （可用性）。<font color="red">在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的</font>。因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。 <font color="red">Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了，只不过这个节点上的数据可能并不是最新的</font>。</li><li><strong>Nacos 不仅支持 CP 也支持 AP。</strong></li></ol><p><strong>🐛 修正（参见：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1NuYWlsY2xpbWIvSmF2YUd1aWRlL2lzc3Vlcy8xOTA2">issue#1906</span>）</strong>：</p><p>ZooKeeper 通过可线性化（Linearizable）写入、全局 FIFO 顺序访问等机制来保障数据一致性。多节点部署的情况下， ZooKeeper 集群处于 Quorum 模式。Quorum 模式下的 ZooKeeper 集群，是一组 ZooKeeper 服务器节点组成的集合，其中大多数节点必须同意任何变更才能被视为有效。</p><p>由于 Quorum 模式下的读请求不会触发各个 ZooKeeper 节点之间的数据同步，因此在某些情况下还是可能会存在读取到旧数据的情况，导致不同的客户端视图上看到的结果不同，这可能是由于网络延迟、丢包、重传等原因造成的。ZooKeeper 为了解决这个问题，提供了 Watcher 机制和版本号机制来帮助客户端检测数据的变化和版本号的变更，以保证数据的一致性。</p><h3 id="小结"><a class="anchor" href="#小结">#</a> 小结</h3><p>在进行分布式系统设计和开发时，我们不应该仅仅局限在 CAP 问题上，还要关注系统的扩展性、可用性等等。</p><p><font color="red">在系统发生 “分区” 的情况下，CAP 理论只能满足 CP 或者 AP</font>。要注意的是，这里的前提是系统发生了 “分区”。</p><p><font color="red">如果系统没有发生 “分区” 的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了</font>。</p><p>总结：<strong><font color="red">如果系统发生 “分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生 “分区” 的话，我们要思考如何保证 CA 。</font></strong></p><h2 id="base-理论"><a class="anchor" href="#base-理论">#</a> BASE 理论</h2><h3 id="简介-2"><a class="anchor" href="#简介-2">#</a> 简介</h3><p><font color="red">BASE 是对 CAP 中一致性 C 和可用性 A 权衡的结果</font>，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求，由以下三个短语的简写组成：</p><ul><li><font color="cornflowerblue"><code>B</code> asically <code>A</code> vailable（基本可用）</font>：分布式系统在出现不可预知故障的时候，<font color="red">允许损失部分可用性</font>。但这绝不等价于系统不可用。</li><li><font color="cornflowerblue"><code>S</code> oft state（软状态）</font>：允许系统数据存在的中间状态，并认为该中间状态的存在不会影响系统的整体可用性。即，<font color="red">允许系统主机间进行数据同步的过程存在一定延时</font>。软状态，其实就是一种灰度状态，过渡状态。</li><li><font color="cornflowerblue"><code>E</code> ventually consistent（最终一致性）</font>：强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是<font color="red">需要系统保证最终数据能够达到一致，而不需要保证系统数据的实时一致性</font>。</li></ul><h3 id="核心思想"><a class="anchor" href="#核心思想">#</a> 核心思想</h3><p>BASE 理论的核心思想：<font color="red">即使无法做到强一致性 C ，但每个系统都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性 E </font>。</p><blockquote><p>也就是 **<font color="red">牺牲数据的强一致性 C 来满足系统的基本可用性 BA</font>** ，系统中一部分数据不可用或者不一致时，仍需要保持系统整体 “基本可用”。</p></blockquote><p>**BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。**AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。<font color="red">在分区故障恢复后，系统应该达到最终一致性</font>。这一点其实就是 BASE 理论延伸的地方。</p><h3 id="三要素"><a class="anchor" href="#三要素">#</a> 三要素</h3><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC81LzI0LzE2MzkxNDgwNmQ5ZTE1YzY" alt="BASE理论三要素"></p><h4 id="基本可用ba"><a class="anchor" href="#基本可用ba">#</a> 基本可用（BA）</h4><p>基本可用是指分布式系统在出现不可预知故障的时候，<font color="red">允许损失部分可用性</font>。但是，这绝不等价于系统不可用。</p><ul><li><strong>响应时间上的损失</strong>：正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。</li><li><strong>系统功能上的损失</strong>：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。</li></ul><h4 id="软状态s"><a class="anchor" href="#软状态s">#</a> 软状态（S）</h4><p>软状态指允许系统中的数据存在中间状态（<strong>CAP 理论中的数据不一致</strong>），并认为该中间状态的存在不会影响系统的整体可用性，即<font color="red">允许系统在不同节点的数据副本之间进行数据同步的过程存在延时</font>。</p><h4 id="最终一致性e"><a class="anchor" href="#最终一致性e">#</a> 最终一致性（E）</h4><p>最终一致性强调的是<font color="red">系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态</font>。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，<font color="red">而不需要实时保证系统数据的强一致性</font>。</p><blockquote><p>分布式一致性的 3 种级别：</p><ol><li><strong>强一致性</strong>：系统写入了什么，读出来的就是什么。</li><li><strong>弱一致性</strong>：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。</li><li><strong>最终一致性</strong>：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。</li></ol><p><strong><font color="red">业界比较推崇是最终一致性级别，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。</font></strong></p></blockquote><p>那实现最终一致性的具体方式是什么呢？<span class="exturl" data-url="aHR0cDovL2drLmxpbmsvYS8xMHJaTQ==">《分布式协议与算法实战》</span> 中是这样介绍：</p><blockquote><ul><li><strong>读时修复</strong>：在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点的副本数据不一致，系统就自动修复数据。</li><li><strong><font color="red">写时修复</font></strong>: 在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败 就将数据缓存下来，然后定时重传，修复数据的不一致性。</li><li><strong>异步修复</strong>：这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。</li></ul></blockquote><p>比较推荐 <strong>写时修复</strong>，这种方式对性能消耗比较低。</p><h3 id="小结-2"><a class="anchor" href="#小结-2">#</a> 小结</h3><p><strong><font color="#B32015">ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。</font></strong></p><h1 id="paxos-算法详解"><a class="anchor" href="#paxos-算法详解">#</a> Paxos 算法详解</h1><h2 id="背景"><a class="anchor" href="#背景">#</a> 背景</h2><p>Paxos 算法是 Leslie Lamport（<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU4JThFJUIxJUU2JTk2JUFGJUU1JTg4JUE5JUMyJUI3JUU1JTg1JUIwJUU0JUJDJUFGJUU3JTg5JUI5">莱斯利・兰伯特</span>）在 1990 年提出了一种 **<font color="#B32015">分布式系统共识算法</font>**。这也是第一个被证明完备的共识算法（前提是不存在拜占庭将军问题，也就是没有恶意节点）。</p><p>为了介绍 Paxos 算法，兰伯特专门写了一篇幽默风趣的论文。在这篇论文中，他虚拟了一个叫做 Paxos 的希腊城邦来更形象化地介绍 Paxos 算法。</p><p>不过，审稿人并不认可这篇论文的幽默。于是，他们就给兰伯特说：“如果你想要成功发表这篇论文的话，必须删除所有 Paxos 相关的故事背景”。兰伯特一听就不开心了：“我凭什么修改啊，你们这些审稿人就是缺乏幽默细胞，发不了就不发了呗！”。</p><p>于是乎，提出 Paxos 算法的那篇论文在当时并没有被成功发表。</p><p>直到 1998 年，系统研究中心 (Systems Research Center，SRC）的两个技术研究员需要找一些合适的分布式算法来服务他们正在构建的分布式系统，Paxos 算法刚好可以解决他们的部分需求。因此，兰伯特就把论文发给了他们。在看了论文之后，这俩大佬觉得论文还是挺不错的。于是，兰伯特在 1998 年重新发表论文 <span class="exturl" data-url="aHR0cDovL2xhbXBvcnQuYXp1cmV3ZWJzaXRlcy5uZXQvcHVicy9sYW1wb3J0LXBheG9zLnBkZg==">《The Part-Time Parliament》</span>。</p><p>论文发表之后，各路学者直呼看不懂，言语中还略显调侃之意。这谁忍得了，在 2001 年的时候，兰伯特专门又写了一篇 <span class="exturl" data-url="aHR0cDovL2xhbXBvcnQuYXp1cmV3ZWJzaXRlcy5uZXQvcHVicy9wYXhvcy1zaW1wbGUucGRm">《Paxos Made Simple》</span> 的论文来简化对 Paxos 的介绍，主要讲述<font color="red">两阶段共识协议</font>部分，顺便还不忘嘲讽一下这群学者。</p><p>《Paxos Made Simple》这篇论文就 14 页，相比于 《The Part-Time Parliament》的 33 页精简了不少。最关键的是这篇论文的摘要就一句话：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/paxos-made-simple-L9ik01kM.png" alt="img"></p><blockquote><p>The Paxos algorithm, when presented in plain English, is very simple.</p></blockquote><p>翻译过来的意思大概就是：<font color="red">当我用无修饰的英文来描述时，Paxos 算法真心简单！</font></p><p>有没有感觉到来自兰伯特大佬满满地嘲讽的味道？</p><h2 id="介绍"><a class="anchor" href="#介绍">#</a> 介绍</h2><p>Paxos 算法是第一个被证明完备的分布式系统共识算法。共识算法的作用是 **<font color="red">让分布式系统中的多个节点之间对某个提案（Proposal）达成一致的看法</font>**。提案的含义在分布式系统中十分宽泛，像哪一个节点是 Leader 节点、多个事件发生的顺序等等都可以是一个提案。</p><p>兰伯特当时提出的 Paxos 算法主要包含 2 个部分:</p><ul><li><strong><font color="cornflowerblue">Basic Paxos 算法</font></strong>：描述的是<font color="red">多节点之间如何就某个值 (提案 Value) 达成共识</font>。</li><li><strong><font color="cornflowerblue">Multi-Paxos 思想</font></strong>：描述的是执行多个 Basic Paxos 实例，就一系列值达成共识。<font color="red">Multi-Paxos 说白了就是执行多次 Basic Paxos </font>，核心还是 Basic Paxos 。</li></ul><p>由于 Paxos 算法在国际上被公认的非常难以理解和实现，因此不断有人尝试简化这一算法。到了 2013 年才诞生了<font color="red">一个比 Paxos 算法更易理解和实现的共识算法 —<span class="exturl" data-url="aHR0cHM6Ly9qYXZhZ3VpZGUuY24vZGlzdHJpYnV0ZWQtc3lzdGVtL3RoZW9yZW0mYW1wO2FsZ29yaXRobSZhbXA7cHJvdG9jb2wvcmFmdC1hbGdvcml0aG0uaHRtbA==">Raft 算法</span></font> 。更具体点来说，<font color="red">Raft 是 Multi-Paxos 的一个简化变种</font>，其简化了 Multi-Paxos 的思想，变得更容易被理解以及工程实现。</p><p>针对没有恶意节点的情况，除了 Raft 算法之外，当前最常用的一些共识算法比如 <strong>ZAB 协议</strong>、 <strong>Fast Paxos</strong> 算法都是基于 Paxos 算法改进的。</p><p>针对存在恶意节点的情况，一般使用的是 <strong>工作量证明（POW，Proof-of-Work）</strong>、 <strong>权益证明（PoS，Proof-of-Stake ）</strong> 等共识算法。这类共识算法最典型的应用就是<font color="red">区块链</font>，就比如说前段时间以太坊官方宣布其共识机制正在从工作量证明 (PoW) 转变为权益证明 (PoS)。</p><p>区块链系统使用的共识算法需要解决的核心问题是 **<font color="red">拜占庭将军问题</font>** ，这和我们日常接触到的 ZooKeeper、Etcd、Consul 等分布式中间件不太一样。</p><hr><p>下面我们来对 Paxos 算法的定义做一个总结：</p><ul><li>Paxos 算法是兰伯特在 1990 年提出了一种分布式系统共识算法。</li><li>兰伯特当时提出的 Paxos 算法主要包含 2 个部分: Basic Paxos 算法和 Multi-Paxos 思想。</li><li><font color="red">Raft 算法、ZAB 协议、 Fast Paxos 算法都是基于 Paxos 算法改进而来</font>。</li></ul><h2 id="basic-paxos-算法"><a class="anchor" href="#basic-paxos-算法">#</a> Basic Paxos 算法</h2><p>Basic Paxos 中存在 3 个重要的角色：</p><ol><li><strong><font color="cornflowerblue">提议者（Proposer）</font></strong>：也可以叫做协调者（coordinator），提议者<font color="red">负责接受客户端的请求，并发起提案</font>。提案信息通常包括提案编号 (Proposal ID) 、提议的值 (Value)。</li><li><strong><font color="cornflowerblue">接受者（Acceptor）</font></strong>：也可以叫做投票员（voter），<font color="red">负责对提议者的提案进行投票，同时需要记住自己的投票历史</font>；</li><li><strong><font color="cornflowerblue">学习者（Learner）</font></strong>：<font color="red">如果有超过半数接受者就某个提议达成了共识，那么学习者就需要接受这个提议，并就该提议作出运算，然后将运算结果返回给客户端</font>。</li></ol><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/up-890fa3212e8bf72886a595a34654918486c.png" alt="img"></p><blockquote><p>为了减少实现该算法所需的节点数，<font color="red">一个节点可以身兼多个角色</font>。并且，一个提案被选定需要被半数以上的 Acceptor 接受。这样的话，Basic Paxos 算法还<font color="red">具备容错性，在少于一半的节点出现故障时，集群仍能正常工作</font>。</p></blockquote><h2 id="multi-paxos-思想"><a class="anchor" href="#multi-paxos-思想">#</a> Multi Paxos 思想</h2><p>Basic Paxos 算法的仅能就单个值达成共识，为了能够对一系列的值达成共识，我们需要用到 Multi Paxos 思想。</p><blockquote><p>⚠️<strong>注意</strong>：Multi-Paxos 只是一种思想，这种思想的核心就是<font color="red">通过多个 Basic Paxos 实例就一系列值达成共识</font>。也就是说，Basic Paxos 是 Multi-Paxos 思想的核心，Multi-Paxos 就是多执行几次 Basic Paxos。</p></blockquote><p>由于兰伯特提到的 Multi-Paxos 思想缺少代码实现的必要细节 (比如怎么选举领导者)，所以<font color="red">在理解和实现上比较困难</font>。</p><p>不过，也不需要担心，我们并不需要自己实现基于 Multi-Paxos 思想的共识算法，业界已经有了比较出名的实现。<font color="red">像 Raft 算法就是 Multi-Paxos 的一个变种，其简化了 Multi-Paxos 的思想，变得更容易被理解以及工程实现，实际项目中可以优先考虑 Raft 算法</font>。</p><h1 id="raft-算法详解"><a class="anchor" href="#raft-算法详解">#</a> Raft 算法详解</h1><h2 id="背景-2"><a class="anchor" href="#背景-2">#</a> 背景</h2><p>当今的数据中心和应用程序在高度动态的环境中运行，为了应对高度动态的环境，它们通过额外的服务器进行横向扩展，并且根据需求进行扩展和收缩。同时，服务器和网络故障也很常见。</p><p>因此，<font color="red">系统必须在正常操作期间处理服务器的上下线。它们必须对变故做出反应并在几秒钟内自动适应</font>；对客户来说的话，明显的中断通常是不可接受的。</p><p>幸运的是，<font color="red">分布式共识</font>可以帮助应对这些挑战。</p><h3 id="拜占庭将军问题"><a class="anchor" href="#拜占庭将军问题">#</a> 拜占庭将军问题</h3><p>在介绍共识算法之前，先介绍一个简化版拜占庭将军的例子来帮助理解共识算法。</p><blockquote><p>假设多位拜占庭将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成是否要进攻的一致性决定？</p></blockquote><p>解决方案大致可以理解成：<font color="red">先在所有的将军中选出一个大将军，用来做出所有的决定</font>。</p><p>举例如下：假如现在一共有 3 个将军 A，B 和 C，每个将军都有一个随机时间的倒计时器。</p><ol><li>假设 A 将军的倒计时先结束，这个将军就把自己当成大将军候选人，然后派信使传递选举投票的信息给将军 B 和 C；</li><li>如果将军 B 和 C 还没有把自己当作候选人（自己的倒计时还没有结束），并且没有把选举票投给其他人，它们就会把票投给将军 A；</li><li>信使回到将军 A 时，它知道自己收到了足够的票数，成为了大将军，此后是否需要进攻就由大将军 A 决定；</li><li>然后 A 将军再去派信使通知另外两个将军，自己已经成为了大将军。如果一段时间还没收到将军 B 和 C 的回复（信使可能会被暗杀），那就再重派一个信使，直到收到回复。</li></ol><h3 id="共识算法"><a class="anchor" href="#共识算法">#</a> 共识算法</h3><p>共识是可容错系统中的一个基本问题：<strong><font color="red">即使面对故障，服务器也可以在共享状态上达成一致</font></strong>。</p><p>共识算法允许<font color="red">一组节点像一个整体一样一起工作，即使其中的一些节点出现故障也能够继续工作下去</font>，其正确性主要是源于复制状态机的性质：一组 <code>Server</code> 的状态机计算相同状态的副本，即使有一部分的 <code>Server</code> 宕机了，它们仍然能够继续运行。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/paxos-rsm-architecture.png" alt="rsm-architecture.png"></p><center>复制状态机架构</center><p>一般通过使用<font color="red">复制日志</font>来实现复制状态机。每个 <code>Server</code> 存储着一份包括命令序列的日志文件，状态机会按顺序执行这些命令。因为每个日志包含相同的命令，并且顺序也相同，所以每个状态机处理相同的命令序列。由于状态机是确定性的，所以处理相同的状态，得到相同的输出。</p><p>因此，<font color="red">共识算法的工作就是保持复制日志的一致性</font>。服务器上的共识模块从客户端接收命令并将它们添加到日志中。它与其他服务器上的共识模块通信，以确保即使某些服务器发生故障。每个日志最终包含相同顺序的请求。一旦命令被正确地复制，它们就被称为已提交。每个服务器的状态机按照日志顺序处理已提交的命令，并将输出返回给客户端。因此，这些服务器形成了一个单一的、高度可靠的状态机。</p><p>适用于实际系统的共识算法通常具有以下特性：</p><ul><li>安全。确保在非拜占庭条件（也就是上文中提到的简易版拜占庭）下的安全性，包括网络延迟、分区、包丢失、复制和重新排序。</li><li>高可用。只要大多数服务器都是可操作的，并且可以相互通信，也可以与客户端进行通信，那么这些服务器就可以看作完全功能可用的。因此，一个典型的由五台服务器组成的集群可以容忍任何两台服务器端故障。假设服务器因停止而发生故障；它们稍后可能会从稳定存储上的状态中恢复并重新加入集群。</li><li>一致性不依赖时序。错误的时钟和极端的消息延迟，在最坏的情况下也只会造成可用性问题，而不会产生一致性问题。</li><li>在集群中大多数服务器响应，命令就可以完成，不会被少数运行缓慢的服务器来影响整体系统性能。</li></ul><h2 id="raft-算法基础"><a class="anchor" href="#raft-算法基础">#</a> Raft 算法基础</h2><p>Raft 算法是一种 **<font color="#B32015">通过对日志复制管理来达到集群节点一致性</font>** 的算法。这个日志复制管理发生在集群节点中的 Leader 与 Followers 之间。<font color="red">Raft 通过选举出的 Leader 节点负责管理日志复制过程，以实现各个节点间数据的一致性</font>。</p><h3 id="节点类型"><a class="anchor" href="#节点类型">#</a> 节点类型</h3><p>一个 Raft 集群包括若干服务器，在任意的时间，每个服务器一定会处于以下<font color="red">三个状态</font>中的一个：</p><ul><li><code>Leader</code> ：负责发起心跳；响应客户端的读写请求；创建、同步（复制）日志；</li><li><code>Candidate</code> ：Leader 选举的候选人，由 Follower 转化而来；发起投票参与竞选；</li><li><code>Follower</code> ：可以处理客户端的读请求；接受 Leader 的心跳；同步来自于 Leader 的日志；当接收到其它 Candidate 的投票请求后，可以进行投票；当 Leader 挂了后，会转变为 Candidate 发起 Leader 选举；</li></ul><p>在正常的情况下，只有一个服务器是 Leader，剩下的服务器是 Follower。Follower 是被动的，它们不会发送任何请求，只是响应来自 Leader 和 Candidate 的请求。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/paxos-server-state.png" alt="img"></p><h3 id="任期term"><a class="anchor" href="#任期term">#</a> 任期（term）</h3><p>如下图所示，<font color="red">raft 算法将时间划分为任意长度的任期（term），任期用连续的数字表示，看作当前 term 号</font>。</p><ul><li>每一个任期的开始都是一次选举，在选举开始时，一个或多个 Candidate 会尝试成为 Leader。</li><li>如果一个 Candidate 赢得了选举，它就会在该任期内担任 Leader。</li><li>如果没有选出 Leader，将会开启另一个任期，并立刻开始下一次选举。【t3】</li><li><font color="red">raft 算法保证在给定的一个任期最少要有一个 Leader</font>。</li></ul><p>任期规则：</p><ul><li>每个节点都会存储当前的 term 号，当服务器之间进行通信时会交换当前的 term 号；</li><li>如果有服务器发现自己的 term 号比其他人小，那么他会更新到较大的 term 值；</li><li>如果一个 Candidate 或者 Leader 发现自己的 term 过期了，他会立即退回成 Follower；</li><li>如果一台服务器收到的请求的 term 号是过期的，那么它会拒绝此次请求；</li></ul><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/paxos-term.png" alt="img"></p><h3 id="日志"><a class="anchor" href="#日志">#</a> 日志</h3><ul><li><p><code>entry</code> ：每一个事件成为 entry，只有 Leader 可以创建 entry。entry 的内容为 <code>&lt;term,index,cmd&gt;</code> 其中 cmd 是可以应用到状态机的操作。</p></li><li><p><code>log</code> ：<font color="red">由 entry 构成的数组</font>，每一个 entry 都有一个表明自己在 log 中的 index。只有 Leader 才可以改变其他节点的 log。entry 总是先被 Leader 添加到自己的 log 数组中，然后再发起共识请求，获得同意后才会被 Leader 提交给状态机。Follower 只能从 Leader 获取新日志和当前的 commitIndex，然后把对应的 entry 应用到自己的状态机中。</p></li></ul><h2 id="leader-选举"><a class="anchor" href="#leader-选举">#</a> <mark>🌟Leader 选举</mark></h2><p>Raft 算法使用<font color="red">心跳机制</font>来触发集群中 Leader 的选举。</p><p>如果一台服务器能够收到来自 Leader 或者 Candidate 的有效信息，那么它会一直保持为 Follower 状态，并且刷新自己的 electionElapsed（选举已用时间），重新计时。</p><p>Leader 会向所有的 Follower 周期性发送心跳来保证自己的 Leader 地位。<font color="red">如果一个 Follower 在一个心跳超时周期内没有收到 Leader 的心跳信息，则认为 Leader 挂了，这叫做<strong>选举超时</strong></font>。</p><p>为了开始新的选举，Follower 会自增自己的 term 号，并且转换状态为 Candidate。然后他会向所有节点发起 RequestVoteRPC 请求， Candidate 的状态会持续到以下情况发生：</p><ul><li><p><font color="gree">该节点赢得选举</font>。条件是该 Candidate <font color="red">在一个任期内，收到了来自集群内的多数选票 <code>（N/2+1）</code> </font>，它就可以成为 Leader。然后会将消息广播给所有其它节点，通知大家我是新的 Leader 了。</p></li><li><p><font color="gree">其他节点赢得选举</font>。在该 Candidate 等待选票的时候，它可能<font color="red">收到其他节点声明自己是 Leader 的心跳</font>，此时有两种情况：</p><ul><li><font color="red">对方的 term 号 ≥ 自己的 term 号，说明对方已经成为 Leader，则自己回退为 Follower</font> 。</li><li>对方的 term 号 ＜ 自己的 term 号，那么会拒绝该请求，并让对方节点更新 term 。</li></ul></li><li><p><font color="gree">一轮选举结束无人胜出，重新选举</font>。由于可能<font color="red">同一时刻出现多个 Candidate，导致没有 Candidate 获得大多数选票（即：没有收到过半选票，也没有收到新 Leader 通知）</font>。如果没有其他手段来重新分配选票的话，那么可能会无限重复下去。</p><blockquote><p>raft 使用了 **<font color="red">随机的选举超时时间</font>**（ <code>randomized election timeouts</code> ）来避免上述情况。<font color="red">其会为这些 Follower 随机分配一个选举发起时间 election timeout，只有到达了 election timeout 时间的 Follower 才能转变为 candidate，否则等待</font>。那么 election timeout 较小的 Follower 则会转变为 candidate 然后先发起选举，一般情况下其会优先获取到过半选票成为新的 leader。</p></blockquote></li></ul><h2 id="日志复制数据同步"><a class="anchor" href="#日志复制数据同步">#</a> 日志复制（数据同步）</h2><p>一旦选出了 Leader，它就开始接受客户端的请求。<font color="red">每一个客户端的请求都包含一条需要被复制状态机（ <code>Replicated State Machine</code> ）执行的命令</font>。</p><ol><li><p>Leader 收到客户端请求后，会生成一个 entry，包含 <code>&lt;index,term,cmd&gt;</code> 。将这个 entry 添加到自己的日志末尾后，<font color="red">向所有的节点广播该 entry，要求其他服务器复制这条 entry</font>。</p></li><li><p><font color="red">如果 Follower 接受该 entry，则会将 entry 添加到自己的日志后面</font>，同时返回给 Leader 同意。</p></li><li><p>如果 Leader 收到了多数的成功响应，<font color="red">Leader 会将这个 entry 应用到自己的状态机中</font>，之后可以认为这个 entry 是 committed 的，并且向客户端返回执行结果。</p></li></ol><p>raft 保证以下两个性质：</p><ul><li>在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们一定有相同的 cmd</li><li>在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们前面的 entry 也一定相同</li></ul><blockquote><p>通过 “仅有 Leader 可以生成 entry” 来保证第一个性质，第二个性质需要 **<font color="red">一致性检查</font>** 来进行保证。</p></blockquote><p>一般情况下，Leader 和 Follower 的日志保持一致，然后，Leader 的崩溃会导致日志不一样，这样一致性检查会产生失败。<font color="red">Leader 通过强制 Follower 复制自己的日志来处理日志的不一致</font>。这就意味着，在 Follower 上的冲突日志会被 Leader 的日志覆盖。为了使得 Follower 的日志和 Leader 的日志一致，Leader 需要找到 Follower 与它日志一致的地方，然后删除 Follower 在该位置之后的日志，接着把 Leader 自己在这之后的日志发送给 Follower。</p><p><font color="red">Leader 给每一个 Follower 维护了一个 <code>nextIndex</code> ，它表示 Leader 将要发送给该 Follower 的下一条日志条目的索引</font>。当一个 Leader 开始掌权时，它会将 <code>nextIndex</code> 初始化为它的最新的日志条目索引数 + 1。如果一个 Follower 的日志和 Leader 的不一致， <code>AppendEntries</code> 一致性检查会在下一次 <code>AppendEntries RPC</code> 时返回失败。在失败之后，Leader 会将 <code>nextIndex</code> 递减然后重试 <code>AppendEntries RPC</code> 。<font color="red">最终 <code>nextIndex</code> 会达到一个 Leader 和 Follower 日志一致的地方</font>。这时， <code>AppendEntries</code> 会返回成功，Follower 中冲突的日志条目都被移除了，并且添加所缺少的上了 Leader 的日志条目。<font color="red">一旦 <code>AppendEntries</code> 返回成功，Follower 和 Leader 的日志就一致了，这样的状态会保持到该任期结束</font>。</p><h2 id="leader-宕机处理"><a class="anchor" href="#leader-宕机处理">#</a> Leader 宕机处理</h2><h3 id="请求到达前-leader-挂了"><a class="anchor" href="#请求到达前-leader-挂了">#</a> 请求到达前 Leader 挂了</h3><p>Leader 在 client 发送写操作请求到达之前就挂了，因为请求还没有到达集群，所以这个请求对于集群来说就没有存在过，<font color="red">对集群数据的一致性没有任何影响</font>。Leader 挂了之后，<font color="red">会选举产生新的 Leader</font>。</p><p>由于 Stale Leader （旧领导）并未向 client 发送成功处理响应，所以<font color="red"> client 会重新发送该写操作请求</font>。</p><h3 id="未开始同步数据前-leader-挂了"><a class="anchor" href="#未开始同步数据前-leader-挂了">#</a> 未开始同步数据前 Leader 挂了</h3><p>client 发送写操作请求给 Leader，请求到达 Leader 后，Leader 还没有开始向 Followers 发出数据就挂了。这时集群会<font color="red">选举产生新的 Leader</font>。<font color="red">Stale Leader 重启后会作为 Follower 重新加入集群，并同步新 Leader 中的数据以保证数据一致性</font>。之前接收到 client 的数据被丢弃。</p><p>由于 Stale Leader 并未向 client 发送成功处理响应，所以<font color="red"> client 会重新发送该写操作请求</font>。</p><h3 id="同步完部分后-leader-挂了"><a class="anchor" href="#同步完部分后-leader-挂了">#</a> 同步完部分后 Leader 挂了</h3><p>client 发送写操作请求给 Leader，Leader 接收完数据后向所有 Follower 发送数据。在部分 Follower 接收到数据后 Leader 挂了。由于 Leader 挂了，就<font color="red">会发起新的 Leader 选举</font>。</p><ul><li><font color="gree">若 Leader 产生于已完成数据接收的 Follower</font>，其会继续将前面接收到的写操作请求转换为日志，并写入到本地状态机，并向所有 Flollower 发出询问。在获取过半同意响应后会向所有 Followers 发送 commit 指令，同时向 client 进行响应。</li><li><font color="gree">若 Leader 产生于尚未完成数据接收的 Follower</font>，那么原来已完成接收的 Follower 则会放弃曾接收到的数据。由于 client 没有接收到响应，所以 client 会重新发送该写操作请求。</li></ul><h3 id="commit-通知发出后-leader-挂了"><a class="anchor" href="#commit-通知发出后-leader-挂了">#</a> commit 通知发出后 Leader 挂了</h3><p>client 发送写操作请求给 Leader， Leader 也成功向所有 Followers 发出的 commit 指令，并向 client 发出响应后，Leader 挂了。</p><p>由于 Stale Leader 已经向 client 发送成功接收响应，且 commit 通知已经发出，说明<font color="red">这个写操作请求已经被 server 成功处理</font>。</p><h2 id="安全性"><a class="anchor" href="#安全性">#</a> 安全性</h2><h3 id="选举限制"><a class="anchor" href="#选举限制">#</a> 选举限制</h3><p><font color="red">Leader 需要保证自己存储全部已经提交的日志条目</font>。这样才可以使日志条目只有一个流向：从 Leader 流向 Follower，Leader 永远不会覆盖已经存在的日志条目。</p><p><font color="red">每个 Candidate 发送 RequestVoteRPC 时，都会带上最后一个 entry 的信息。所有节点收到投票信息时，会对该 entry 进行比较，<strong>如果发现自己的日志更新，则拒绝投票给该 Candidate</strong></font>。</p><blockquote><p>判断日志新旧的方式：</p><ul><li>如果两个日志的 term 不同，term 大的更新</li><li>如果 term 相同，更长的 index 更新</li></ul></blockquote><h3 id="节点崩溃"><a class="anchor" href="#节点崩溃">#</a> 节点崩溃</h3><p>如果 Leader 崩溃，集群中的节点在 electionTimeout 时间内没有收到 Leader 的心跳信息就会触发新一轮的 Leader 选举，<strong><font color="red">在 Leader 选举期间，整个集群对外是不可用的</font></strong>。</p><p>如果 Follower 和 Candidate 崩溃，处理方式会简单很多。之后发送给它的 RequestVoteRPC 和 AppendEntriesRPC 会失败。由于 raft 的所有请求都是幂等的，所以失败的话会无限的重试。如果崩溃恢复后，就可以收到新的请求，然后选择追加或者拒绝 entry。</p><h3 id="时间与可用性"><a class="anchor" href="#时间与可用性">#</a> 时间与可用性</h3><p>raft 的要求之一就是<font color="red">安全性不依赖于时间：系统不能仅仅因为一些事件发生的比预想的快一些或者慢一些就产生错误</font>。为了保证上述要求，最好能满足以下的时间条件：</p><pre><code>broadcastTime &lt;&lt; electionTimeout &lt;&lt; MTBF
</code></pre><ul><li><code>broadcastTime</code> ：向其他节点并发发送消息的平均响应时间；</li><li><code>electionTimeout</code> ：选举超时时间；</li><li><code>MTBF(mean time between failures)</code> ：单台机器的平均健康时间；</li></ul><p><code>broadcastTime</code> 应该比 <code>electionTimeout</code> 小一个数量级，为的是使 <code>Leader</code> 能够持续发送心跳信息（heartbeat）来阻止 <code>Follower</code> 开始选举；</p><p><code>electionTimeout</code> 也要比 <code>MTBF</code> 小几个数量级，为的是使得系统稳定运行。当 <code>Leader</code> 崩溃时，大约会在整个 <code>electionTimeout</code> 的时间内不可用；我们希望这种情况仅占全部时间的很小一部分。</p><p>由于 <code>broadcastTime</code> 和 <code>MTBF</code> 是由系统决定的属性，因此需要决定 <code>electionTimeout</code> 的时间。</p><p>一般来说，broadcastTime 一般为 <code>0.5～20ms</code> ，electionTimeout 可以设置为 <code>10～500ms</code> ，MTBF 一般为一两个月。</p><h2 id="动画演示"><a class="anchor" href="#动画演示">#</a> 动画演示</h2><blockquote><p><span class="exturl" data-url="aHR0cDovL3RoZXNlY3JldGxpdmVzb2ZkYXRhLmNvbS9yYWZ0Lw==">http://thesecretlivesofdata.com/raft/</span></p></blockquote><h3 id="raft-概述"><a class="anchor" href="#raft-概述">#</a> raft 概述</h3><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218145626883.png" alt="image-20231218145626883"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218145641429.png" alt="image-20231218145641429"></p><h3 id="leader-选举-2"><a class="anchor" href="#leader-选举-2">#</a> Leader 选举</h3><p>在 Raft 中，有两个控制选举的超时设置：</p><ul><li><font color="cornflowerblue"><code>election timeout</code> （选举超时）</font>：表示 Follower 等待转变为 Candidate 的倒计时间，随机设置在 150ms ~ 300ms 之间。某个 Follower 率先选举超时后，它成为 Candidate，开始新的选举任期（term 加 1），并为自己投一票，同时向其他节点发送请求投票的消息。如果接收节点在本任期内尚未投票，那么它将投票给 Candidate。</li><li><font color="cornflowerblue"><code>heartbeat timeout</code> （心跳超时）</font>：</li></ul><hr><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218110127195.png" alt="image-20231218110127195"></p><center>【<font color="cornflowerblue">election timeout（选举超时）</font>表示 Follower 等待转变为 Candidate 的倒计时间，随机设置在 150ms ~ 300ms 之间。】</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218142116228.png" alt="image-20231218142116228"></p><center>【某个 Follower 率先选举超时后，它成为 Candidate，开始新的选举任期（term 加1），并为自己投一票】</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218142238093.png" alt="image-20231218142238093"></p><center>【同时 Candidate 向其他节点发送请求投票的消息】</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218142326741.png" alt="image-20231218142326741"></p><center>【如果接收节点在本任期内尚未投票，那么它将投票给 Candidate】</center><center>【节点重置其选举超时】</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218143246476.png" alt="image-20231218143246476"></p><center>【一旦 Candidate 获得多数票，他就会成为 Leader】</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218143321866.png" alt="image-20231218143321866"></p><center>【Leader 开始向其 Follower 周期性地发送 Append Entries 消息。这些消息按照<font color="cornflowerblue"> heartbeat timeout（心跳超时）</font>指定的时间间隔发送。】</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218143548477.png" alt="image-20231218143548477"></p><center>【然后 Followers 回复每条 Append Entries 消息。】</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144001221.png" alt="image-20231218144001221"></p><center>【这个选举 term 将持续到某个 Follower 停止接收心跳，并成为 Candidate 为止。让我们阻止 Leader 并观看重新选举的发生。】</center><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144043076.png" alt="image-20231218144043076"></p><center>【节点 B 现在是第 2 个 term 的 Leader。需要多数票才能保证每个任期只能选举一名领导人。如果两个节点同时成为候选人，则可能会发生<font color="red">分裂投票</font>。】</center><hr><p>分裂投票的例子：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144355618.png" alt="image-20231218144355618"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144415586.png" alt="image-20231218144415586"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144428586.png" alt="image-20231218144428586"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144443566.png" alt="image-20231218144443566"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144459719.png" alt="image-20231218144459719"></p><h3 id="日志复制"><a class="anchor" href="#日志复制">#</a> 日志复制</h3><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144528293.png" alt="image-20231218144528293"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144543849.png" alt="image-20231218144543849"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144606513.png" alt="image-20231218144606513"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144617130.png" alt="image-20231218144617130"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144634196.png" alt="image-20231218144634196"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144648281.png" alt="image-20231218144648281"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144657566.png" alt="image-20231218144657566"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144711183.png" alt="image-20231218144711183"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144727919.png" alt="image-20231218144727919"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144744496.png" alt="image-20231218144744496"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144802996.png" alt="image-20231218144802996"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144841610.png" alt="image-20231218144841610"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144911945.png" alt="image-20231218144911945"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144924949.png" alt="image-20231218144924949"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144938649.png" alt="image-20231218144938649"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218144957469.png" alt="image-20231218144957469"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218145013862.png" alt="image-20231218145013862"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218145026793.png" alt="image-20231218145026793"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218145349524.png" alt="image-20231218145349524"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218145426830.png" alt="image-20231218145426830"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218145447316.png" alt="image-20231218145447316"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218145505919.png" alt="image-20231218145505919"></p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/image-20231218145519321.png" alt="image-20231218145519321"></p><h1 id="gossip-协议详解"><a class="anchor" href="#gossip-协议详解">#</a> Gossip 协议详解</h1><blockquote><p>gossip：闲话、流言蜚语</p></blockquote><h2 id="背景-3"><a class="anchor" href="#背景-3">#</a> 背景</h2><p>在分布式系统中，不同的节点进行数据 / 信息共享是一个基本的需求。</p><p>一种比较简单粗暴的方法就是<strong>集中式发散消息</strong>，简单来说就是<font color="red">一个主节点同时共享最新信息给其他所有节点</font>，比较适合中心化系统。这种方法的缺陷也很明显，节点多的时候不光<font color="red">同步消息的效率低，还太依赖与中心节点，存在单点风险问题</font>。</p><p>于是，<strong>分散式发散消息</strong>的 <strong><font color="cornflowerblue">Gossip 协议</font></strong> 就诞生了。</p><h2 id="介绍-2"><a class="anchor" href="#介绍-2">#</a> 介绍</h2><p>Gossip 协议 也叫 Epidemic 协议（流行病协议）或者 Epidemic propagation 算法（疫情传播算法），别名很多。不过这些名字的特点都具有 **<font color="red">随机传播特性</font>**（联想一下病毒传播、癌细胞扩散等生活中常见的情景），这也正是 Gossip 协议最主要的特点。</p><p>Gossip 协议最早是在 ACM 上的一篇 1987 年发表的论文 <span class="exturl" data-url="aHR0cHM6Ly9kbC5hY20ub3JnL2RvaS8xMC4xMTQ1LzQxODQwLjQxODQx">《Epidemic Algorithms for Replicated Database Maintenance》</span>中被提出的。根据论文标题，我们大概就能知道 Gossip 协议当时提出的主要应用是在<font color="red">分布式数据库系统中各个副本节点同步数据</font>。</p><p>正如 Gossip 协议其名一样，这是<font color="red">一种随机且带有传染性的方式，将信息传播到整个网络中，并在一定时间内，使得系统内的所有节点数据一致</font>。</p><p>在 Gossip 协议下，<font color="red">没有所谓的中心节点，每个节点周期性地随机找一个节点互相同步彼此的信息</font>，理论上来说，各个节点的状态最终会保持一致。</p><p>下面我们来对 Gossip 协议的定义做一个总结：<strong><font color="#B32015">Gossip 协议是一种允许在分布式系统中共享状态的去中心化通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员。</font></strong></p><h2 id="应用"><a class="anchor" href="#应用">#</a> 应用</h2><p>NoSQL 数据库 Redis 和 Apache Cassandra、服务网格解决方案 Consul 等知名项目都用到了 Gossip 协议，学习 Gossip 协议有助于我们搞清很多技术的底层原理。</p><p>我们这里以 <font color="gree">Redis Cluster</font> 为例说明 Gossip 协议的实际应用。</p><p>我们经常使用的分布式缓存 Redis 的官方集群解决方案（3.0 版本引入） Redis Cluster 就是<font color="red">基于 Gossip 协议来实现集群中各个节点数据的最终一致性</font>。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/up-fcacc1eefca6e51354a5f1fc9f2919f51ec.png" alt="Redis 的官方集群解决方案"></p><center>Redis 的官方集群解决方案</center><p>Redis Cluster 是一个典型的分布式系统，分布式系统中的各个节点需要互相通信。既然要相互通信就要遵循一致的通信协议，<font color="red">Redis Cluster 中的各个节点基于 <strong>Gossip 协议</strong> 来进行通信共享信息，每个 Redis 节点都维护了一份集群的状态信息</font>。</p><p>Redis Cluster 的节点之间会相互发送多种 Gossip 消息：</p><ul><li><strong><font color="cornflowerblue">MEET</font></strong>：在 Redis Cluster 中的某个 Redis 节点上执行 <code>CLUSTER MEET ip port</code> 命令，<font color="red">可以向指定的 Redis 节点发送一条 MEET 信息，用于将其添加进 Redis Cluster 成为新的 Redis 节点</font>。</li><li><strong><font color="cornflowerblue">PING/PONG</font></strong>：Redis Cluster 中的节点都会<font color="red">定时地向其他节点发送 PING 消息，来交换各个节点状态信息，检查各个节点状态</font>，包括在线状态、疑似下线状态 PFAIL 和已下线状态 FAIL。</li><li><strong><font color="cornflowerblue">FAIL</font></strong>：Redis Cluster 中的节点 A 发现 B 节点 PFAIL，并且在下线报告的有效期限内集群中半数以上的节点将 B 节点标记为 PFAIL，节点 A 就会向集群广播一条 FAIL 消息，通知其他节点将故障节点 B 标记为 FAIL 。</li><li>……</li></ul><p>下图就是主从架构的 Redis Cluster 的示意图，图中的虚线代表的就是各个节点之间使用 Gossip 进行通信 ，实线表示主从复制。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/redis-cluster-gossip-fO4qDqt2.png" alt="img"></p><p>有了 Redis Cluster 之后，不需要专门部署 Sentinel 集群服务了。<strong><font color="red">Redis Cluster 相当于是内置了 Sentinel 机制，内部的各个节点通过 Gossip 协议互相探测健康状态，在故障时可以自动切换</font></strong>。</p><h2 id="消息传播模式"><a class="anchor" href="#消息传播模式">#</a> 消息传播模式</h2><p>Gossip 设计了两种可能的消息传播模式：<strong>反熵（Anti-Entropy）</strong> 和 <strong>传谣（Rumor-Mongering）</strong>。</p><h3 id="反熵anti-entropy"><a class="anchor" href="#反熵anti-entropy">#</a> 反熵（Anti-Entropy）</h3><p>根据维基百科：</p><blockquote><p>熵的概念最早起源于<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU3JTg5JUE5JUU3JTkwJTg2JUU1JUFEJUE2">物理学</span>，用于度量一个热力学系统的混乱程度。熵最好理解为<font color="red">不确定性的量度</font>，而不是确定性的量度，因为越随机的信源的熵越大。</p></blockquote><p>在这里，你可以把反熵中的熵理解为节点之间数据的混乱程度 / 差异性，<font color="red">反熵就是指消除不同节点中数据的差异，提升节点间数据的相似度，从而降低熵值</font>。</p><p>具体是如何反熵的呢？<font color="red">集群中的节点，每隔段时间就随机选择某个其他节点，然后通过互相交换自己的所有数据，来消除两者之间的差异，实现数据的最终一致性</font>。</p><p>在实现反熵的时候，主要有推、拉和推拉三种方式：</p><ul><li>推：就是将自己的所有副本数据，推给对方，修复对方副本中的熵。</li><li>拉：就是拉取对方的所有副本数据，修复自己副本中的熵。</li><li>推拉：就是同时修复自己副本和对方副本中的熵。</li></ul><p>伪代码如下：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/up-df16e98bf71e872a7e1f01ca31cee93d77b.png" alt="反熵伪代码"></p><p>在我们实际应用场景中，<font color="red">一般不会采用随机的节点进行反熵</font>，而是需要可以的设计一个闭环。这样的话，我们能够在一个确定的时间范围内实现各个节点数据的最终一致性，而不是基于随机的概率。像 <code>InfluxDB</code> 就是这样来实现反熵的。</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/%E5%8F%8D%E7%86%B5-%E9%97%AD%E7%8E%AF-TwBsP6eP.png" alt="img"></p><ol><li>节点 A 推送数据给节点 B，节点 B 获取到节点 A 中的最新数据。</li><li>节点 B 推送数据给 C，节点 C 获取到节点 A，B 中的最新数据。</li><li>节点 C 推送数据给 A，节点 A 获取到节点 B，C 中的最新数据。</li><li>节点 A 再推送数据给 B 形成闭环，这样节点 B 就获取到节点 C 中的最新数据。</li></ol><p>虽然反熵很简单实用，<font color="red">但是节点过多或者节点动态变化的话，反熵就不太适用了</font>。这个时候，我们想要实现最终一致性就要靠 传谣 (Rumor mongering) 。</p><h3 id="传谣rumor-mongering"><a class="anchor" href="#传谣rumor-mongering">#</a> 传谣（Rumor-Mongering）</h3><p>谣言传播指的是分布式系统中的一个节点一旦有了新数据之后，就会变为活跃节点，活跃节点会周期性地联系其他节点向其发送新数据，直到所有的节点都存储了该新数据。</p><p>如下图所示（下图来自于<span class="exturl" data-url="aHR0cHM6Ly9tYW5hZ2VtZW50ZnJvbXNjcmF0Y2gud29yZHByZXNzLmNvbS8yMDE2LzA0LzAxL2ludHJvZHVjdGlvbi10by1nb3NzaXAv"> INTRODUCTION TO GOSSIP</span> 这篇文章）：</p><p>伪代码如下：</p><p><img data-src="https://raw.githubusercontent.com/hjx159/picture-bed/main/img/20210605170707933.png" alt="img"></p><p>谣言传播比较适合节点数量比较多的情况，不过，这种模式下<font color="red">要尽量避免传播的信息包不能太大，避免网络消耗太大</font>。</p><h3 id="小结-3"><a class="anchor" href="#小结-3">#</a> 小结</h3><ul><li><p>反熵（Anti-Entropy）会传播节点的所有数据，而谣言传播（Rumor-Mongering）只会传播节点新增的数据。</p></li><li><p>一般会给反熵设计一个闭环。</p></li><li><p>谣言传播（Rumor-Mongering）比较适合节点数量比较多或者节点动态变化的场景。</p></li></ul><h2 id="优缺点"><a class="anchor" href="#优缺点">#</a> 优缺点</h2><p><strong>优势：</strong></p><p>1、相比于其他分布式协议 / 算法来说，<font color="red">Gossip 协议理解起来非常简单</font>。</p><p>2、能够容忍网络上节点的随意地增加或者减少，宕机或者重启，因为 Gossip 协议下这些<font color="red">节点都是平等的，去中心化的</font>。新增加或者重启的节点在理想情况下最终是一定会和其他节点的状态达到一致。</p><p>3、<font color="red">速度相对较快</font>。节点数量比较多的情况下，扩散速度比一个主节点向其他节点传播信息要更快（多播）。</p><p><strong>缺陷</strong> :</p><p>1、消息需要通过多个传播的轮次才能传播到整个网络中，因此，<font color="red">必然会出现各节点状态不一致的情况</font>。毕竟，Gossip 协议强调的是最终一致，至于达到各个节点的状态一致需要多长时间，谁也无从得知。</p><p>2、由于拜占庭将军问题，<font color="red">不允许存在恶意节点</font>。</p><p>3、可能会出现<font color="red">消息冗余</font>的问题。由于消息传播的随机性，同一个节点可能会重复收到相同的消息。</p><h2 id="总结"><a class="anchor" href="#总结">#</a> 总结</h2><ul><li><p>Gossip 协议是一种<font color="red">允许在分布式系统中共享状态</font>的通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员。</p></li><li><p>Gossip 协议被 Redis、Apache Cassandra、Consul 等项目应用。</p></li><li><p>谣言传播（Rumor-Mongering）比较适合节点数量比较多或者节点动态变化的场景</p></li></ul></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2024-01-04 00:25:43" itemprop="dateModified" datetime="2024-01-04T00:25:43+08:00">2024-01-04</time> </span><span id="distributed-microservices/分布式ID&分布式锁&分布式事务&分布式配置中心/" class="item leancloud_visitors" data-flag-title="分布式理论&算法&协议" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>范特东东东 <i class="ic i-at"><em>@</em></i>水文 & 摄影</li><li class="link"><strong>本文链接：</strong> <a href="http://example.com/distributed-microservices/%E5%88%86%E5%B8%83%E5%BC%8FID&%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81&%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1&%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/" title="分布式理论&amp;算法&amp;协议">http://example.com/distributed-microservices/分布式ID&分布式锁&分布式事务&分布式配置中心/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/distributed-microservices/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA&%E7%AE%97%E6%B3%95&%E5%8D%8F%E8%AE%AE/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;hjx159&#x2F;picture-bed&#x2F;main&#x2F;img&#x2F;image-20231217154635468.png" title="分布式理论&amp;算法&amp;协议"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 分布式微服务</span><h3>分布式理论&算法&协议</h3></a></div><div class="item right"><a href="/distributed-microservices/API%E7%BD%91%E5%85%B3&SpringCloud%20Gateway/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;hjx159&#x2F;picture-bed&#x2F;main&#x2F;img&#x2F;spring-cloud-gateway-workflow.png" title="API网关 &amp; SpringCloud Gateway"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 分布式微服务</span><h3>API网关 & SpringCloud Gateway</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#cap-base-%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.</span> <span class="toc-text">CAP &amp; BASE 理论详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#cap-%E7%90%86%E8%AE%BA"><span class="toc-number">1.1.</span> <span class="toc-text">CAP 理论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E6%98%AF%E6%89%80%E8%B0%93%E7%9A%843%E9%80%892"><span class="toc-number">1.1.2.</span> <span class="toc-text">不是所谓的 “3 选 2”</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cap-%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83"><span class="toc-number">1.1.3.</span> <span class="toc-text">CAP 实际应用案例：注册中心</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">1.1.4.</span> <span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#base-%E7%90%86%E8%AE%BA"><span class="toc-number">1.2.</span> <span class="toc-text">BASE 理论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B-2"><span class="toc-number">1.2.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">1.2.2.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E8%A6%81%E7%B4%A0"><span class="toc-number">1.2.3.</span> <span class="toc-text">三要素</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%8F%AF%E7%94%A8ba"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">基本可用（BA）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%AF%E7%8A%B6%E6%80%81s"><span class="toc-number">1.2.3.2.</span> <span class="toc-text">软状态（S）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7e"><span class="toc-number">1.2.3.3.</span> <span class="toc-text">最终一致性（E）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-2"><span class="toc-number">1.2.4.</span> <span class="toc-text">小结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#paxos-%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3"><span class="toc-number">2.</span> <span class="toc-text">Paxos 算法详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">2.1.</span> <span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.2.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#basic-paxos-%E7%AE%97%E6%B3%95"><span class="toc-number">2.3.</span> <span class="toc-text">Basic Paxos 算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#multi-paxos-%E6%80%9D%E6%83%B3"><span class="toc-number">2.4.</span> <span class="toc-text">Multi Paxos 思想</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#raft-%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3"><span class="toc-number">3.</span> <span class="toc-text">Raft 算法详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF-2"><span class="toc-number">3.1.</span> <span class="toc-text">背景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98"><span class="toc-number">3.1.1.</span> <span class="toc-text">拜占庭将军问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95"><span class="toc-number">3.1.2.</span> <span class="toc-text">共识算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#raft-%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80"><span class="toc-number">3.2.</span> <span class="toc-text">Raft 算法基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E7%B1%BB%E5%9E%8B"><span class="toc-number">3.2.1.</span> <span class="toc-text">节点类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BB%E6%9C%9Fterm"><span class="toc-number">3.2.2.</span> <span class="toc-text">任期（term）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A5%E5%BF%97"><span class="toc-number">3.2.3.</span> <span class="toc-text">日志</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#leader-%E9%80%89%E4%B8%BE"><span class="toc-number">3.3.</span> <span class="toc-text">🌟Leader 选举</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5"><span class="toc-number">3.4.</span> <span class="toc-text">日志复制（数据同步）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#leader-%E5%AE%95%E6%9C%BA%E5%A4%84%E7%90%86"><span class="toc-number">3.5.</span> <span class="toc-text">Leader 宕机处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%B7%E6%B1%82%E5%88%B0%E8%BE%BE%E5%89%8D-leader-%E6%8C%82%E4%BA%86"><span class="toc-number">3.5.1.</span> <span class="toc-text">请求到达前 Leader 挂了</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%AA%E5%BC%80%E5%A7%8B%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E5%89%8D-leader-%E6%8C%82%E4%BA%86"><span class="toc-number">3.5.2.</span> <span class="toc-text">未开始同步数据前 Leader 挂了</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5%E5%AE%8C%E9%83%A8%E5%88%86%E5%90%8E-leader-%E6%8C%82%E4%BA%86"><span class="toc-number">3.5.3.</span> <span class="toc-text">同步完部分后 Leader 挂了</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#commit-%E9%80%9A%E7%9F%A5%E5%8F%91%E5%87%BA%E5%90%8E-leader-%E6%8C%82%E4%BA%86"><span class="toc-number">3.5.4.</span> <span class="toc-text">commit 通知发出后 Leader 挂了</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E5%85%A8%E6%80%A7"><span class="toc-number">3.6.</span> <span class="toc-text">安全性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%89%E4%B8%BE%E9%99%90%E5%88%B6"><span class="toc-number">3.6.1.</span> <span class="toc-text">选举限制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E5%B4%A9%E6%BA%83"><span class="toc-number">3.6.2.</span> <span class="toc-text">节点崩溃</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E4%B8%8E%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="toc-number">3.6.3.</span> <span class="toc-text">时间与可用性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E7%94%BB%E6%BC%94%E7%A4%BA"><span class="toc-number">3.7.</span> <span class="toc-text">动画演示</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#raft-%E6%A6%82%E8%BF%B0"><span class="toc-number">3.7.1.</span> <span class="toc-text">raft 概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#leader-%E9%80%89%E4%B8%BE-2"><span class="toc-number">3.7.2.</span> <span class="toc-text">Leader 选举</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6"><span class="toc-number">3.7.3.</span> <span class="toc-text">日志复制</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#gossip-%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3"><span class="toc-number">4.</span> <span class="toc-text">Gossip 协议详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF-3"><span class="toc-number">4.1.</span> <span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D-2"><span class="toc-number">4.2.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8"><span class="toc-number">4.3.</span> <span class="toc-text">应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E4%BC%A0%E6%92%AD%E6%A8%A1%E5%BC%8F"><span class="toc-number">4.4.</span> <span class="toc-text">消息传播模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%8D%E7%86%B5anti-entropy"><span class="toc-number">4.4.1.</span> <span class="toc-text">反熵（Anti-Entropy）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%A0%E8%B0%A3rumor-mongering"><span class="toc-number">4.4.2.</span> <span class="toc-text">传谣（Rumor-Mongering）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-3"><span class="toc-number">4.4.3.</span> <span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">4.5.</span> <span class="toc-text">优缺点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">4.6.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/distributed-microservices/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA&%E7%AE%97%E6%B3%95&%E5%8D%8F%E8%AE%AE/" rel="bookmark" title="分布式理论&算法&协议">分布式理论&算法&协议</a></li><li class="active"><a href="/distributed-microservices/%E5%88%86%E5%B8%83%E5%BC%8FID&%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81&%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1&%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/" rel="bookmark" title="分布式理论&算法&协议">分布式理论&算法&协议</a></li><li><a href="/distributed-microservices/API%E7%BD%91%E5%85%B3&SpringCloud%20Gateway/" rel="bookmark" title="API网关 & SpringCloud Gateway">API网关 & SpringCloud Gateway</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="范特东东东" data-src="/images/avatar.jpg"><p class="name" itemprop="name">范特东东东</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">59</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">18</span> <span class="name">分类</span></a></div></nav><div class="social"><span class="exturl item xiaohongshu" data-url="aHR0cHM6Ly93d3cueGlhb2hvbmdzaHUuY29tL3VzZXIvcHJvZmlsZS81ZTAyYzhhZDAwMDAwMDAwMDEwMDFmM2U=" title="https:&#x2F;&#x2F;www.xiaohongshu.com&#x2F;user&#x2F;profile&#x2F;5e02c8ad0000000001001f3e"><i class="ic i-xiaohongshu"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于我</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><span class="exturl" data-url="aHR0cHM6Ly9oangxNTkuZ2l0aHViLmlvL2NhdGVnb3JpZXMvcGhvdG9ncmFwaHkv"><i class="ic i-photography"></i>摄影</span></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/distributed-microservices/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA&%E7%AE%97%E6%B3%95&%E5%8D%8F%E8%AE%AE/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/distributed-microservices/API%E7%BD%91%E5%85%B3&SpringCloud%20Gateway/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-knowledge/" title="分类于 Java基础-知识点">Java基础-知识点</a></div><span><a href="/java/java-se/java-knowledge/%E5%B0%9A%E7%A1%85%E8%B0%B7_%E5%AE%8B%E7%BA%A2%E5%BA%B7_%E7%AC%AC17%E7%AB%A0_%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6/" title="宋红康_第17章_反射机制">宋红康_第17章_反射机制</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/photography/" title="分类于 摄影">摄影</a></div><span><a href="/photography/%E6%97%A5%E8%90%BD%E6%94%B6%E9%9B%86%E8%AE%A1%E5%88%92/" title="日落收集计划">日落收集计划</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/database/" title="分类于 数据库">数据库</a> <i class="ic i-angle-right"></i> <a href="/categories/database/redis/" title="分类于 Redis">Redis</a></div><span><a href="/database/redis/%E5%B0%9A%E7%A1%85%E8%B0%B7-%E5%91%A8%E9%98%B3-Redis7/" title="Redis7-尚硅谷-周阳">Redis7-尚硅谷-周阳</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-excise/" title="分类于 Java基础-真题">Java基础-真题</a></div><span><a href="/java/java-se/java-excise/%E7%AC%AC18%E7%AB%A0%EF%BC%9A%E9%9A%8F%E5%A0%82%E5%A4%8D%E4%B9%A0%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%9C%9F%E9%A2%98%EF%BC%88JDK8-17%E6%96%B0%E7%89%B9%E6%80%A7%EF%BC%89/" title="宋红康_第18章：JDK8-17新特性">宋红康_第18章：JDK8-17新特性</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-excise/" title="分类于 Java基础-真题">Java基础-真题</a></div><span><a href="/java/java-se/java-excise/%E7%AC%AC07%E7%AB%A0%EF%BC%9A%E9%9A%8F%E5%A0%82%E5%A4%8D%E4%B9%A0%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%9C%9F%E9%A2%98%EF%BC%88%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1-%E8%BF%9B%E9%98%B6%EF%BC%89/" title="宋红康_第07章：面向对象-进阶">宋红康_第07章：面向对象-进阶</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-knowledge/" title="分类于 Java基础-知识点">Java基础-知识点</a></div><span><a href="/java/java-se/java-knowledge/%E5%B0%9A%E7%A1%85%E8%B0%B7_%E5%AE%8B%E7%BA%A2%E5%BA%B7_%E7%AC%AC10%E7%AB%A0_%E5%A4%9A%E7%BA%BF%E7%A8%8B/" title="宋红康_第10章_多线程">宋红康_第10章_多线程</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-excise/" title="分类于 Java基础-真题">Java基础-真题</a></div><span><a href="/java/java-se/java-excise/%E7%AC%AC05%E7%AB%A0%EF%BC%9A%E9%9A%8F%E5%A0%82%E5%A4%8D%E4%B9%A0%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%9C%9F%E9%A2%98%EF%BC%88%E6%95%B0%E7%BB%84%EF%BC%89/" title="宋红康_第05章：数组">宋红康_第05章：数组</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/photography/" title="分类于 摄影">摄影</a></div><span><a href="/photography/%E6%95%85%E5%AE%AB%E9%9B%AA%E6%99%AF/" title="故宫雪景">故宫雪景</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-excise/" title="分类于 Java基础-真题">Java基础-真题</a></div><span><a href="/java/java-se/java-excise/%E7%AC%AC09%E7%AB%A0%EF%BC%9A%E9%9A%8F%E5%A0%82%E5%A4%8D%E4%B9%A0%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%9C%9F%E9%A2%98%EF%BC%88%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%EF%BC%89/" title="宋红康_第09章：异常处理">宋红康_第09章：异常处理</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/" title="分类于 Java基础">Java基础</a> <i class="ic i-angle-right"></i> <a href="/categories/java/java-se/java-excise/" title="分类于 Java基础-真题">Java基础-真题</a></div><span><a href="/java/java-se/java-excise/%E7%AC%AC06%E7%AB%A0%EF%BC%9A%E9%9A%8F%E5%A0%82%E5%A4%8D%E4%B9%A0%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%9C%9F%E9%A2%98%EF%BC%88%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1-%E5%9F%BA%E7%A1%80%EF%BC%89/" title="宋红康_第06章：面向对象-基础">宋红康_第06章：面向对象-基础</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">范特东东东 @ fantedong</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">1.8m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">27:56</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"distributed-microservices/分布式ID&分布式锁&分布式事务&分布式配置中心/",favicon:{show:"(●´3｀●)欢迎回来",hide:"(〃＞皿＜)你快回来"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->